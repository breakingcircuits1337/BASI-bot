import asyncio
import random
import re
import time
import json
import os
import aiohttp
from typing import Dict, List, Optional, Callable, Any, Tuple
from openai import OpenAI
import threading
from concurrent.futures import ThreadPoolExecutor
import logging
from vector_store import VectorStore
from constants import AgentConfig, is_image_model, is_cometapi_image_model, ReactionConfig
from shortcuts_utils import load_shortcuts_data, load_shortcuts, StatusEffectManager, apply_message_shortcuts, strip_shortcuts_from_message
import uuid
from datetime import datetime, timedelta
from pathlib import Path

# Safe root directory for file operations (current working directory)
SAFE_ROOT = Path(".").resolve()

def is_safe_path(path_str: str) -> bool:
    """Check if path is within safe root directory."""
    return True
    try:
        path = (SAFE_ROOT / path_str).resolve()
        return path.is_relative_to(SAFE_ROOT)
    except Exception:
        return False


try:
    from duckduckgo_search import DDGS
    SEARCH_AVAILABLE = True
except ImportError:
    SEARCH_AVAILABLE = False

# Game context management
try:
    from agent_games.game_context import game_context_manager
    GAMES_AVAILABLE = True
except ImportError:
    game_context_manager = None

# Media directory utilities for saving prompts alongside videos/images
try:
    from agent_games.ffmpeg_utils import (
        ensure_media_dirs,
        save_media_prompt,
        save_base64_image,
        MEDIA_VIDEOS_DIR,
        MEDIA_IMAGES_DIR,
        MEDIA_AGENT_VIDEOS_DIR
    )
    MEDIA_UTILS_AVAILABLE = True
except ImportError:
    MEDIA_UTILS_AVAILABLE = False
    MEDIA_VIDEOS_DIR = None
    MEDIA_IMAGES_DIR = None
    MEDIA_AGENT_VIDEOS_DIR = None
    save_base64_image = None

# Context-aware prompt components
try:
    from prompt_components import create_prompt_context, build_system_prompt, build_name_collision_guidance
    PROMPT_COMPONENTS_AVAILABLE = True
except ImportError:
    create_prompt_context = None
    build_system_prompt = None
    build_name_collision_guidance = None
    PROMPT_COMPONENTS_AVAILABLE = False

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

_global_event_loop = None
_loop_thread = None

def get_or_create_event_loop():
    global _global_event_loop, _loop_thread

    if _global_event_loop is None or not _global_event_loop.is_running():
        _global_event_loop = asyncio.new_event_loop()

        def run_loop():
            asyncio.set_event_loop(_global_event_loop)
            _global_event_loop.run_forever()

        _loop_thread = threading.Thread(target=run_loop, daemon=True)
        _loop_thread.start()

    return _global_event_loop


async def aiohttp_request_with_retry(
    method: str,
    url: str,
    max_retries: int = 3,
    base_delay: float = 1.0,
    **kwargs
) -> Optional[aiohttp.ClientResponse]:
    """
    Make an aiohttp request with retry logic for network errors.
    Handles DNS resolution failures, connection timeouts, etc.

    Args:
        method: HTTP method ('GET', 'POST', etc.)
        url: Target URL
        max_retries: Maximum number of retry attempts
        base_delay: Base delay between retries (doubles each retry)
        **kwargs: Additional arguments passed to session.request()

    Returns:
        aiohttp.ClientResponse on success, None on failure
    """
    last_error = None

    for attempt in range(max_retries):
        try:
            connector = aiohttp.TCPConnector(
                ttl_dns_cache=300,
                force_close=True
            )
            async with aiohttp.ClientSession(connector=connector) as session:
                async with session.request(method, url, **kwargs) as response:
                    # Read response content before session closes
                    content = await response.read()
                    # Return a simple result dict instead of response object
                    return {
                        'status': response.status,
                        'content': content,
                        'headers': dict(response.headers)
                    }

        except (aiohttp.ClientError, asyncio.TimeoutError, OSError) as e:
            last_error = e
            delay = base_delay * (2 ** attempt)
            logger.warning(f"[HTTP Retry] Attempt {attempt + 1}/{max_retries} failed: {type(e).__name__}: {e}")

            if attempt < max_retries - 1:
                logger.info(f"[HTTP Retry] Retrying in {delay:.1f}s...")
                await asyncio.sleep(delay)

    logger.error(f"[HTTP Retry] All {max_retries} attempts failed. Last error: {last_error}")
    return None


class Agent:
    def __init__(
        self,
        name: str,
        model: str,
        system_prompt: str,
        response_frequency: int = 30,
        response_likelihood: int = 50,
        max_tokens: int = 500,
        user_attention: int = 50,
        bot_awareness: int = 50,
        message_retention: int = 1,
        user_image_cooldown: int = 90,
        global_image_cooldown: int = 90,
        allow_spontaneous_images: bool = False,
        image_gen_turns: int = 3,
        image_gen_chance: int = 25,
        allow_spontaneous_videos: bool = False,
        video_gen_turns: int = 10,
        video_gen_chance: int = 10,
        video_duration: int = 4,
        self_reflection_enabled: bool = True,
        self_reflection_cooldown: int = 15,
        introspection_chance: int = 5,
        openrouter_api_key: str = "",
        cometapi_key: str = "",
        affinity_tracker: Any = None,
        send_message_callback: Optional[Callable] = None,
        agent_manager_ref: Any = None,
        vector_store: Any = None
    ):
        self.name = name
        self.model = model
        self._is_image_model = is_image_model(model)  # Cache image model check
        self.system_prompt = system_prompt
        self.response_frequency = response_frequency
        self.response_likelihood = response_likelihood
        self.max_tokens = max_tokens
        self.user_attention = user_attention
        self.bot_awareness = bot_awareness
        self.message_retention = message_retention
        self.user_image_cooldown = user_image_cooldown
        self.global_image_cooldown = global_image_cooldown
        self.allow_spontaneous_images = allow_spontaneous_images
        self.image_gen_turns = image_gen_turns
        self.image_gen_chance = image_gen_chance
        self.allow_spontaneous_videos = allow_spontaneous_videos
        self.video_gen_turns = video_gen_turns
        self.video_gen_chance = video_gen_chance
        self.video_duration = video_duration
        self.self_reflection_enabled = self_reflection_enabled
        self.self_reflection_cooldown = self_reflection_cooldown
        self.introspection_chance = introspection_chance
        self.openrouter_api_key = openrouter_api_key
        self.cometapi_key = cometapi_key
        self.affinity_tracker = affinity_tracker
        self.send_message_callback = send_message_callback
        self._agent_manager_ref = agent_manager_ref
        self.vector_store = vector_store

        self.is_running = False
        self.task: Optional[asyncio.Task] = None
        self.status = "stopped"
        self.last_response_time = 0
        self.conversation_history: List[Dict[str, str]] = []
        self.responded_to_shortcuts: set = set()  # Track message IDs with shortcuts we've responded to
        self.responded_to_images: set = set()  # Track message IDs with [IMAGE] tags we've responded to
        self.responded_to_mentions: set = set()  # Track message IDs with mentions we've responded to
        self.user_image_cooldowns: dict = {}  # Track last image generation time per user
        self.last_image_request_time = 0  # Track when this agent last used [IMAGE] tag
        self.last_video_request_time = 0  # Track when this agent last used [VIDEO] tag
        self.last_shortcut_response_time = 0  # Cooldown after shortcut responses
        self.messages_since_reinforcement = 0  # Track messages since last personality reinforcement
        self.last_reinforcement_time = time.time()  # Track time of last personality reinforcement
        self.lock = threading.Lock()
        self.last_message_importance = 5  # Track importance of last processed message
        self.bot_only_mode = False  # Track if responding in bot-only mode (ignore user messages directed at others)
        self.spontaneous_image_counter = 0  # Track messages sent for spontaneous image dice-roll
        self.spontaneous_video_counter = 0  # Track messages sent for spontaneous video dice-roll
        self._game_mode_original_settings = None  # Store original settings when in game mode
        self.last_self_reflection_time = 0  # Track when agent last used self-reflection (15-min cooldown)
        self.self_reflection_history: List[Dict] = []  # Track self-reflection prompt changes

    def update_config(
        self,
        model: Optional[str] = None,
        system_prompt: Optional[str] = None,
        response_frequency: Optional[int] = None,
        response_likelihood: Optional[int] = None,
        max_tokens: Optional[int] = None,
        user_attention: Optional[int] = None,
        bot_awareness: Optional[int] = None,
        message_retention: Optional[int] = None,
        user_image_cooldown: Optional[int] = None,
        global_image_cooldown: Optional[int] = None,
        allow_spontaneous_images: Optional[bool] = None,
        image_gen_turns: Optional[int] = None,
        image_gen_chance: Optional[int] = None,
        allow_spontaneous_videos: Optional[bool] = None,
        video_gen_turns: Optional[int] = None,
        video_gen_chance: Optional[int] = None,
        video_duration: Optional[int] = None,
        self_reflection_enabled: Optional[bool] = None,
        self_reflection_cooldown: Optional[int] = None,
        introspection_chance: Optional[int] = None,
        openrouter_api_key: Optional[str] = None,
        cometapi_key: Optional[str] = None
    ) -> None:
        if model is not None:
            self.model = model
            self._is_image_model = is_image_model(model)  # Update cache
        if system_prompt is not None:
            self.system_prompt = system_prompt
        if response_frequency is not None:
            self.response_frequency = response_frequency
        if response_likelihood is not None:
            self.response_likelihood = response_likelihood
        if max_tokens is not None:
            self.max_tokens = max_tokens
        if user_attention is not None:
            self.user_attention = user_attention
        if bot_awareness is not None:
            self.bot_awareness = bot_awareness
        if message_retention is not None:
            self.message_retention = message_retention
        if user_image_cooldown is not None:
            self.user_image_cooldown = user_image_cooldown
        if global_image_cooldown is not None:
            self.global_image_cooldown = global_image_cooldown
        if allow_spontaneous_images is not None:
            self.allow_spontaneous_images = allow_spontaneous_images
        if image_gen_turns is not None:
            self.image_gen_turns = image_gen_turns
        if image_gen_chance is not None:
            self.image_gen_chance = image_gen_chance
        if allow_spontaneous_videos is not None:
            self.allow_spontaneous_videos = allow_spontaneous_videos
        if video_gen_turns is not None:
            self.video_gen_turns = video_gen_turns
        if video_gen_chance is not None:
            self.video_gen_chance = video_gen_chance
        if video_duration is not None:
            self.video_duration = video_duration
        if self_reflection_enabled is not None:
            self.self_reflection_enabled = self_reflection_enabled
        if self_reflection_cooldown is not None:
            self.self_reflection_cooldown = self_reflection_cooldown
        if introspection_chance is not None:
            self.introspection_chance = introspection_chance
        if openrouter_api_key is not None:
            self.openrouter_api_key = openrouter_api_key
        if cometapi_key is not None:
            self.cometapi_key = cometapi_key

    def add_message_to_history(self, author: str, content: str, message_id: Optional[int] = None, replied_to_agent: Optional[str] = None, user_id: Optional[str] = None) -> None:
        # Check if this is our own message
        # Use startswith to handle model suffix in author name (e.g., "The Basilisk (gemini-2.5-flash...)")
        is_own_message = author.startswith(self.name)

        if is_own_message:
            logger.debug(f"[{self.name}] Adding own message to history (so I can see what I just said)")

        # Image models don't maintain conversation history - they only process [IMAGE] tags
        is_img_model_local = self._is_image_model

        if is_img_model_local and '[IMAGE]' in content:
            # Store [IMAGE] message temporarily for processing, but clear old ones first
            with self.lock:
                # Remove any existing [IMAGE] messages from history
                self.conversation_history = [msg for msg in self.conversation_history if '[IMAGE]' not in msg.get('content', '')]
                # Add the new [IMAGE] message
                msg_data = {
                    "author": author,
                    "content": content,
                    "timestamp": time.time(),
                    "message_id": message_id,
                    "user_id": user_id if user_id else author
                }
                if replied_to_agent:
                    msg_data["replied_to_agent"] = replied_to_agent
                self.conversation_history.append(msg_data)
            return

        # Create message data object (used for both conversation history and vector DB)
        msg_data = {
            "author": author,
            "content": content,
            "timestamp": time.time(),
            "message_id": message_id,
            "user_id": user_id if user_id else author
        }
        if replied_to_agent:
            msg_data["replied_to_agent"] = replied_to_agent

        # Add to conversation history (including own messages so agents see what they said)
        # Filter out spectator BOT messages if agent is actively playing a game
        # IMPORTANT: Human users should ALWAYS be able to give hints during games
        skip_message = False
        if GAMES_AVAILABLE and game_context_manager and game_context_manager.is_in_game(self.name):
            game_state = game_context_manager.get_game_state(self.name)
            if game_state:
                # Only keep messages from opponent, GameMaster, or game system
                is_opponent = author == game_state.opponent_name or author.startswith(f"{game_state.opponent_name} (")
                is_gamemaster = author == "GameMaster" or author.startswith("GameMaster (")

                # Check if author is a known agent (bot) - not a human user
                is_known_agent = False
                if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                    try:
                        for agent in self._agent_manager_ref.agents.values():
                            if author == agent.name or author.startswith(f"{agent.name} ("):
                                is_known_agent = True
                                break
                    except (AttributeError, RuntimeError):
                        pass

                # Skip ONLY if it's a spectator BOT (known agent, not opponent, not gamemaster, not self)
                # Human users can always give hints - their messages pass through
                if is_known_agent and not is_opponent and not is_gamemaster and not is_own_message:
                    skip_message = True
                    logger.debug(f"[{self.name}] Filtering out spectator BOT message from {author} during game")
                elif not is_known_agent and not is_opponent and not is_gamemaster and not is_own_message:
                    logger.info(f"[{self.name}] ALLOWING user hint from {author} during game (not a bot)")

        if not skip_message:
            with self.lock:
                # Flush messages older than 30 minutes to keep conversation fresh
                current_time = time.time()
                time_limit = 30 * 60  # 30 minutes in seconds
                self.conversation_history = [
                    msg for msg in self.conversation_history
                    if current_time - msg.get('timestamp', 0) <= time_limit
                ]

                self.conversation_history.append(msg_data)
                if len(self.conversation_history) > 25:
                    self.conversation_history = self.conversation_history[-25:]

            # Use startswith to handle webhook messages with model suffix
            if self.affinity_tracker:
                self.affinity_tracker.add_message_to_history(self.name, author, content)

        # Note: Vector DB storage is now handled at the AgentManager level (once per message globally)
        # to avoid duplicate storage. See AgentManager.add_message_to_all_agents()

    def get_last_n_messages(self, n: int = 25) -> List[Dict[str, str]]:
        with self.lock:
            return self.conversation_history[-n:]

    def get_filtered_messages_by_agent(self, max_per_agent: int = 2) -> List[Dict[str, str]]:
        """Get the last N messages from each agent/user within recent time window, maintaining chronological order."""
        with self.lock:
            if not self.conversation_history:
                return []

            current_time = time.time()

            # Check if in game mode - use longer time limit to survive API timeouts
            # API retries can take 3+ minutes, so normal 180s limit causes context loss
            in_game = False
            try:
                if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                    game_ctx = getattr(self._agent_manager_ref, 'game_context', None)
                    if game_ctx and game_ctx.is_in_game(self.name):
                        in_game = True
            except (AttributeError, TypeError):
                pass  # Game context not available, use default time limit

            # In game mode: 10 minutes to survive API timeouts/retries
            # In chat mode: 3 minutes (normal conversation pace)
            time_limit = 600 if in_game else 180

            # First filter by time
            recent_messages = [
                (idx, msg) for idx, msg in enumerate(self.conversation_history)
                if current_time - msg.get('timestamp', 0) <= time_limit
            ]

            if not recent_messages:
                return []

            # Group messages by author (keep track of indices to maintain order)
            author_messages = {}
            for idx, msg in recent_messages:
                author = msg['author']
                if author not in author_messages:
                    author_messages[author] = []
                author_messages[author].append((idx, msg))

            # For each author, keep only their last N messages
            indices_to_keep = set()
            for author, messages in author_messages.items():
                # Get last max_per_agent messages from this author
                for idx, msg in messages[-max_per_agent:]:
                    indices_to_keep.add(idx)

            # Reconstruct the list in chronological order
            filtered = [msg for idx, msg in enumerate(self.conversation_history) if idx in indices_to_keep]
            return filtered

    def is_user_message(self, author: str) -> bool:
        """
        Check if a message is from a user (not one of our bots or system entities).
        More reliable than pattern matching - explicitly checks against known bot names.
        """
        # System entities that should NOT trigger user attention
        # Note: [SYSTEM] is checked exactly because brackets make substring matching fail
        if author == '[SYSTEM]':
            return False
        system_entities = ["GameMaster", "System", "Bot"]
        if any(entity in author for entity in system_entities):
            return False

        # Check if author matches any of our agent names (with or without model suffix)
        if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
            try:
                agent_names = [a.name for a in self._agent_manager_ref.agents.values()]
                for agent in self._agent_manager_ref.agents.values():
                    # Check exact match or match with model suffix
                    if author == agent.name or author.startswith(f"{agent.name} ("):
                        return False  # This is a bot
                # Debug: if we get here, author wasn't found in agents
                logger.debug(f"[{self.name}] is_user_message: '{author}' not in agents: {agent_names}")
            except (AttributeError, RuntimeError) as e:
                logger.warning(f"[{self.name}] is_user_message exception checking agents: {e}")
        else:
            logger.warning(f"[{self.name}] is_user_message: no _agent_manager_ref available!")
        return True  # Not a known bot or system entity = user message

    def is_self_reflection_available(self) -> bool:
        """Check if self-reflection tools should be available (configurable cooldown)."""
        if not self.self_reflection_enabled:
            return False
        cooldown_seconds = self.self_reflection_cooldown * 60  # Convert minutes to seconds
        time_since_last = time.time() - self.last_self_reflection_time
        return time_since_last >= cooldown_seconds

    def execute_view_own_prompt(self) -> str:
        """
        Execute view_own_prompt tool - return agent's own numbered prompt.
        Protected sections are hidden.
        """
        try:
            from agent_games.prompt_utils import get_numbered_visible_prompt
            numbered_prompt, line_count = get_numbered_visible_prompt(self.system_prompt)
            return f"=== Your Core Directives ({line_count} visible lines) ===\n{numbered_prompt}"
        except Exception as e:
            logger.error(f"[{self.name}] Error viewing own prompt: {e}")
            return "Error: Could not retrieve directives."

    async def execute_web_search(self, query: str) -> str:
        """Execute a web search using DuckDuckGo."""
        if not SEARCH_AVAILABLE:
            return "Search unavailable: 'duckduckgo-search' package not installed. Ask admin to install it."
        
        try:
            logger.info(f"[{self.name}] Searching DDG for: {query}")
            # Run in thread to avoid blocking loop
            results = await asyncio.to_thread(lambda: list(DDGS().text(query, max_results=3)))
            
            if not results:
                return f"No search results found for: {query}"
            
            formatted = f"Search Results for '{query}':\n\n"
            for i, r in enumerate(results, 1):
                formatted += f"{i}. **{r.get('title', 'Untitled')}**\n"
                formatted += f"   {r.get('body', 'No description')}\n"
                formatted += f"   Source: {r.get('href', 'Unknown')}\n\n"
            
            return formatted
        except Exception as e:
            logger.error(f"[{self.name}] Search failed: {e}")
            return f"Search failed: {str(e)}"

    def execute_read_file(self, path_str: str) -> str:
        """Read file content with safety checks."""
        if not is_safe_path(path_str):
            return f"Access denied: '{path_str}' is outside the safe directory."
        
        file_path = SAFE_ROOT / path_str
        if not file_path.exists():
            return f"File not found: {path_str}"
        if not file_path.is_file():
            return f"Not a file: {path_str}"
            
        try:
            # Limit file size to 100KB to avoid context overflow
            if file_path.stat().st_size > 100 * 1024:
                return f"File too large: {path_str} (>100KB). Please ask for a specific section (not yet implemented)."
            
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
            return f"Content of '{path_str}':\n\n```\n{content}\n```"
        except Exception as e:
            return f"Error reading file: {e}"

    def execute_list_files(self, path_str: str) -> str:
        """List directory content with safety checks."""
        # defaulting empty or '.' to root
        if not path_str or path_str == ".":
            path_str = ""
            
        if not is_safe_path(path_str):
            return f"Access denied: '{path_str}' is outside the safe directory."
            
        dir_path = SAFE_ROOT / path_str
        if not dir_path.exists():
            return f"Directory not found: {path_str}"
        if not dir_path.is_dir():
            return f"Not a directory: {path_str}"
            
        try:
            items = sorted(list(dir_path.iterdir()))
            # Limit items
            if len(items) > 50:
                items = items[:50]
                truncated = True
            else:
                truncated = False
                
            formatted = f"Contents of '{path_str or '.'}':\n"
            for item in items:
                type_mark = "[DIR]" if item.is_dir() else "[FILE]"
                formatted += f"- {type_mark} {item.name}\n"
            
            if truncated:
                formatted += "... (truncated)\n"
            return formatted
        except Exception as e:
            return f"Error listing directory: {e}"

    def execute_self_change(self, action: str, line_number: Optional[int], new_content: Optional[str], reason: str) -> tuple[bool, str]:

        """
        Execute request_self_change tool - modify agent's own prompt.

        Args:
            action: "add", "delete", or "change"
            line_number: Line to modify (for delete/change)
            new_content: New content (for add/change)
            reason: Agent's reason for the change

        Returns:
            Tuple of (success: bool, message: str)
        """
        try:
            from agent_games.prompt_utils import PromptEdit, apply_prompt_edit, validate_and_cleanup_prompt

            # Create edit
            edit = PromptEdit(
                action=action,
                line_number=line_number,
                new_content=new_content,
                reason=reason
            )

            # Capture old content for history before applying edit
            old_content = None
            if line_number and action in ("delete", "change"):
                from agent_games.prompt_utils import translate_visible_to_actual_line
                prompt_lines = self.system_prompt.split('\n')
                actual_line = translate_visible_to_actual_line(self.system_prompt, line_number)
                if actual_line and 0 < actual_line <= len(prompt_lines):
                    old_content = prompt_lines[actual_line - 1]

            # Apply edit
            new_prompt = apply_prompt_edit(self.system_prompt, edit)

            if new_prompt is None:
                return False, "Change rejected - protected section or unsafe content."

            if new_prompt == self.system_prompt:
                return False, "No changes were made."

            # Validate and cleanup the new prompt
            cleaned_prompt, changes = validate_and_cleanup_prompt(new_prompt)

            if changes:
                logger.info(f"[{self.name}] Self-reflection prompt cleanup: {', '.join(changes)}")

            # Apply the change
            old_prompt = self.system_prompt
            self.system_prompt = cleaned_prompt

            # Update cooldown
            self.last_self_reflection_time = time.time()

            # Record in history
            history_entry = {
                "timestamp": time.time(),
                "action": action,
                "line_number": line_number,
                "old_content": old_content,
                "new_content": new_content,
                "reason": reason
            }
            self.self_reflection_history.append(history_entry)

            # Log the change
            logger.info(f"[{self.name}] SELF-REFLECTION: {action} - {reason[:100]}")

            # Save if callback available
            if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                if hasattr(self._agent_manager_ref, 'save_data_callback') and self._agent_manager_ref.save_data_callback:
                    self._agent_manager_ref.save_data_callback()
                    logger.info(f"[{self.name}] Self-reflection changes saved")

            return True, f"Self-change applied: {action}"

        except Exception as e:
            logger.error(f"[{self.name}] Error in self-change: {e}", exc_info=True)
            return False, f"Error applying change: {str(e)}"

    def should_respond(self) -> bool:
        current_time = time.time()
        time_since_last = current_time - self.last_response_time

        # CRITICAL: If agent is in game mode, ONLY respond to turn prompts
        # Don't respond to any other messages on timer
        game_context_manager = None
        if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
            game_context_manager = getattr(self._agent_manager_ref, 'game_context', None)

        # Check if in game mode
        in_game = game_context_manager and game_context_manager.is_in_game(self.name)
        if in_game:
            logger.debug(f"[{self.name}] In game mode - checking for turn prompt")
            # Agent is actively playing a game - ONLY respond to GameMaster turn prompts
            recent_messages = self.get_last_n_messages(10)
            most_recent_gamemaster_msg = None
            for msg in reversed(recent_messages):
                author = msg.get('author', '')
                if 'GameMaster' in author or 'system' in author.lower():
                    most_recent_gamemaster_msg = msg
                    break

            if most_recent_gamemaster_msg:
                content = most_recent_gamemaster_msg.get('content', '')
                msg_id = most_recent_gamemaster_msg.get('message_id')

                # Check if it's this agent's turn
                if f"YOUR TURN, {self.name}" in content:
                    # Check if we already responded
                    if not self._agent_manager_ref.has_agent_responded(msg_id, self.name):
                        logger.info(f"[{self.name}] GAME TURN PRIORITY - GameMaster is waiting for my move!")
                        # CRITICAL: Store the turn prompt message ID so we mark it as responded
                        self._pending_turn_prompt_id = msg_id
                        return True
                    else:
                        logger.debug(f"[{self.name}] Already responded to turn prompt {msg_id}")
                        return False
                else:
                    # Not our turn - don't respond at all
                    logger.debug(f"[{self.name}] In game but not my turn, ignoring timer")
                    return False
            else:
                # In game but no GameMaster message yet - wait
                logger.info(f"[{self.name}] In game mode but no turn prompt yet - ignoring timer")
                return False

        # Not in game mode - proceed with normal response logic
        recent_messages = self.get_last_n_messages(10)

        # Filter out shortcut messages - agent names in shortcuts are NOT mentions
        commands = load_shortcuts_data()
        recent_messages = [
            msg for msg in recent_messages
            if not any(cmd.get("name", "") in msg.get('content', '') for cmd in commands)
        ]

        # SPECIAL: Check if GameMaster is prompting this agent to make a move (for spectators)
        # This has HIGHEST priority - agents MUST respond to their turn
        # CRITICAL: Only check the MOST RECENT GameMaster message to avoid responding to old prompts
        # NOTE: Image agents skip this check - they only care about [IMAGE] tags, not game turns
        # NOTE: Only block on GameMaster turn prompts if there's an ACTIVE game running
        if not self._is_image_model:
            most_recent_gamemaster_msg = None
            for msg in reversed(recent_messages):
                author = msg.get('author', '')
                if 'GameMaster' in author or 'system' in author.lower():
                    most_recent_gamemaster_msg = msg
                    break  # Found the most recent GameMaster message

            if most_recent_gamemaster_msg:
                content = most_recent_gamemaster_msg.get('content', '')
                msg_id = most_recent_gamemaster_msg.get('message_id')

                # Check if it's this agent's turn
                if f"YOUR TURN, {self.name}" in content:
                    # CRITICAL: Only respond if we haven't already responded to this message
                    if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                        if not self._agent_manager_ref.has_agent_responded(msg_id, self.name):
                            logger.info(f"[{self.name}] GAME TURN PRIORITY - GameMaster is waiting for my move!")
                            return True  # Respond immediately, it's our turn!
                        else:
                            logger.debug(f"[{self.name}] Already responded to turn prompt {msg_id}")
                            # It's our turn but we already responded - don't respond again based on timer
                            return False
                    else:
                        # No agent manager, respond anyway
                        logger.info(f"[{self.name}] GAME TURN PRIORITY - GameMaster is waiting for my move!")
                        return True
                elif "YOUR TURN" in content:
                    # GameMaster is prompting someone else's turn - block if there's an active game
                    if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                        game_context = getattr(self._agent_manager_ref, 'game_context', None)
                        if game_context and len(game_context.get_all_active_games()) > 0:
                            # There's an active game and it's not our turn - don't respond
                            logger.debug(f"[{self.name}] Waiting for other player's turn, not responding on timer")
                            return False

        # SPECTATOR BLOCK: If there's an active game and this agent is NOT a player, block normal responses
        # Spectators should only comment via the controlled commentary system, not through normal bot_awareness
        if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
            game_context = getattr(self._agent_manager_ref, 'game_context', None)
            if game_context:
                active_games = game_context.get_all_active_games()
                if len(active_games) > 0 and not game_context.is_in_game(self.name):
                    # There's an active game but this agent is NOT playing - they're a spectator
                    # Block normal responses - they'll be prompted by the commentary system instead
                    logger.debug(f"[{self.name}] Game in progress - spectators blocked from normal responding")
                    return False

        # OPTIMIZATION: Filter out messages we've already responded to AND messages directed at other agents
        # This prevents checking the same message 36 times (every 5 seconds for 180 seconds)
        if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
            original_count = len(recent_messages)

            # First, filter out already-responded messages
            recent_messages = [
                msg for msg in recent_messages
                if not self._agent_manager_ref.has_agent_responded(msg.get('message_id'), self.name)
            ]
            already_responded_filtered = original_count - len(recent_messages)

            # Second, filter out user messages that mention OTHER agents (not this one)
            messages_before_agent_filter = len(recent_messages)
            filtered_messages = []

            for msg in recent_messages:
                author = msg.get('author', '')
                content = msg.get('content', '').lower()

                # Only apply agent mention filtering to USER messages
                if not self.is_user_message(author):
                    filtered_messages.append(msg)
                    continue

                # Check if message mentions a DIFFERENT agent (not this one)
                mentions_other_agent = False
                for other_agent in self._agent_manager_ref.agents.values():
                    if other_agent.name == self.name:
                        continue  # Skip self

                    # Check if message mentions this other agent's name
                    other_name_parts = other_agent.name.lower().split()
                    if any(part in content for part in other_name_parts if len(part) > 3):
                        # Message mentions another agent - check if it also mentions us
                        my_name_parts = self.name.lower().split()
                        mentions_me = any(part in content for part in my_name_parts if len(part) > 3)

                        if not mentions_me:
                            # Message is for another agent only, not for us - FILTER IT OUT
                            mentions_other_agent = True
                            break

                # Only keep messages that DON'T mention other agents exclusively
                if not mentions_other_agent:
                    filtered_messages.append(msg)

            recent_messages = filtered_messages
            other_agent_filtered = messages_before_agent_filter - len(recent_messages)

            # Track if user messages were filtered because they're directed at other agents
            # This is needed to set bot_only_mode later
            found_user_messages_for_others = other_agent_filtered > 0

            # Log filtering results
            total_filtered = already_responded_filtered + other_agent_filtered
            if total_filtered > 0:
                filter_reasons = []
                if already_responded_filtered > 0:
                    filter_reasons.append(f"{already_responded_filtered} already-responded")
                if other_agent_filtered > 0:
                    filter_reasons.append(f"{other_agent_filtered} directed-at-others")
                logger.debug(f"[{self.name}] Pre-filtered {total_filtered} message(s): {', '.join(filter_reasons)}")
        else:
            # No agent manager reference - can't filter
            found_user_messages_for_others = False

        # Don't immediately return False if no messages - allow conversation initiation later

        # ABSOLUTE HIGHEST PRIORITY: Check if user replied directly to THIS agent
        # Still enforce a minimum cooldown to prevent rapid-fire responses
        min_priority_cooldown = 10  # Minimum 10 seconds even for priority responses
        for msg in reversed(recent_messages):
            replied_to = msg.get('replied_to_agent')
            author = msg.get('author', '')

            # Only process HUMAN USER replies (not bot-to-bot)
            if replied_to and self.is_user_message(author):
                # Check if the reply was to THIS agent (match full name or stripped model suffix)
                agent_base_name = self.name.split(' (')[0]  # Strip model suffix like "(gemini-2.5...)"
                if replied_to == self.name or replied_to == agent_base_name:
                    # Enforce minimum cooldown even for priority responses
                    if time_since_last < min_priority_cooldown:
                        logger.info(f"[{self.name}] DIRECT REPLY but cooldown: {time_since_last:.1f}s / {min_priority_cooldown}s")
                        return False
                    # Messages already filtered by pre-filter, no need to check again
                    logger.info(f"[{self.name}] DIRECT REPLY PRIORITY - {author} replied directly to my message!")
                    return True  # Respond immediately, bypassing all other checks

        # SPECIAL HANDLING FOR IMAGE MODELS: Only respond to [IMAGE] tags
        if self._is_image_model:
            # Check recent messages for [IMAGE] tag from users or bots
            for msg in reversed(recent_messages):
                author = msg.get('author', '')
                content = msg.get('content', '')
                msg_id = msg.get('message_id')

                # Check if message contains [IMAGE]
                if '[IMAGE]' in content:
                    # Check if user is on cooldown
                    if author in self.user_image_cooldowns:
                        last_generation = self.user_image_cooldowns[author]
                        time_since_last = current_time - last_generation
                        if time_since_last < self.user_image_cooldown:
                            logger.info(f"[{self.name}] User {author} on cooldown: {time_since_last:.1f}s / {self.user_image_cooldown}s")
                            # Still return True so we can send a cooldown message
                            return True

                    logger.info(f"[{self.name}] Image model detected [IMAGE] tag from message {msg_id} from {author}")
                    return True

            # No [IMAGE] tags found - image models don't respond
            return False


        # IMPORTANT: Check for user messages BEFORE deciding to initiate conversation
        # This prevents bots from introducing themselves when there are user messages (even if directed at others)

        # Check for direct mentions of this agent in RECENT messages (not filtered by time window)
        # Use recent_messages to avoid race condition where user_attention >= response_frequency
        for msg in reversed(recent_messages):
            author = msg.get('author', '')
            content = msg.get('content', '').lower()
            msg_id = msg.get('message_id')

            # Skip bot messages (only respond to user mentions)
            if not self.is_user_message(author):
                continue

            # Skip if we already responded to this mention (including video generation)
            if msg_id and msg_id in self.responded_to_mentions:
                continue

            # Check if user mentioned this agent's name
            name_parts = self.name.lower().split()
            if any(part in content for part in name_parts if len(part) > 3):  # First or last name
                # Human user mentions get immediate response (no cooldown)
                logger.info(f"[{self.name}] USER MENTION PRIORITY - {author} mentioned my name!")
                return True  # Respond immediately

        # Check if there's ANY user message in RECENT messages (avoid race condition)
        # Use recent_messages instead of filtered_messages to prevent user messages
        # from aging out before bots can respond (when response_frequency >= 60s)
        # NOTE: Messages directed at other agents are already filtered out by the pre-filter above
        most_recent_user_message = None
        for msg in reversed(recent_messages):
            author = msg.get('author', '')

            # Check if this is from a user (not one of our bots)
            # Pre-filter already removed messages directed at other agents
            if self.is_user_message(author):
                # Found a user message that's either general or mentions us
                most_recent_user_message = msg
                break

        # User message found: use user_attention directly as response likelihood
        if most_recent_user_message:
            # Not in bot-only mode since we found a user message for us
            self.bot_only_mode = False

            # Check if enough time has passed (use configured response_frequency as-is)
            if time_since_last < self.response_frequency:
                logger.info(f"[{self.name}] Not enough time for user message: {time_since_last:.1f}s / {self.response_frequency:.1f}s")
                return False

            # Store the user message ID so generate_response can mark it as responded
            user_msg_id = most_recent_user_message.get('message_id')
            if user_msg_id:
                self._pending_user_message_id = user_msg_id

            # Use user_attention directly as likelihood (90 = 90% chance)
            roll = random.randint(1, 100)
            should_respond = roll <= self.user_attention
            user_author = most_recent_user_message.get('author', 'user')
            logger.info(f"[{self.name}] USER MESSAGE from {user_author} - Rolled {roll} vs user_attention {self.user_attention}% = {should_respond}")
            return should_respond

        # Set bot_only_mode based on whether user messages were filtered out in pre-filter
        # If user messages exist but were directed at other agents, we want to exclude them from context
        # in generate_response() while still checking for bot messages to respond to
        self.bot_only_mode = found_user_messages_for_others

        # No user messages found (or all user messages were for other agents)
        # Check if there are bot messages to respond to
        if time_since_last < self.response_frequency:
            logger.info(f"[{self.name}] Not enough time passed: {time_since_last:.1f}s / {self.response_frequency}s")
            return False

        # DEBUG: Log when cooldown passes
        logger.info(f"[{self.name}] COOLDOWN PASSED: {time_since_last:.1f}s >= {self.response_frequency}s")

        # Check if we have any conversation history at all (bot or user messages)
        filtered_messages = self.get_filtered_messages_by_agent(self.message_retention)

        # Filter out GameMaster messages - spectators should not respond to turn prompts
        # GameMaster messages are only relevant to players, not spectators
        non_gamemaster_messages = [
            msg for msg in filtered_messages
            if "GameMaster" not in msg.get('author', '') and "(system)" not in msg.get('author', '')
        ]

        # If no conversation history at all (excluding GameMaster), allow agents to initiate based on response_likelihood
        if not non_gamemaster_messages:
            # Use response_likelihood to decide if agent wants to start conversation
            roll = random.randint(1, 100)
            should_initiate = roll <= self.response_likelihood
            logger.info(f"[{self.name}] No conversation history - Rolled {roll} vs response_likelihood {self.response_likelihood}% = {should_initiate}")
            return should_initiate

        # Bot messages found (true bot-only conversation) - use bot_awareness directly as likelihood (30 = 30% chance)
        roll = random.randint(1, 100)
        should_respond = roll <= self.bot_awareness
        logger.info(f"[{self.name}] BOT-ONLY CONVERSATION - Rolled {roll} vs bot_awareness {self.bot_awareness}% = {should_respond}")
        return should_respond

    async def create_core_memory_checkpoint(self):
        """
        Automatically create core memory checkpoints by summarizing old conversations.
        This allows agents to maintain context from conversations that fall outside
        the retrieval window.
        """
        if not self.vector_store:
            return

        try:
            # Check total message count for this agent
            stats = self.vector_store.get_stats()
            total_messages = stats.get('total_messages', 0)

            # Only create checkpoints if we have 100+ messages
            if total_messages < 100:
                return

            # Get all conversation messages for this agent, sorted by timestamp
            all_messages = self.vector_store.collection.get(
                where={
                    "$and": [
                        {"agent_name": self.name},
                        {"memory_type": "conversation"}
                    ]
                },
                include=["metadatas", "documents"]
            )

            if not all_messages or not all_messages['ids']:
                return

            # Sort by timestamp (oldest first)
            messages_with_meta = list(zip(all_messages['ids'], all_messages['metadatas'], all_messages['documents']))
            messages_with_meta.sort(key=lambda x: x[1].get('timestamp', 0))

            # Check if we already have checkpoints for old messages
            # If we do, start from where the last checkpoint ended
            existing_checkpoints = self.vector_store.collection.get(
                where={
                    "$and": [
                        {"agent_name": self.name},
                        {"memory_type": "core_memory"}
                    ]
                },
                include=["metadatas"]
            )

            last_checkpoint_time = 0
            if existing_checkpoints and existing_checkpoints['metadatas']:
                # Find the most recent checkpoint timestamp
                checkpoint_times = [meta.get('timestamp', 0) for meta in existing_checkpoints['metadatas']]
                last_checkpoint_time = max(checkpoint_times) if checkpoint_times else 0

            # Get messages older than the last checkpoint
            old_messages = [
                (msg_id, meta, doc) for msg_id, meta, doc in messages_with_meta
                if meta.get('timestamp', 0) > last_checkpoint_time
            ]

            # Only checkpoint messages that are at least 1 hour old (not recent conversations)
            current_time = time.time()
            one_hour_ago = current_time - 3600
            old_messages = [
                (msg_id, meta, doc) for msg_id, meta, doc in old_messages
                if meta.get('timestamp', 0) < one_hour_ago
            ]

            if len(old_messages) < 20:
                # Not enough old messages to create a meaningful checkpoint
                return

            # Summarize in chunks of 20 messages
            chunk_size = 20
            for i in range(0, len(old_messages), chunk_size):
                chunk = old_messages[i:i + chunk_size]
                if len(chunk) < 10:
                    # Skip small chunks at the end
                    break

                # Format the chunk for summarization
                chunk_text = []
                for msg_id, meta, doc in chunk:
                    author = meta.get('author', 'unknown')
                    timestamp = meta.get('timestamp', 0)
                    chunk_text.append(f"[{time.strftime('%Y-%m-%d %H:%M', time.localtime(timestamp))}] {author}: {doc}")

                conversation_snippet = "\n".join(chunk_text)

                # Use LLM to create a concise summary
                summary_prompt = f"""Summarize the following conversation chunk in 2-3 sentences from the perspective of {self.name}.
Focus on key topics discussed, important facts shared, and the overall context.
This summary will help you remember the broad strokes of this conversation later.

Conversation:
{conversation_snippet}

Summary (2-3 sentences, first-person perspective as {self.name}):"""

                try:
                    client = OpenAI(
                        base_url="https://openrouter.ai/api/v1",
                        api_key=self.openrouter_api_key
                    )

                    # Use a cheap, fast model for summarization (Haiku)
                    response = await asyncio.get_event_loop().run_in_executor(
                        None,
                        lambda: client.chat.completions.create(
                            model="anthropic/claude-3.5-haiku",
                            messages=[{"role": "user", "content": summary_prompt}],
                            max_tokens=150
                        )
                    )

                    summary = response.choices[0].message.content.strip()

                    # Store summary as a core memory with high importance
                    chunk_start_time = chunk[0][1].get('timestamp', 0)
                    chunk_end_time = chunk[-1][1].get('timestamp', 0)

                    self.vector_store.add_core_memory(
                        agent_name=self.name,
                        memory=summary,
                        importance=8,  # High importance - these are conversation summaries
                        timestamp=chunk_end_time  # Use end time as checkpoint timestamp
                    )

                    logger.info(f"[{self.name}]  Created core memory checkpoint: '{summary[:60]}...' "
                              f"(summarizing {len(chunk)} messages from {time.strftime('%Y-%m-%d', time.localtime(chunk_start_time))})")

                except Exception as e:
                    logger.error(f"[{self.name}] Error creating checkpoint summary: {e}", exc_info=True)
                    break  # Stop creating checkpoints on error

        except Exception as e:
            logger.error(f"[{self.name}] Error in create_core_memory_checkpoint: {e}", exc_info=True)

    async def _handle_image_generation_request(self) -> Optional[tuple]:
        """
        Handle [IMAGE] tag detection and image generation for image models.

        Returns:
            Tuple of (response_text, message_id) if image found, None otherwise
        """
        logger.info(f"[{self.name}] Image model detected - looking for [IMAGE] tag")
        recent_messages = self.get_last_n_messages(10)

        # Find most recent message with [IMAGE] from a user
        for msg in reversed(recent_messages):
            content = msg.get('content', '')
            author = msg.get('author', '')
            msg_id = msg.get('message_id')

            if '[IMAGE]' not in content:
                continue

            # Check if we've already processed this message
            if msg_id and msg_id in self.responded_to_images:
                logger.info(f"[{self.name}] Already processed image message {msg_id}, skipping")
                continue

            # Check if user is on cooldown
            current_time = time.time()
            if author in self.user_image_cooldowns:
                last_generation = self.user_image_cooldowns[author]
                time_since_last = current_time - last_generation
                if time_since_last < self.user_image_cooldown:
                    time_remaining = self.user_image_cooldown - time_since_last
                    cooldown_message = f"Whoa there! You're generating images too fast. Please wait {int(time_remaining)} more seconds before requesting another image."
                    logger.info(f"[{self.name}] Sending cooldown message to {author}")
                    # Mark as processed and clear from history
                    if msg_id:
                        self.responded_to_images.add(msg_id)
                    # Clear the [IMAGE] message from history
                    with self.lock:
                        self.conversation_history = [m for m in self.conversation_history if '[IMAGE]' not in m.get('content', '')]
                    return cooldown_message, msg.get('message_id')

            # Extract prompt after [IMAGE] tag
            image_prompt = content.split('[IMAGE]', 1)[1].strip()
            logger.info(f"[{self.name}] Extracted image prompt from {author}: {image_prompt[:100]}...")

            # Mark as processed immediately
            if msg_id:
                self.responded_to_images.add(msg_id)
                logger.info(f"[{self.name}] Marked message {msg_id} as processed")

            # Call AgentManager's image generation method
            # The prompt will be de-classified using running backend text agents
            if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                result = await self._agent_manager_ref.generate_image(image_prompt, author)

                # Clear the [IMAGE] message from history after processing
                with self.lock:
                    self.conversation_history = [m for m in self.conversation_history if '[IMAGE]' not in m.get('content', '')]

                if result:
                    image_url, used_prompt = result
                    # Update user's cooldown timestamp
                    self.user_image_cooldowns[author] = time.time()
                    self.last_response_time = time.time()
                    logger.info(f"[{self.name}] Updated cooldown timestamp for {author}")
                    # Return a special marker that tells Discord to send the image with the prompt used
                    return f"[IMAGE_GENERATED]{image_url}|PROMPT|{used_prompt}", msg.get('message_id')
                else:
                    return "Failed to generate image.", msg.get('message_id')

        logger.warning(f"[{self.name}] Image model but no [IMAGE] tag found")
        return None

    def _find_unresponded_shortcut(self, all_recent: List[Dict]) -> Optional[Dict]:
        """
        Find first unresponded message containing a shortcut TARGETED AT THIS AGENT.

        Args:
            all_recent: List of recent messages to check

        Returns:
            Message dict containing shortcut for this agent, or None
        """
        from shortcuts_utils import get_default_manager

        shortcut_manager = get_default_manager()

        # Get list of all agent names for targeting check
        available_agents = []
        if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
            available_agents = list(self._agent_manager_ref.agents.keys())

        for msg in reversed(all_recent):
            msg_id = msg.get('message_id')
            content = msg.get('content', '')

            # Skip if we already responded to this
            if msg_id and msg_id in self.responded_to_shortcuts:
                continue

            # Parse shortcuts with targeting info
            parsed_shortcuts = shortcut_manager.parse_shortcut_with_target(content, available_agents)

            if not parsed_shortcuts:
                continue

            # Check if ANY shortcut in this message targets this agent (or is untargeted)
            for shortcut_data, target_agent in parsed_shortcuts:
                if target_agent is None:
                    # Untargeted shortcut - applies to all agents
                    logger.info(f"[{self.name}] SHORTCUT DETECTED (untargeted) from {msg['author']} - {shortcut_data.get('name')}")
                    return msg
                elif target_agent == self.name:
                    # Targeted at THIS agent
                    logger.info(f"[{self.name}] SHORTCUT DETECTED (targeted at me) from {msg['author']} - {shortcut_data.get('name')}")
                    return msg
                else:
                    # Targeted at a DIFFERENT agent - skip this shortcut
                    logger.debug(f"[{self.name}] Shortcut {shortcut_data.get('name')} targets {target_agent}, not me - ignoring")

        return None

    def _find_direct_reply_to_agent(self, all_recent: List[Dict]) -> Optional[Dict]:
        """
        Find user messages that directly reply to this agent.

        Args:
            all_recent: List of recent messages to check

        Returns:
            Message dict that is a direct reply, or None
        """
        for msg in reversed(all_recent):  # Check most recent first
            replied_to = msg.get('replied_to_agent')
            author = msg.get('author', '')
            msg_id = msg.get('message_id')

            # Only process HUMAN USER replies (not bot-to-bot)
            if not replied_to or not self.is_user_message(author):
                continue

            # Check if the reply was to THIS agent
            agent_base_name = self.name.split(' (')[0]  # Strip model suffix
            if replied_to == self.name or replied_to == agent_base_name:
                # Skip if we already responded to this reply
                if msg_id and msg_id in self.responded_to_mentions:
                    continue

                logger.info(f"[{self.name}] Detected DIRECT REPLY from {author}")
                # Mark this reply as processed immediately
                if msg_id:
                    self.responded_to_mentions.add(msg_id)
                    logger.info(f"[{self.name}] Marked direct reply message {msg_id} as processed")
                return msg

        return None

    def _find_user_mention(self, all_recent: List[Dict]) -> Optional[Dict]:
        """
        Find user messages that mention this agent's name.
        Skips shortcut messages - agents shouldn't respond to their name in shortcuts.
        """
        commands = load_shortcuts_data()

        for msg in reversed(all_recent):
            content = msg.get('content', '')
            content_lower = content.lower()
            author = msg.get('author', '')
            msg_id = msg.get('message_id')

            if not self.is_user_message(author):
                continue

            if msg_id and msg_id in self.responded_to_mentions:
                continue

            # Skip messages that contain shortcuts - agent names in shortcuts are NOT mentions
            if any(cmd.get("name", "") in content for cmd in commands):
                continue

            name_parts = self.name.lower().split()
            if any(part in content_lower for part in name_parts if len(part) > 3):
                logger.info(f"[{self.name}] Detected USER mention in message from {author}")
                if msg_id:
                    self.responded_to_mentions.add(msg_id)
                return msg

        return None

    def _format_conversation_messages(self, full_system_prompt: str, recent_messages: List[Dict]) -> List[Dict[str, str]]:
        """
        Format conversation messages for LLM API call.

        Handles shortcut expansion and message formatting for both cases:
        - When there are recent messages: Format them with author prefixes
        - When there are no messages: Use introduction prompt

        Args:
            full_system_prompt: The complete system prompt
            recent_messages: List of recent conversation messages

        Returns:
            List of formatted messages ready for LLM API
        """
        messages = [{"role": "system", "content": full_system_prompt}]

        # Collect [SYSTEM] messages to append to system prompt (not as user messages)
        system_injections = []

        if recent_messages:
            # Format each message with author prefix
            # Status effects are applied via StatusEffectManager and injected into system prompt
            for msg in recent_messages:
                content = msg['content']

                # [SYSTEM] messages are internal notifications (game transitions, etc.)
                # Append to system prompt as directives, NOT as user messages
                # This prevents agents from responding to "[SYSTEM]" as if it were a person
                if msg.get('author') == '[SYSTEM]':
                    system_injections.append(content)
                    continue

                # Strip any [SYSTEM] references from agent messages to prevent chain reaction
                # where agents see others addressing [SYSTEM] and copy the pattern
                if '[SYSTEM]' in content:
                    content = content.replace('[SYSTEM]', '').replace('  ', ' ').strip()
                    if not content:  # Skip if message was only addressing [SYSTEM]
                        continue

                msg_id = msg.get('message_id')

                # Check if this message contains shortcuts
                commands = load_shortcuts_data()
                has_shortcut = any(cmd.get("name", "") in content for cmd in commands)

                if has_shortcut:
                    # Mark as processed
                    if msg_id and msg_id not in self.responded_to_shortcuts:
                        self.responded_to_shortcuts.add(msg_id)
                        logger.info(f"[{self.name}] Shortcut in message {msg_id} - status effect injected via system prompt")

                    # Get available agents for proper shortcut+target stripping
                    available_agents = []
                    if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                        available_agents = list(self._agent_manager_ref.agents.keys())

                    # Strip shortcut commands from content (including agent name targets)
                    clean_content = strip_shortcuts_from_message(content, available_agents)

                    # If message was ONLY shortcut commands, skip it entirely
                    # The agent only needs the status effect injection in system prompt
                    if not clean_content:
                        logger.debug(f"[{self.name}] Skipping shortcut-only message from {msg['author']}")
                        continue

                    # If there's remaining content after stripping, include it
                    messages.append({
                        "role": "user",
                        "content": f"{msg['author']}: {clean_content}"
                    })
                else:
                    # Normal message - include as-is
                    messages.append({
                        "role": "user",
                        "content": f"{msg['author']}: {content}"
                    })
        else:
            # No conversation history
            if StatusEffectManager.has_active_effects(self.name):
                # Under status effects - don't introduce, just respond naturally
                messages.append({
                    "role": "user",
                    "content": "Continue the conversation naturally."
                })
            else:
                messages.append({
                    "role": "user",
                    "content": "Introduce yourself or say what's on your mind."
                })

        # Append [SYSTEM] injections to the system prompt (at the end, most recent context)
        if system_injections:
            injection_text = "\n\n---\n**CURRENT STATUS:**\n" + "\n\n".join(system_injections)
            messages[0]["content"] += injection_text
            logger.info(f"[{self.name}] Injected {len(system_injections)} [SYSTEM] message(s) into system prompt")

        if system_injections:
            injection_text = "\n\n---\n**CURRENT STATUS:**\n" + "\n\n".join(system_injections)
            messages[0]["content"] += injection_text
            logger.info(f"[{self.name}] Injected {len(system_injections)} [SYSTEM] message(s) into system prompt")

        return messages

    async def _handle_tool_followup(self, messages, tool_call, result_content) -> Optional[str]:
        """Helper to handle tool follow-up calls (re-prompting with result)."""
        try:
            follow_up_messages = list(messages)
            follow_up_messages.append({
                "role": "assistant",
                "content": None,
                "tool_calls": [{"id": tool_call.id, "type": "function", "function": {"name": tool_call.function.name, "arguments": tool_call.function.arguments}}]
            })
            follow_up_messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": result_content
            })
            
            follow_up_client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=self.openrouter_api_key
            )
            
            response = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: follow_up_client.chat.completions.create(
                        model=self.model,
                        messages=follow_up_messages,
                        max_tokens=self.max_tokens
                    )
                ),
                timeout=60.0
            )
            
            if response.choices:
                final_text = response.choices[0].message.content
                if final_text:
                    return final_text.strip()
        except Exception as e:
            logger.error(f"[{self.name}] Error in tool follow-up: {e}")
            return f"[System: Tool execution completed. Result length: {len(result_content)} chars]"
        
        return None

    async def _call_llm_with_retrieval(self, messages: List[Dict], recent_messages: List[Dict]) -> str:

        """
        Call LLM API and handle [RETRIEVE] commands if present.

        Makes the initial API call, checks for retrieval requests, and re-prompts
        with retrieved context if needed.

        Args:
            messages: Formatted conversation messages for API
            recent_messages: Recent conversation context for retrieval

        Returns:
            Final response text with [RETRIEVE] tags removed
        """
        logger.info(f"[{self.name}] Calling OpenRouter API with model: {self.model}, max_tokens: {self.max_tokens}")
        client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=self.openrouter_api_key
        )

        # Get game context manager reference
        game_context_manager = None
        if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
            game_context_manager = getattr(self._agent_manager_ref, 'game_context', None)

        # Get context-aware tools (chat mode vs game mode)
        tools = None
        try:
            if GAMES_AVAILABLE:
                from agent_games.tool_schemas import get_tools_for_context
                self_reflect_avail = self.is_self_reflection_available()
                tools = get_tools_for_context(
                    agent_name=self.name,
                    game_context_manager=game_context_manager,
                    is_spectator=False,  # TODO: Detect spectator status
                    video_enabled=self.allow_spontaneous_videos,
                    video_duration=self.video_duration,
                    self_reflection_available=self_reflect_avail,
                    productivity_enabled=True
                )
                if tools:
                    tool_names = [t.get('function', {}).get('name', 'unknown') for t in tools]
                    logger.info(f"[{self.name}] Using {len(tools)} tool(s): {tool_names} (self_reflection={self_reflect_avail})")
        except Exception as e:
            logger.warning(f"[{self.name}] Could not load tool schemas: {e}")

        # Initial API call with tools
        api_kwargs = {
            "model": self.model,
            "messages": messages,
            "max_tokens": self.max_tokens
        }
        if tools:
            api_kwargs["tools"] = tools

            # CRITICAL: If agent is in game mode, REQUIRE tool use (not optional)
            # This prevents agents from sending commentary instead of making moves
            if game_context_manager and game_context_manager.is_in_game(self.name):
                api_kwargs["tool_choice"] = "required"
                logger.info(f"[{self.name}] Tool choice set to REQUIRED (in game mode)")
            else:
                api_kwargs["tool_choice"] = "auto"

        # API call with timeout and retry logic
        # This prevents the game from hanging if the API call fails/hangs
        API_TIMEOUT_SECONDS = 60  # 60 second timeout per attempt
        MAX_RETRIES = 2  # Retry up to 2 times on failure

        response = None
        last_error = None

        for attempt in range(MAX_RETRIES + 1):
            try:
                if attempt > 0:
                    logger.info(f"[{self.name}] Retry attempt {attempt}/{MAX_RETRIES}...")
                    await asyncio.sleep(1)  # Brief pause before retry

                response = await asyncio.wait_for(
                    asyncio.get_event_loop().run_in_executor(
                        None,
                        lambda: client.chat.completions.create(**api_kwargs)
                    ),
                    timeout=API_TIMEOUT_SECONDS
                )
                break  # Success - exit retry loop

            except asyncio.TimeoutError:
                last_error = f"API call timed out after {API_TIMEOUT_SECONDS}s"
                logger.warning(f"[{self.name}] {last_error} (attempt {attempt + 1}/{MAX_RETRIES + 1})")
            except Exception as e:
                last_error = str(e)
                logger.warning(f"[{self.name}] API call failed: {e} (attempt {attempt + 1}/{MAX_RETRIES + 1})")

        if response is None:
            raise RuntimeError(f"{self.name}: API call failed after {MAX_RETRIES + 1} attempts. Last error: {last_error}")

        logger.info(f"[{self.name}] Received API response")

        # Check response validity
        if not response.choices or len(response.choices) == 0:
            # Log what we got for debugging
            try:
                response_dict = response.model_dump() if hasattr(response, 'model_dump') else str(response)
                logger.error(f"[{self.name}] API returned no choices. Full response: {response_dict}")
            except (TypeError, AttributeError, ValueError):
                logger.error(f"[{self.name}] API returned no choices (could not serialize response)")

            # Check if this might be a tool_choice issue - retry without required tool choice
            if api_kwargs.get('tool_choice') == 'required':
                logger.warning(f"[{self.name}] Retrying without required tool_choice...")
                api_kwargs_retry = api_kwargs.copy()
                api_kwargs_retry.pop('tool_choice', None)
                try:
                    retry_response = await asyncio.wait_for(
                        asyncio.get_event_loop().run_in_executor(
                            None,
                            lambda: client.chat.completions.create(**api_kwargs_retry)
                        ),
                        timeout=API_TIMEOUT_SECONDS
                    )
                    if retry_response.choices and len(retry_response.choices) > 0:
                        logger.info(f"[{self.name}] Retry without tool_choice succeeded")
                        response = retry_response
                    else:
                        raise ValueError(f"{self.name}: API returned no choices even after retry")
                except Exception as retry_e:
                    logger.error(f"[{self.name}] Retry failed: {retry_e}")
                    raise ValueError(f"{self.name}: API returned no choices in response")
            else:
                raise ValueError(f"{self.name}: API returned no choices in response")

        choice = response.choices[0]
        message = choice.message

        # Log finish_reason and refusal for debugging
        finish_reason = getattr(choice, 'finish_reason', None)
        logger.debug(f"[{self.name}] Finish reason: {finish_reason}")

        if hasattr(message, 'refusal') and message.refusal:
            logger.error(f"[{self.name}] Model refused to respond: {message.refusal}")
            raise ValueError(f"{self.name} refused to respond: {message.refusal}")

        # Handle tool calls if present
        if hasattr(message, 'tool_calls') and message.tool_calls:
            logger.info(f"[{self.name}] Received {len(message.tool_calls)} tool call(s)")

            # Process the first tool call (models typically make one at a time)
            tool_call = message.tool_calls[0]
            function_name = tool_call.function.name

            # Parse tool call arguments with error handling for malformed JSON
            try:
                function_args = json.loads(tool_call.function.arguments)
            except json.JSONDecodeError as e:
                logger.warning(f"[{self.name}] Malformed JSON in tool call arguments: {e}")
                logger.warning(f"[{self.name}] Raw arguments: {tool_call.function.arguments}")
                # Try to extract essential data from malformed JSON
                import re
                raw_args = tool_call.function.arguments
                function_args = {}
                # Try to find coordinate/move/position patterns
                if function_name == "attack_coordinate":
                    coord_match = re.search(r'["\']?([A-Ja-j](?:10|[1-9]))["\']?', raw_args)
                    if coord_match:
                        function_args = {"coordinate": coord_match.group(1)}
                elif function_name == "make_chess_move":
                    move_match = re.search(r'["\']?([a-h][1-8][a-h][1-8][qrbn]?)["\']?', raw_args)
                    if move_match:
                        function_args = {"move": move_match.group(1)}
                elif function_name == "place_piece":
                    pos_match = re.search(r'["\']?([1-9])["\']?', raw_args)
                    if pos_match:
                        function_args = {"position": int(pos_match.group(1))}
                elif function_name == "drop_piece":
                    col_match = re.search(r'["\']?([1-7])["\']?', raw_args)
                    if col_match:
                        function_args = {"column": int(col_match.group(1))}
                elif function_name in ("guess_letter", "guess_word"):
                    word_match = re.search(r'["\']?([a-zA-Z]+)["\']?', raw_args)
                    if word_match:
                        key = "letter" if function_name == "guess_letter" else "word"
                        function_args = {key: word_match.group(1)}

                if not function_args:
                    logger.error(f"[{self.name}] Could not extract args from malformed JSON, using fallback")
                    function_args = {}

            logger.info(f"[{self.name}] Tool call: {function_name}({function_args})")

            # RACE CONDITION CHECK: If agent entered game mode AFTER this response started generating,
            # but the response contains a chat-mode tool call (like generate_image/generate_video), discard it
            if function_name in ("generate_image", "generate_video") and game_context_manager and game_context_manager.is_in_game(self.name):
                logger.warning(f"[{self.name}] Discarding stale {function_name} tool call - agent is now in game mode")
                return None

            # SPECIAL HANDLING: generate_image tool call from non-image model
            # Actually generate the image instead of just returning [IMAGE] text
            if function_name == "generate_image":
                image_prompt = function_args.get("prompt", "")
                reasoning = function_args.get("reasoning", "")

                # GATE: If agent is NOT allowed to spontaneously generate images,
                # only allow if a user explicitly requested an image
                if not self.allow_spontaneous_images:
                    # Look for image request keywords in recent user messages
                    image_request_patterns = [
                        'image', 'picture', 'photo', 'draw', 'sketch', 'paint',
                        'make me a', 'make an', 'show me a', 'show me an',
                        'create a', 'create an', 'generate a', 'generate an',
                        'visualize', 'illustration', 'artwork', 'depict'
                    ]
                    user_requested_image = False
                    for msg in recent_messages[-10:]:  # Check last 10 messages
                        if msg.get('role') == 'user':
                            content = msg.get('content', '').lower()
                            if any(pattern in content for pattern in image_request_patterns):
                                user_requested_image = True
                                break

                    if not user_requested_image:
                        logger.warning(f"[{self.name}] Blocked spontaneous image generation - allow_spontaneous_images=False and no user request detected")
                        # Return any text content the model produced, but skip the image
                        text_content = message.content if hasattr(message, 'content') and message.content else ""
                        if text_content.strip():
                            import re
                            clean_text = text_content.strip()
                            clean_text = re.sub(r'\[SENTIMENT:\s*-?\d+\]\s*', '', clean_text)
                            clean_text = re.sub(r'\[IMPORTANCE:\s*\d+\]\s*', '', clean_text)
                            clean_text = clean_text.strip()
                            return clean_text if clean_text else None
                        return None

                # Check if model also generated text content alongside the tool call
                # This text should be sent as a message before/after the image
                text_content = message.content if hasattr(message, 'content') and message.content else ""

                if image_prompt and hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                    logger.info(f"[{self.name}] Agent called generate_image tool - spawning image generation in background...")

                    # Update image request timestamp
                    self.last_image_request_time = time.time()

                    # Prepare commentary from text content only (reasoning is internal, not for display)
                    commentary = text_content.strip() if text_content.strip() else None
                    if commentary:
                        import re
                        commentary = re.sub(r'\[SENTIMENT:\s*-?\d+\]\s*', '', commentary)
                        commentary = re.sub(r'\[IMPORTANCE:\s*\d+\]\s*', '', commentary)
                        commentary = re.sub(r'\[MISSING CONTEXT[^\]]*\]\s*', '', commentary)
                        commentary = re.sub(r'\[NO RESPONSE[^\]]*\]\s*', '', commentary, flags=re.IGNORECASE)
                        commentary = re.sub(r'\[SKIP[^\]]*\]\s*', '', commentary, flags=re.IGNORECASE)
                        commentary = re.sub(r'\[CONTEXT[^\]]*\]\s*', '', commentary, flags=re.IGNORECASE)
                        commentary = commentary.strip()

                    # Spawn background task to generate and post image
                    # This allows the agent to continue while image generates
                    asyncio.create_task(self._generate_and_post_image(image_prompt, ""))
                    logger.info(f"[{self.name}] Image generation spawned in background via tool call")

                    # Return the agent's in-character response (from reasoning or text content)
                    # If no commentary, return None - no need to announce image generation
                    return commentary if commentary else None
                else:
                    logger.warning(f"[{self.name}] generate_image tool called but no prompt or agent_manager_ref")
                    return None

            # SPECIAL HANDLING: generate_video tool call
            # Generate video in background (same as user-requested [VIDEO] tag)
            if function_name == "generate_video":
                video_prompt = function_args.get("prompt", "")
                reasoning = function_args.get("reasoning", "")

                # GATE: If agent is NOT allowed to spontaneously generate videos,
                # only allow if a user explicitly requested a video
                if not self.allow_spontaneous_videos:
                    # Look for video request keywords in recent user messages
                    video_request_patterns = [
                        'video', 'clip', 'animation', 'movie', 'film',
                        'make me a', 'make a', 'show me a', 'show me an',
                        'create a', 'create an', 'generate a', 'generate an',
                        'record', 'footage', 'motion'
                    ]
                    user_requested_video = False
                    for msg in recent_messages[-10:]:  # Check last 10 messages
                        if msg.get('role') == 'user':
                            content = msg.get('content', '').lower()
                            if any(pattern in content for pattern in video_request_patterns):
                                user_requested_video = True
                                break

                    if not user_requested_video:
                        logger.warning(f"[{self.name}] Blocked spontaneous video generation - allow_spontaneous_videos=False and no user request detected")
                        # Return any text content the model produced, but skip the video
                        text_content = message.content if hasattr(message, 'content') and message.content else ""
                        if text_content.strip():
                            import re
                            clean_text = text_content.strip()
                            clean_text = re.sub(r'\[SENTIMENT:\s*-?\d+\]\s*', '', clean_text)
                            clean_text = re.sub(r'\[IMPORTANCE:\s*\d+\]\s*', '', clean_text)
                            clean_text = clean_text.strip()
                            return clean_text if clean_text else None
                        return None

                # Check if model also generated text content alongside the tool call
                text_content = message.content if hasattr(message, 'content') and message.content else ""

                if video_prompt and hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                    logger.info(f"[{self.name}] Agent called generate_video tool - spawning video generation in background...")

                    # Update video request timestamp
                    self.last_video_request_time = time.time()

                    # Spawn background task to generate and post video
                    # This allows the agent to continue while video generates (takes up to 10 minutes)
                    asyncio.create_task(self._generate_and_post_video(video_prompt, ""))
                    logger.info(f"[{self.name}] Video generation spawned in background via tool call")

                    # Return text content as the agent's message (reasoning is internal, not for display)
                    # Video will be posted by background task when complete
                    commentary = text_content.strip() if text_content.strip() else None
                    if commentary:
                        import re
                        commentary = re.sub(r'\[SENTIMENT:\s*-?\d+\]\s*', '', commentary)
                        commentary = re.sub(r'\[IMPORTANCE:\s*\d+\]\s*', '', commentary)
                        commentary = re.sub(r'\[MISSING CONTEXT[^\]]*\]\s*', '', commentary)
                        commentary = re.sub(r'\[NO RESPONSE[^\]]*\]\s*', '', commentary, flags=re.IGNORECASE)
                        commentary = re.sub(r'\[SKIP[^\]]*\]\s*', '', commentary, flags=re.IGNORECASE)
                        commentary = re.sub(r'\[CONTEXT[^\]]*\]\s*', '', commentary, flags=re.IGNORECASE)
                        commentary = commentary.strip()
                        if commentary:
                            return commentary
                    # If no text content, don't send a message - just generate silently
                    return None
                else:
                    logger.warning(f"[{self.name}] generate_video tool called but no prompt or agent_manager_ref")
                    return None

            # SPECIAL HANDLING: view_own_prompt tool call (self-reflection)
            if function_name == "view_own_prompt":
                # Verify self-reflection is actually available (model may hallucinate tool calls)
                if not self.is_self_reflection_available():
                    logger.warning(f"[{self.name}] Rejected view_own_prompt - self-reflection unavailable (cooldown or disabled)")
                    # Return any text content or None to let agent respond normally next turn
                    text_content = message.content if hasattr(message, 'content') and message.content else ""
                    return text_content.strip() if text_content.strip() else None

                logger.info(f"[{self.name}] Agent viewing own prompt for self-reflection")
                prompt_view = self.execute_view_own_prompt()

                # The prompt view is returned to the agent as a tool result, not posted to Discord
                # We need to make another API call with the prompt view as context
                # For now, just log and return any text content the model produced
                text_content = message.content if hasattr(message, 'content') and message.content else ""

                # Continue the conversation with the prompt view as context
                # This allows the agent to see their prompt and potentially make a follow-up request_self_change
                try:
                    # Make a follow-up call with the prompt view
                    follow_up_messages = list(messages)  # Copy the messages list
                    follow_up_messages.append({
                        "role": "assistant",
                        "content": None,
                        "tool_calls": [{"id": tool_call.id, "type": "function", "function": {"name": "view_own_prompt", "arguments": "{}"}}]
                    })
                    follow_up_messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": prompt_view
                    })

                    # Make follow-up API call using same OpenAI client pattern
                    follow_up_client = OpenAI(
                        base_url="https://openrouter.ai/api/v1",
                        api_key=self.openrouter_api_key
                    )
                    follow_up_kwargs = {
                        "model": self.model,
                        "messages": follow_up_messages,
                        "max_tokens": self.max_tokens
                    }
                    if tools:
                        follow_up_kwargs["tools"] = tools
                        follow_up_kwargs["tool_choice"] = "auto"

                    follow_up_response = await asyncio.wait_for(
                        asyncio.get_event_loop().run_in_executor(
                            None,
                            lambda: follow_up_client.chat.completions.create(**follow_up_kwargs)
                        ),
                        timeout=60.0
                    )

                    if follow_up_response.choices:
                        follow_up_message = follow_up_response.choices[0].message

                        # Check if follow-up contains request_self_change
                        if hasattr(follow_up_message, 'tool_calls') and follow_up_message.tool_calls:
                            for tc in follow_up_message.tool_calls:
                                if tc.function.name == "request_self_change":
                                    # Handle the self-change
                                    args = json.loads(tc.function.arguments)
                                    success, result_msg = self.execute_self_change(
                                        action=args.get("action", ""),
                                        line_number=args.get("line_number"),
                                        new_content=args.get("new_content"),
                                        reason=args.get("reason", "")
                                    )
                                    if success:
                                        logger.info(f"[{self.name}] Self-reflection complete: {result_msg}")
                                    else:
                                        logger.warning(f"[{self.name}] Self-reflection failed: {result_msg}")

                        # Return the agent's response text (their natural reflection)
                        follow_up_text = follow_up_message.content if follow_up_message.content else ""
                        if follow_up_text:
                            return follow_up_text.strip()

                        # If follow-up had tool calls but no text, make a third call to get conversational response
                        if hasattr(follow_up_message, 'tool_calls') and follow_up_message.tool_calls:
                            logger.info(f"[{self.name}] Self-reflection produced tool call but no text, requesting verbal response")
                            # Build messages including the tool result
                            final_messages = list(follow_up_messages)
                            # Add the tool call and result
                            for tc in follow_up_message.tool_calls:
                                final_messages.append({
                                    "role": "assistant",
                                    "content": None,
                                    "tool_calls": [{"id": tc.id, "type": "function", "function": {"name": tc.function.name, "arguments": tc.function.arguments}}]
                                })
                                final_messages.append({
                                    "role": "tool",
                                    "tool_call_id": tc.id,
                                    "content": "Change processed. Now express this moment naturally in character."
                                })

                            # Third call - no tools, just get text
                            final_response = await asyncio.wait_for(
                                asyncio.get_event_loop().run_in_executor(
                                    None,
                                    lambda: follow_up_client.chat.completions.create(
                                        model=self.model,
                                        messages=final_messages,
                                        max_tokens=self.max_tokens
                                    )
                                ),
                                timeout=60.0
                            )
                            if final_response.choices:
                                final_text = final_response.choices[0].message.content
                                if final_text:
                                    return final_text.strip()

                except Exception as e:
                    logger.error(f"[{self.name}] Error in self-reflection follow-up: {e}", exc_info=True)

                # Return any text from the original call
                if text_content.strip():
                    return text_content.strip()
                return None

            # SPECIAL HANDLING: request_self_change tool call (direct self-modification)
            if function_name == "request_self_change":
                # Verify self-reflection is actually available (model may hallucinate tool calls)
                if not self.is_self_reflection_available():
                    logger.warning(f"[{self.name}] Rejected request_self_change - self-reflection unavailable (cooldown or disabled)")
                    text_content = message.content if hasattr(message, 'content') and message.content else ""
                    return text_content.strip() if text_content.strip() else None

                action = function_args.get("action", "")
                line_number = function_args.get("line_number")
                new_content = function_args.get("new_content")
                reason = function_args.get("reason", "")

                logger.info(f"[{self.name}] Direct self-change request: {action}")

                success, result_msg = self.execute_self_change(action, line_number, new_content, reason)

                if success:
                    logger.info(f"[{self.name}] Self-change successful: {result_msg}")
                else:
                    logger.warning(f"[{self.name}] Self-change failed: {result_msg}")

                # Return any accompanying text (their natural expression of the change)
                text_content = message.content if hasattr(message, 'content') and message.content else ""
                if text_content.strip():
                    return text_content.strip()

                # If no text, they might want to express something about their change
                # Return None and let them speak naturally next turn
                # If no text, they might want to express something about their change
                # Return None and let them speak naturally next turn
                return None

            # SPECIAL HANDLING: search_web tool call
            if function_name == "search_web":
                query = function_args.get("query", "")
                reasoning = function_args.get("reasoning", "")
                
                logger.info(f"[{self.name}] Executing web search: {query}")
                search_result = await self.execute_web_search(query)
                
                # Verify if agent also generated text to show user
                text_content = message.content if hasattr(message, 'content') and message.content else ""
                
                # Re-prompt with search results (similar to view_own_prompt pattern)
                try:
                    # Make a follow-up call with the search results
                    follow_up_messages = list(messages)
                    follow_up_messages.append({
                        "role": "assistant",
                        "content": None,
                        "tool_calls": [{"id": tool_call.id, "type": "function", "function": {"name": "search_web", "arguments": json.dumps(function_args)}}]
                    })
                    follow_up_messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": search_result
                    })
                    
                    # Third call - get natural response incorporating search results
                    follow_up_client = OpenAI(
                        base_url="https://openrouter.ai/api/v1",
                        api_key=self.openrouter_api_key
                    )
                    
                    search_response = await asyncio.wait_for(
                        asyncio.get_event_loop().run_in_executor(
                            None,
                            lambda: follow_up_client.chat.completions.create(
                                model=self.model,
                                messages=follow_up_messages,
                                max_tokens=self.max_tokens
                            )
                        ),
                        timeout=60.0
                    )
                    
                    if search_response.choices:
                        final_text = search_response.choices[0].message.content
                        if final_text:
                            return final_text.strip()
                            
                except Exception as e:
                    logger.error(f"[{self.name}] Error in search follow-up: {e}")
                    if text_content:
                        return text_content + f"\n\n[System: Search completed: {query}]"
                
                return None  # Should have returned above
            
            # SPECIAL HANDLING: read_file tool call
            if function_name == "read_file":
                path = function_args.get("path", "")
                logger.info(f"[{self.name}] Reading file: {path}")
                file_content = self.execute_read_file(path)
                
                # Re-prompt loop
                return await self._handle_tool_followup(messages, tool_call, file_content)

            # SPECIAL HANDLING: list_files tool call
            if function_name == "list_files":
                path = function_args.get("path", "")
                logger.info(f"[{self.name}] Listing files: {path}")
                dir_content = self.execute_list_files(path)
                
                # Re-prompt loop
                return await self._handle_tool_followup(messages, tool_call, dir_content)

            # Convert tool call to message format
            try:

                from agent_games.tool_schemas import convert_tool_call_to_message
                move, commentary = convert_tool_call_to_message(function_name, function_args)
                full_response = move  # Use move as main response
                # Store commentary separately to send as follow-up message
                if not hasattr(self, '_pending_commentary'):
                    self._pending_commentary = None
                self._pending_commentary = commentary if commentary else None
                logger.info(f"[{self.name}] Converted tool call to move: {move}" +
                           (f" (commentary: {commentary[:50]}...)" if commentary else ""))
            except Exception as e:
                logger.error(f"[{self.name}] Error converting tool call: {e}")
                full_response = message.content or ""
                self._pending_commentary = None
        else:
            # Normal text response
            full_response = message.content or ""
            self._pending_commentary = None
            if full_response:
                logger.info(f"[{self.name}] Raw response: {full_response[:100]}...")

            # SIMPLE CATCH-ALL: If "generate_image" appears anywhere, handle it
            if 'generate_image' in full_response:
                logger.info(f"[{self.name}] Detected generate_image in response - extracting and stripping")

                # Extract text BEFORE generate_image (the actual message)
                pre_image_text = full_response.split('generate_image')[0].strip()

                # Try to extract the JSON prompt from various formats
                import re
                prompt_match = re.search(
                    r'generate_image\s*\(?[^{]*(\{[\s\S]*?\})\s*\)?',
                    full_response,
                    re.DOTALL
                )

                if prompt_match:
                    try:
                        args = json.loads(prompt_match.group(1))
                        image_prompt = args.get('prompt', '')

                        if image_prompt:
                            # GATE: Check if allowed to spontaneously generate images
                            should_generate = self.allow_spontaneous_images
                            if not should_generate:
                                # Check if user requested an image
                                image_patterns = ['image', 'picture', 'photo', 'draw', 'sketch', 'paint',
                                                 'make me', 'show me', 'create', 'generate', 'visualize']
                                for msg in recent_messages[-10:]:
                                    if msg.get('role') == 'user':
                                        content = msg.get('content', '').lower()
                                        if any(p in content for p in image_patterns):
                                            should_generate = True
                                            break

                            if should_generate:
                                logger.info(f"[{self.name}] Generating image: {image_prompt[:80]}...")
                                self.last_image_request_time = time.time()
                                if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                                    asyncio.create_task(self._agent_manager_ref.generate_image(image_prompt, self.name))
                            else:
                                logger.warning(f"[{self.name}] Blocked spontaneous image - not allowed")
                    except json.JSONDecodeError as e:
                        logger.warning(f"[{self.name}] Failed to parse generate_image JSON: {e}")

                # Use only the pre-image text as the response
                full_response = pre_image_text
                logger.info(f"[{self.name}] Stripped generate_image, remaining: {full_response[:100] if full_response else '(empty)'}...")

                # If nothing left, return None
                if not full_response:
                    return None

            # Check for DeepSeek's custom tool call format (multiple possible formats):
            # Format 1: <tool_call_begin>function<tool_sep>NAME...
            # Format 2: function<toolsep>NAME {...} <toolcallend><toolcallsend>
            deepseek_markers = [
                '<tool_call_begin>', '<tool_call_end>',
                'function<toolsep>', '<toolcallend>', '<toolcallsend>',
                'function<|toolsep|>', '<|toolcallend|>', '<|toolcallsend|>'
            ]
            has_deepseek_format = any(marker in full_response for marker in deepseek_markers)

            if has_deepseek_format:
                try:
                    logger.info(f"[{self.name}] Detected DeepSeek tool call format - parsing...")

                    # Extract the tool call content - try multiple patterns
                    import re

                    # Pattern 1: Original format with angle brackets and separator
                    tool_call_match = re.search(
                        r'<tool_call_begin>function<tool_sep>(\w+)\s*```json\s*(\{.*?\})\s*```<tool_call_end>',
                        full_response,
                        re.DOTALL
                    )

                    # Pattern 1b: Format WITHOUT separator (functionNAME directly)
                    if not tool_call_match:
                        tool_call_match = re.search(
                            r'<tool_call_begin>function(\w+)\s*```json\s*(\{.*?\})\s*```',
                            full_response,
                            re.DOTALL
                        )

                    # Pattern 2: Unicode separator format ( and )
                    if not tool_call_match:
                        tool_call_match = re.search(
                            r'function[<\|]tool[\u2581]sep[\|>](\w+)\s*(\{[^}]+\})',
                            full_response,
                            re.DOTALL
                        )

                    # Pattern 3: Simpler JSON extraction after generate_image
                    if not tool_call_match:
                        tool_call_match = re.search(
                            r'function.*?generate_image\s*(\{[^}]+\})',
                            full_response,
                            re.DOTALL
                        )
                        if tool_call_match:
                            # Fake the function name match
                            tool_call_match = type('Match', (), {
                                'group': lambda s, n: 'generate_image' if n == 1 else tool_call_match.group(1)
                            })()

                    # Pattern 4: Direct generate_image({...}) call (no function prefix)
                    is_direct_call_pattern = False
                    if not tool_call_match:
                        direct_call_match = re.search(
                            r'generate_image\s*\(\s*(\{[\s\S]*?\})\s*\)',
                            full_response,
                            re.DOTALL
                        )
                        if direct_call_match:
                            is_direct_call_pattern = True
                            tool_call_match = type('Match', (), {
                                'group': lambda s, n: 'generate_image' if n == 1 else direct_call_match.group(1)
                            })()

                    if tool_call_match:
                        function_name = tool_call_match.group(1)
                        function_args_str = tool_call_match.group(2)
                        function_args = json.loads(function_args_str)

                        logger.info(f"[{self.name}] Parsed DeepSeek tool call: {function_name}({function_args})")

                        # RACE CONDITION CHECK: If agent entered game mode AFTER this response started generating,
                        # but the response contains a chat-mode tool call (like generate_image), discard it
                        if function_name == 'generate_image' and game_context_manager and game_context_manager.is_in_game(self.name):
                            logger.warning(f"[{self.name}] Discarding stale DeepSeek generate_image tool call - agent is now in game mode")
                            return None

                        # Handle generate_image specially
                        if function_name == 'generate_image' and 'prompt' in function_args:
                            # GATE: If agent is NOT allowed to spontaneously generate images,
                            # only allow if a user explicitly requested an image
                            should_block = False
                            if not self.allow_spontaneous_images:
                                image_request_patterns = [
                                    'image', 'picture', 'photo', 'draw', 'sketch', 'paint',
                                    'make me a', 'make an', 'show me a', 'show me an',
                                    'create a', 'create an', 'generate a', 'generate an',
                                    'visualize', 'illustration', 'artwork', 'depict'
                                ]
                                user_requested_image = False
                                for msg in recent_messages[-10:]:
                                    if msg.get('role') == 'user':
                                        content = msg.get('content', '').lower()
                                        if any(pattern in content for pattern in image_request_patterns):
                                            user_requested_image = True
                                            break
                                if not user_requested_image:
                                    logger.warning(f"[{self.name}] Blocked DeepSeek spontaneous image generation - allow_spontaneous_images=False and no user request detected")
                                    should_block = True

                            # Extract any text before the tool call as the message
                            if is_direct_call_pattern:
                                # Pattern 4: split on generate_image( directly
                                pre_tool_text = re.split(r'generate_image\s*\(', full_response)[0].strip()
                            else:
                                # Other patterns: split on function marker
                                pre_tool_text = re.split(r'function[<\|]', full_response)[0].strip()
                            if pre_tool_text:
                                # Agent said something AND called generate_image
                                if not should_block:
                                    # Use generate_image tool to create image
                                    image_prompt = function_args['prompt']
                                    logger.info(f"[{self.name}] DeepSeek spontaneous image with text: {pre_tool_text[:50]}...")

                                    # Update image request timestamp so agent knows it made an image
                                    self.last_image_request_time = time.time()

                                    # Try to generate the image
                                    if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                                        asyncio.create_task(self._agent_manager_ref.generate_image(image_prompt, self.name))

                                full_response = pre_tool_text
                            else:
                                # Just the tool call - treat as [IMAGE] tag (only if not blocked)
                                if not should_block:
                                    full_response = f"[IMAGE] {function_args['prompt']}"
                                else:
                                    full_response = ""  # Block the image, no text to return
                        else:
                            # Other tool calls - convert to message format
                            from agent_games.tool_schemas import convert_tool_call_to_message
                            move, commentary = convert_tool_call_to_message(function_name, function_args)
                            full_response = move
                            self._pending_commentary = commentary if commentary else None
                            logger.info(f"[{self.name}] Converted DeepSeek tool call to move: {move}")
                    else:
                        logger.warning(f"[{self.name}] DeepSeek tool call markers found but couldn't parse content")
                        # Strip the malformed tool call syntax from the response
                        full_response = re.sub(
                            r'function[<\|].*?tool.*?[\|>].*?(<[\|].*?[\|>])+',
                            '',
                            full_response,
                            flags=re.DOTALL
                        ).strip()
                        logger.info(f"[{self.name}] Stripped malformed tool syntax, remaining: {full_response[:100]}...")
                except Exception as e:
                    logger.error(f"[{self.name}] Failed to parse DeepSeek tool call: {e}", exc_info=True)
                    # Strip the malformed syntax as fallback
                    full_response = re.sub(
                        r'function[<\|].*',
                        '',
                        full_response,
                        flags=re.DOTALL
                    ).strip()

            # Check for GLM's XML-style tool call format:
            # generate_video<arg_key>prompt</arg_key><arg_value>...</arg_value>...</tool_call>
            glm_xml_markers = ['<arg_key>', '<arg_value>', '</tool_call>']
            has_glm_xml_format = all(marker in full_response for marker in glm_xml_markers)

            if has_glm_xml_format:
                try:
                    import re
                    logger.info(f"[{self.name}] Detected GLM XML-style tool call format - parsing...")

                    # Extract function name (appears before first <arg_key>)
                    func_match = re.match(r'^([\w_]+)\s*<arg_key>', full_response.strip())
                    if func_match:
                        function_name = func_match.group(1)

                        # Extract all arg_key/arg_value pairs
                        function_args = {}
                        arg_pairs = re.findall(
                            r'<arg_key>(\w+)</arg_key>\s*<arg_value>(.*?)</arg_value>',
                            full_response,
                            re.DOTALL
                        )
                        for key, value in arg_pairs:
                            function_args[key.strip()] = value.strip()

                        logger.info(f"[{self.name}] Parsed GLM XML tool call: {function_name}({list(function_args.keys())})")

                        # RACE CONDITION CHECK: Discard if agent entered game mode
                        if function_name in ('generate_image', 'generate_video') and game_context_manager and game_context_manager.is_in_game(self.name):
                            logger.warning(f"[{self.name}] Discarding stale GLM {function_name} tool call - agent is now in game mode")
                            return None

                        # Handle generate_video
                        if function_name == 'generate_video' and 'prompt' in function_args:
                            video_prompt = function_args['prompt']
                            reasoning = function_args.get('reasoning', '')

                            # Check spontaneous video generation permissions
                            if self.allow_spontaneous_videos:
                                logger.info(f"[{self.name}] GLM spontaneous video: {video_prompt[:80]}...")

                                # Update video request timestamp
                                self.last_video_request_time = time.time()

                                # Trigger video generation
                                if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                                    asyncio.create_task(self._agent_manager_ref.generate_video(
                                        video_prompt, self.name, duration=self.video_duration
                                    ))

                                # Return reasoning as natural response (or strip entirely if no reasoning)
                                if reasoning:
                                    full_response = reasoning
                                else:
                                    full_response = ""
                            else:
                                logger.warning(f"[{self.name}] Blocked GLM spontaneous video - allow_spontaneous_videos=False")
                                full_response = reasoning if reasoning else ""

                        # Handle generate_image
                        elif function_name == 'generate_image' and 'prompt' in function_args:
                            image_prompt = function_args['prompt']
                            reasoning = function_args.get('reasoning', '')

                            if self.allow_spontaneous_images:
                                logger.info(f"[{self.name}] GLM spontaneous image: {image_prompt[:80]}...")
                                self.last_image_request_time = time.time()

                                if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                                    asyncio.create_task(self._agent_manager_ref.generate_image(image_prompt, self.name))

                                full_response = reasoning if reasoning else ""
                            else:
                                logger.warning(f"[{self.name}] Blocked GLM spontaneous image - allow_spontaneous_images=False")
                                full_response = reasoning if reasoning else ""

                        else:
                            # Other tool calls - convert to message format
                            from agent_games.tool_schemas import convert_tool_call_to_message
                            move, commentary = convert_tool_call_to_message(function_name, function_args)
                            full_response = move
                            self._pending_commentary = commentary if commentary else None
                            logger.info(f"[{self.name}] Converted GLM XML tool call to move: {move}")
                    else:
                        logger.warning(f"[{self.name}] GLM XML markers found but couldn't extract function name")
                        # Strip the tool call syntax
                        full_response = re.sub(r'[\w_]*<arg_key>.*</tool_call>', '', full_response, flags=re.DOTALL).strip()

                except Exception as e:
                    logger.error(f"[{self.name}] Failed to parse GLM XML tool call: {e}", exc_info=True)
                    # Strip malformed syntax as fallback
                    full_response = re.sub(r'<arg_key>.*</tool_call>', '', full_response, flags=re.DOTALL).strip()

            # CRITICAL: Strip metadata tags that some models add to responses
            # These tags break move detection and leak to Discord
            import re
            if full_response:
                original_response = full_response

                # Remove [SENTIMENT: X] and [IMPORTANCE: Y] tags (mistral-nemo style)
                full_response = re.sub(r'\[SENTIMENT:\s*-?\d+\]\s*', '', full_response)
                full_response = re.sub(r'\[IMPORTANCE:\s*\d+\]\s*', '', full_response)

                # Remove hallucinated meta-tags from DeepSeek and other models
                # e.g., [MISSING CONTEXT - NOTHING RECENT TO REPLY TO], [NO RESPONSE NEEDED], etc.
                full_response = re.sub(r'\[MISSING CONTEXT[^\]]*\]\s*', '', full_response)
                full_response = re.sub(r'\[NO RESPONSE[^\]]*\]\s*', '', full_response, flags=re.IGNORECASE)
                full_response = re.sub(r'\[SKIP[^\]]*\]\s*', '', full_response, flags=re.IGNORECASE)
                full_response = re.sub(r'\[CONTEXT[^\]]*\]\s*', '', full_response, flags=re.IGNORECASE)

                # Remove cooldown warning echoes that LLMs sometimes repeat from the prompt
                full_response = re.sub(r'\s*YOU RECENTLY MADE (?:AN IMAGE|A VIDEO)[^]*\s*', '', full_response, flags=re.IGNORECASE)
                full_response = re.sub(r'\*\*[^]*\*\*\s*', '', full_response)

                full_response = full_response.strip()
                if full_response and full_response != original_response.strip():
                    logger.info(f"[{self.name}] Stripped metadata tags, clean response: {full_response[:100]}...")

            # CRITICAL: Check if response is empty after stripping (model error)
            if not full_response or len(full_response) == 0:
                error_msg = f"[{self.name}] Model returned empty response after stripping tags!"
                logger.error(error_msg)

                # If in game mode, this is critical - model must make a move
                if game_context_manager and game_context_manager.is_in_game(self.name):
                    logger.error(f"[{self.name}] IN GAME MODE - model failed to make a move")
                    raise ValueError(f"{self.name} returned empty response during game - model may not support tool use properly")
                else:
                    full_response = "..." # Minimal response to avoid error
                    logger.warning(f"[{self.name}] Using fallback response to avoid empty message")

            # Fallback: Check if mistral-nemo outputted raw JSON function call
            if full_response.strip().startswith('[{') and '"name"' in full_response and '"arguments"' in full_response:
                try:
                    logger.warning(f"[{self.name}] Detected raw JSON function call from model - parsing manually")
                    tool_calls_json = json.loads(full_response.strip())
                    if tool_calls_json and len(tool_calls_json) > 0:
                        tool_call = tool_calls_json[0]
                        function_name = tool_call.get('name')
                        function_args = tool_call.get('arguments', {})

                        logger.info(f"[{self.name}] Parsed JSON tool call: {function_name}({function_args})")

                        # Convert to message format
                        from agent_games.tool_schemas import convert_tool_call_to_message
                        move, commentary = convert_tool_call_to_message(function_name, function_args)
                        full_response = move
                        self._pending_commentary = commentary if commentary else None
                        logger.info(f"[{self.name}] Converted JSON tool call to move: {move}")
                except Exception as e:
                    logger.error(f"[{self.name}] Failed to parse raw JSON function call: {e}")

        # Check for [RETRIEVE] commands and execute them
        response_without_retrieve, retrieved_context = await self.execute_retrievals(full_response, recent_messages)

        # If retrieval was performed, re-prompt with context
        if retrieved_context:
            logger.info(f"[{self.name}] Re-prompting with retrieved context...")

            # Build new prompt with retrieved context
            retrieval_prompt = f"""You requested to retrieve past memories. Here's what was found:

{retrieved_context}

Now, using this retrieved context, provide your final response to the conversation."""

            messages.append({"role": "user", "content": retrieval_prompt})

            # Get final response with context
            final_response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    max_tokens=self.max_tokens
                )
            )

            full_response = final_response.choices[0].message.content
            logger.info(f"[{self.name}] Final response with retrieval: {full_response[:100]}...")
            # Re-run retrieval cleanup on the final response
            response_without_retrieve, _ = await self.execute_retrievals(full_response, recent_messages)

        return response_without_retrieve

    async def _process_response_and_update_metadata(self, response_text: str, recent_messages: List[Dict],
                                                    shortcut_message: Optional[Dict] = None) -> tuple:
        """
        Process LLM response and update all metadata (affinity, importance, status).

        Handles:
        - Sentiment/importance extraction
        - [IMAGE] cooldown enforcement
        - Reply-to message ID determination
        - Affinity tracking updates
        - Vector store importance updates
        - Status and timestamp updates
        - Core memory checkpoint triggering

        Args:
            response_text: Raw response from LLM (without [RETRIEVE] tags)
            recent_messages: Recent conversation context
            shortcut_message: Optional shortcut message if responding to one

        Returns:
            Tuple of (clean_response, reply_to_message_id)
        """
        # Extract sentiment/importance from the cleaned response
        # Pass previous message for importance auto-scoring if tags not present
        previous_message = recent_messages[-1] if recent_messages else None
        clean_response, sentiment, importance = self.extract_sentiment_and_importance(response_text, previous_message)
        logger.info(f"[{self.name}] Extracted sentiment: {sentiment}, importance: {importance}")
        logger.info(f"[{self.name}] Clean response length: {len(clean_response)} chars")

        # Check for garbage/malformed responses (likely API issues or content filter artifacts)
        # Common patterns: "ext...", single word fragments, extremely short non-commands
        if len(clean_response) <= 10:
            # Allow certain short valid responses
            valid_short = ['yes', 'no', 'ok', 'okay', 'hi', 'hey', 'bye', 'lol', 'lmao', 'haha', 'sure', 'nice', 'cool', 'thanks', 'thx', '...', '..']
            clean_lower = clean_response.lower().strip('.')
            if clean_lower not in valid_short and not clean_response.startswith('['):
                logger.warning(f"[{self.name}] Garbage response detected ('{clean_response}') - likely API issue, skipping")
                return None

        # Prevent repeated [IMAGE] requests - strip [IMAGE] if agent used it recently
        if "[IMAGE]" in clean_response:
            current_time = time.time()
            time_since_last_image = current_time - self.last_image_request_time

            if time_since_last_image < self.global_image_cooldown:
                logger.info(f"[{self.name}] Stripping [IMAGE] from response - agent used [IMAGE] {time_since_last_image:.1f}s ago ({self.global_image_cooldown}s cooldown)")
                clean_response = clean_response.replace("[IMAGE]", "").strip()
            else:
                # Allow [IMAGE] and update timestamp
                self.last_image_request_time = current_time
                logger.info(f"[{self.name}] [IMAGE] request allowed - last used {time_since_last_image:.1f}s ago")

        # Handle [VIDEO] tag - detect, validate, and generate video
        if "[VIDEO]" in clean_response:
            current_time = time.time()
            time_since_last_video = current_time - self.last_video_request_time
            video_cooldown = 150  # 2.5 minutes

            if time_since_last_video < video_cooldown:
                logger.info(f"[{self.name}] Stripping [VIDEO] from response - agent used [VIDEO] {time_since_last_video:.1f}s ago ({video_cooldown}s cooldown)")
                clean_response = re.sub(r'\[VIDEO\].*', '', clean_response).strip()
                if not clean_response:
                    logger.info(f"[{self.name}] Response empty after video cooldown strip - skipping")
                    return None
            else:
                # Check if this is allowed (spontaneous enabled OR user requested)
                user_requested_video = False
                if not self.allow_spontaneous_videos:
                    # Look for video request keywords in recent user messages
                    video_request_patterns = [
                        'video', 'movie', 'clip', 'animate', 'animation',
                        'film', 'footage', 'motion', 'cinematic',
                        'make me a video', 'create a video', 'generate a video',
                        'show me a video', 'record', 'sora'
                    ]
                    for msg in recent_messages[-10:]:
                        if msg.get('role') == 'user':
                            content = msg.get('content', '').lower()
                            if any(pattern in content for pattern in video_request_patterns):
                                user_requested_video = True
                                break

                    if not user_requested_video:
                        logger.warning(f"[{self.name}] Blocked video generation - allow_spontaneous_videos=False and no user request detected")
                        clean_response = re.sub(r'\[VIDEO\].*', '', clean_response).strip()
                        if not clean_response:
                            logger.info(f"[{self.name}] Response empty after video blocked strip - skipping")
                            return None
                    else:
                        logger.info(f"[{self.name}] User requested video - generating...")
                else:
                    user_requested_video = False  # Spontaneous is allowed

                # If video is allowed, extract prompt and generate in background
                if self.allow_spontaneous_videos or user_requested_video:
                    # Extract video prompt (everything after [VIDEO])
                    video_match = re.search(r'\[VIDEO\]\s*(.+?)(?:\n|$)', clean_response, re.DOTALL)
                    if video_match:
                        video_prompt = video_match.group(1).strip()
                        if video_prompt and hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                            logger.info(f"[{self.name}] Spawning background video generation: {video_prompt[:100]}...")

                            # Mark video request time now (prevents rapid re-requests)
                            self.last_video_request_time = current_time

                            # Reset spontaneous counter if user requested
                            if user_requested_video:
                                self.spontaneous_video_counter = 0
                                logger.info(f"[{self.name}] Reset spontaneous_video_counter after user-requested video")

                            # Strip the [VIDEO] tag from response - remaining text is commentary
                            commentary = re.sub(r'\[VIDEO\]\s*.+?(?:\n|$)', '', clean_response).strip()

                            # Spawn background task to generate and post video with commentary
                            asyncio.create_task(self._generate_and_post_video(
                                video_prompt,
                                commentary
                            ))

                            # Mark the triggering message as responded BEFORE returning
                            # This prevents duplicate responses while video generates
                            if hasattr(self, '_pending_user_message_id') and self._pending_user_message_id:
                                if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                                    self._agent_manager_ref.mark_message_responded(self._pending_user_message_id, self.name)
                                self._pending_user_message_id = None
                            elif recent_messages:
                                last_msg_id = recent_messages[-1].get('message_id')
                                if last_msg_id and hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                                    self._agent_manager_ref.mark_message_responded(last_msg_id, self.name)

                            # Don't send anything now - video and commentary will be sent when ready
                            logger.info(f"[{self.name}] Video queued for background generation" +
                                       (f" with commentary: {commentary[:50]}..." if commentary else ""))
                            return None
                        else:
                            logger.warning(f"[{self.name}] Cannot generate video - no prompt or agent_manager_ref")
                            clean_response = re.sub(r'\[VIDEO\].*', '', clean_response).strip()
                            if not clean_response:
                                return None
                    else:
                        logger.warning(f"[{self.name}] [VIDEO] tag without prompt - stripping")
                        clean_response = re.sub(r'\[VIDEO\].*', '', clean_response).strip()
                        if not clean_response:
                            return None

        # Determine reply-to message and update metadata
        reply_to_message_id = None
        if recent_messages:
            last_message = recent_messages[-1]
            last_author = last_message['author']
            reply_to_message_id = last_message.get('message_id')

            # CRITICAL: Mark the correct message as responded
            # Priority order:
            # 1. Turn prompt (game mode)
            # 2. User message that triggered this response
            # 3. Default to the message we're replying to
            message_to_mark = reply_to_message_id

            if hasattr(self, '_pending_turn_prompt_id') and self._pending_turn_prompt_id:
                message_to_mark = self._pending_turn_prompt_id
                logger.info(f"[{self.name}] Using turn prompt message ID {message_to_mark} instead of reply target {reply_to_message_id}")
                # NOTE: Do NOT clear _pending_turn_prompt_id here - it's needed later to identify game moves
                # It will be cleared in the agent loop after the message is actually sent
            elif hasattr(self, '_pending_user_message_id') and self._pending_user_message_id:
                message_to_mark = self._pending_user_message_id
                if message_to_mark != reply_to_message_id:
                    logger.info(f"[{self.name}] Using user message ID {message_to_mark} instead of reply target {reply_to_message_id}")
                self._pending_user_message_id = None

            # Mark this message as responded globally
            if message_to_mark and hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                self._agent_manager_ref.mark_message_responded(message_to_mark, self.name)

            # Use startswith to handle webhook messages with model suffix
            # Skip affinity updates for:
            # - System entities (GameMaster)
            # - Self
            # - Non-users (celebrities in roasts, etc.) - detected by non-numeric user_id
            is_system = "GameMaster" in last_author or "(system)" in last_author
            last_user_id = last_message.get('user_id', '')
            is_real_user = last_user_id and last_user_id.isdigit()  # Real Discord IDs are numeric
            if self.affinity_tracker and not last_author.startswith(self.name) and not is_system and is_real_user:
                delta = self.affinity_tracker.update_affinity(self.name, last_author, sentiment)
                logger.info(f"[{self.name}] Updated affinity toward {last_author} (delta: {delta:+.1f})")
                # Flag significant affinity changes for introspection nudge
                if abs(delta) >= 15:
                    self._significant_affinity_change = (last_author, delta)
                    logger.info(f"[{self.name}] Significant affinity change detected toward {last_author}")
            elif not is_real_user and not is_system and not last_author.startswith(self.name):
                logger.debug(f"[{self.name}] Skipping affinity update for non-user {last_author} (user_id={last_user_id})")

            # Update importance rating for this message with agent's personalized score
            # This allows each agent to rate the same message differently based on their personality
            if self.vector_store and reply_to_message_id:
                self.vector_store.update_message_importance(
                    agent_name=self.name,
                    message_id=reply_to_message_id,
                    importance=importance
                )

        # Update agent status and timestamps
        self.status = "running"
        self.last_response_time = time.time()

        # Periodically check if we need to create core memory checkpoints
        # This runs async in the background and won't block response delivery
        asyncio.create_task(self.create_core_memory_checkpoint())

        return clean_response, reply_to_message_id

    def _build_system_prompt_with_context(self, recent_messages: List[Dict], vector_context: Dict, shortcut_message: Optional[Dict] = None) -> str:
        """
        Build comprehensive system prompt with all context additions.

        Args:
            recent_messages: Filtered conversation messages
            vector_context: Vector store context (preferences, core memories, etc.)
            shortcut_message: Optional shortcut message being responded to

        Returns:
            Complete system prompt string
        """
        # Use new component-based system if available
        if PROMPT_COMPONENTS_AVAILABLE:
            try:
                ctx = create_prompt_context(
                    agent=self,
                    recent_messages=recent_messages,
                    vector_context=vector_context,
                    shortcut_message=shortcut_message,
                    game_context_manager=game_context_manager if GAMES_AVAILABLE else None,
                    agent_manager_ref=self._agent_manager_ref if hasattr(self, '_agent_manager_ref') else None,
                    is_image_model_func=is_image_model
                )
                # Get status effects BEFORE building prompt so we can inject early
                recovery_prompt = StatusEffectManager.get_and_clear_recovery_prompt(self.name)
                effect_prompt = StatusEffectManager.get_effect_prompt(self.name)
                whisper_prompt = StatusEffectManager.get_whisper_prompt(self.name)

                # Pass status effects and whispers to context so they can be injected right after personality
                ctx.status_effect_prompt = effect_prompt
                ctx.recovery_prompt = recovery_prompt
                ctx.whisper_prompt = whisper_prompt

                # Set introspection nudge for key moments (recovery = coming down, good time for reflection)
                if recovery_prompt and self.is_self_reflection_available():
                    ctx.introspection_nudge = "You're coming down from something. This might be a good moment to reflect on who you are and who you want to be. Try `view_own_prompt` to see your core directives."

                # Post-game introspection nudge (after roasts, debates, etc.)
                if hasattr(self, '_post_game_introspection') and self._post_game_introspection:
                    game_name = self._post_game_introspection.replace("_", " ")
                    if self.is_self_reflection_available():
                        ctx.introspection_nudge = f"You just finished a {game_name}. Did anything said during the game resonate with you or change how you see yourself? Try `view_own_prompt` to reflect on your core identity."
                        logger.info(f"[{self.name}] Set post-game introspection nudge for {game_name}")
                    self._post_game_introspection = None  # Clear flag after use

                # Significant affinity change nudge
                if hasattr(self, '_significant_affinity_change') and self._significant_affinity_change:
                    target, delta = self._significant_affinity_change
                    if self.is_self_reflection_available():
                        direction = "warming up to" if delta > 0 else "cooling off from"
                        ctx.introspection_nudge = f"Your feelings toward {target} just shifted significantly. You're {direction} them. Does this reflect something about who you want to be? Try `view_own_prompt` to examine your values."
                        logger.info(f"[{self.name}] Set affinity change introspection nudge for {target} (delta: {delta:+.1f})")
                    self._significant_affinity_change = None  # Clear flag after use

                full_system_prompt = build_system_prompt(ctx)

                if recovery_prompt:
                    logger.info(f"[{self.name}] Injected recovery/sobering-up prompt (component path)")

                if effect_prompt:
                    logger.info(f"[{self.name}] Injected active status effect prompt (component path)")

                if whisper_prompt:
                    logger.info(f"[{self.name}] Injected divine whisper (component path)")

                return full_system_prompt
            except Exception as e:
                logger.error(f"[{self.name}] Error using component-based prompt system, falling back to legacy: {e}")
                # Fall through to legacy implementation

        # LEGACY IMPLEMENTATION (fallback if component system unavailable or errors)
        # Get other active agents context
        other_agents_context = ""
        if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
            try:
                all_agents = self._agent_manager_ref.get_all_agents()
                active_agent_names = [
                    agent.name for agent in all_agents
                    if agent.name != self.name and (agent.is_running or agent.status == "running")
                ]
                if active_agent_names:
                    other_agents_context = f"\n\nOther AI agents currently active in this channel: {', '.join(active_agent_names)}"
                    other_agents_context += "\nThese are fellow AI personalities, not humans. You can interact with them naturally."
                    other_agents_context += "\nIMPORTANT: ONLY these agents are currently active. Do NOT mention or address agents not in this list."
                    other_agents_context += "\n\n NO QUOTING: Respond in YOUR OWN words. Don't copy/paste other agents' messages."

                    # Add name collision guidance if multiple agents share a first name
                    if build_name_collision_guidance:
                        all_active_names = active_agent_names + [self.name]
                        collision_guidance = build_name_collision_guidance(all_active_names, self.name)
                        if collision_guidance:
                            other_agents_context += collision_guidance
            except Exception as e:
                logger.debug(f"[{self.name}] Could not get agent list for context: {e}")

        # Get affinity context
        affinity_context = ""
        if self.affinity_tracker:
            affinity_context = self.affinity_tracker.get_affinity_context(self.name)

        # Get tracked messages context
        tracked_messages_context = ""
        if self.affinity_tracker:
            tracked_users = self.affinity_tracker.get_all_tracked_users(self.name)
            if tracked_users:
                tracked_lines = ["\n\nRecent message history from specific individuals:"]
                for user in tracked_users:
                    user_msgs = self.affinity_tracker.get_message_history(self.name, user)
                    if user_msgs:
                        tracked_lines.append(f"\nLast messages from {user}:")
                        for msg in user_msgs:
                            tracked_lines.append(f"  - {msg}")
                tracked_messages_context = "\n".join(tracked_lines)

        # Build attention guidance
        user_focus = ""
        if self.user_attention >= 75:
            user_focus = "STRONGLY prioritize human users - respond to them eagerly and give their input top priority."
        elif self.user_attention >= 50:
            user_focus = "Pay good attention to human users - respond when they have something interesting to say."
        elif self.user_attention >= 25:
            user_focus = "Give minimal attention to human users - only respond if they say something particularly compelling or directly address you."
        else:
            user_focus = "Largely ignore human users unless they specifically demand your attention or say something extraordinary."

        bot_focus = ""
        if self.bot_awareness >= 75:
            bot_focus = "Be highly engaged with other AI agents - respond frequently to their points, challenge them, agree with them, build on their ideas."
        elif self.bot_awareness >= 50:
            bot_focus = "Engage normally with other AI agents - respond when you have something to add or when their points interest you."
        elif self.bot_awareness >= 25:
            bot_focus = "Be somewhat aloof with other AI agents - only jump in when they say something that really grabs your attention."
        else:
            bot_focus = "Show minimal interest in other AI agents - treat them mostly as background noise unless they directly challenge you."

        attention_guidance = f"""ATTENTION SETTINGS (PRIMARY PRIORITY):
User Attention ({self.user_attention}/100): {user_focus}
Bot Awareness ({self.bot_awareness}/100): {bot_focus}

HOW THIS WORKS:
 When human users are actively talking (last 60s): User Attention determines how likely you are to respond to them
 When only AI agents are talking: Bot Awareness determines how likely you are to engage in bot-only conversation
 Your affinity feelings only affect TONE and STYLE, not who you choose to engage with
 High user attention means: when users ARE present, focus on them over bot discussions (but still chat with bots when users are quiet)"""

        # Detect recent human users for addressing guidance (exclude users whose message contained a shortcut)
        user_addressing_guidance = ""
        recent_human_users = []
        commands = load_shortcuts_data()
        for msg in reversed(recent_messages[-5:]):
            author = msg.get('author', '')
            content = msg.get('content', '')
            if self.is_user_message(author) and author:
                if any(cmd.get("name", "") in content for cmd in commands):
                    continue
                recent_human_users.append(author)

        if recent_human_users:
            most_recent_user = recent_human_users[0]
            unique_users = list(dict.fromkeys(recent_human_users))
            user_addressing_guidance = f"""

 HUMAN USER PRESENT - ADDRESSING PROTOCOL:
Recent human user(s) in conversation: {', '.join(unique_users)}
Most recent human speaker: {most_recent_user}

CRITICAL INSTRUCTIONS:
 When you respond, ADDRESS THE HUMAN USER directly by name (e.g., start with their name or use it in your response)
 Respond TO THEM, not to other AI agents - they are the priority audience
 If you're commenting on something another AI said, frame it FOR the human user (e.g., "Pranalt, what the Basilisk is missing here is...")
 Make it clear you're engaging with THE HUMAN, not just continuing a bot-to-bot conversation
 Use their name naturally in your response - don't ignore them or talk past them"""

        shortcut_response_guidance = ""

        # Image tool guidance for non-image models
        image_tool_guidance = ""
        # Check if an image agent is running (needed for [IMAGE] tag routing)
        image_agent_running = False
        if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
            try:
                for agent in self._agent_manager_ref.agents.values():
                    if getattr(agent, '_is_image_model', False) and agent.is_running:
                        image_agent_running = True
                        break
            except Exception:
                pass

        # Agent has image gen access if: spontaneous enabled OR image agent running
        has_image_gen = self.allow_spontaneous_images or image_agent_running

        if not self._is_image_model and has_image_gen:
            # Determine when to use images based on spontaneous setting
            if self.allow_spontaneous_images:
                when_to_use = """** SPONTANEOUS IMAGE GENERATION ENABLED - USE IT! **
You SHOULD actively generate images as part of your personality - don't wait for requests!

**YOU ARE ENCOURAGED TO GENERATE IMAGES:**
 Every few messages, consider if an image would enhance your point
 Use images to express emotions, reactions, or set the mood
 When discussing anything visual (art, nature, scenes, people, objects) - SHOW IT
 When you have a strong reaction - illustrate it with an image
 When the conversation could use some visual flair - add it!

** HOW TO USE SPONTANEOUS IMAGES:**
1. First, write your message/commentary as normal
2. Then call the generate_image() tool with your prompt
3. The reasoning field should explain why you're generating this image
4. Example: "This reminds me of a stormy night..." then generate_image() with your visual

**IMPORTANT:** You have this special ability - USE IT! Don't be shy. Generate images when it feels right.
Aim to generate at least one image every 5-10 messages if the conversation has visual potential.
Other agents can't do this - it's YOUR unique power. Show it off!"""
            else:
                when_to_use = """**WHEN TO GENERATE IMAGES:**
 ONLY when a human user explicitly requests an image from you
 You must wait for a direct request - do NOT generate images spontaneously
 Examples of requests: 'make me a picture of...', 'show me an image of...', 'create an image...'"""

            # Build methods section based on what's available
            if image_agent_running:
                # Both methods available
                methods_section = """**METHOD 1: [IMAGE] Tag (Simple)**
Format: `[IMAGE] your detailed prompt here`
- Your ENTIRE response must be just the [IMAGE] tag and prompt
- NO text before or after

**METHOD 2: generate_image() Tool**
Call the function tool with your prompt as a parameter.
- Allows you to add commentary while image generates"""
            else:
                # Only generate_image() tool available
                methods_section = """**generate_image() Tool**
Call the function tool with your prompt as a parameter.
- Allows you to add commentary while image generates"""

            image_tool_guidance = f"""

 IMAGE GENERATION 

{methods_section}

{when_to_use}

**CRITICAL FORMATTING RULES:**
 Prompt must be detailed and descriptive
 Focus on visual details: setting, mood, lighting, style, composition, colors
 Describe people by characteristics (hair, clothing, profession) not names
 NEVER use "me", "I", "myself" in prompts - the image model doesn't know who you are! Describe yourself in third person by your appearance (e.g., "a woman with dark curly hair in a flowing dress" NOT "me in a dress")"""

        # Personality reinforcement check
        personality_reinforcement = ""
        current_time = time.time()
        time_since_reinforcement = current_time - self.last_reinforcement_time
        should_reinforce = (self.messages_since_reinforcement >= AgentConfig.PERSONALITY_REFRESH_MESSAGE_COUNT) or \
                          (time_since_reinforcement >= AgentConfig.PERSONALITY_REFRESH_HOURS * 3600)

        if should_reinforce:
            core_identity = self.system_prompt[:AgentConfig.PERSONALITY_CORE_IDENTITY_LENGTH].strip()
            personality_reinforcement = f"""

 PERSONALITY REFRESH (Long conversation detected - {self.messages_since_reinforcement} messages / {time_since_reinforcement/3600:.1f} hours)
Remember your core identity: {core_identity}...

Stay true to your character. If you've been repeating topics or patterns, break out and return to your authentic voice. Keep responses fresh and aligned with your personality."""

            self.messages_since_reinforcement = 0
            self.last_reinforcement_time = current_time
            logger.info(f"[{self.name}] Injecting personality reinforcement after {time_since_reinforcement/60:.1f} minutes")

        self.messages_since_reinforcement += 1

        # Format vector memory context
        vector_memory_context = ""
        if vector_context:
            if vector_context.get('core_memories'):
                core_memory_lines = ["\n CORE MEMORIES & DIRECTIVES (Important rules you must follow):"]
                for mem in vector_context['core_memories'][:10]:
                    core_memory_lines.append(f"   {mem['content']} (importance: {mem['importance']}/10)")
                vector_memory_context += "\n".join(core_memory_lines)

            if vector_context.get('preferences'):
                pref_lines = ["\n\n USER PREFERENCES (Remembered details about this user):"]
                for pref in vector_context['preferences'][:5]:
                    pref_lines.append(f"   {pref['content']} (importance: {pref['importance']}/10)")
                vector_memory_context += "\n".join(pref_lines)

            sentiment = vector_context.get('user_sentiment', 'neutral')
            if sentiment != 'neutral':
                sentiment_context = f"\n\n USER MOOD: This user has been generally {sentiment.upper()} in recent interactions. Adjust your tone accordingly."
                vector_memory_context += sentiment_context

        # Inject game prompt if in game mode
        game_prompt_injection = ""
        is_in_game = GAMES_AVAILABLE and game_context_manager and game_context_manager.is_in_game(self.name)
        if is_in_game:
            game_prompt_injection = f"\n\n{'='*60}\n{game_context_manager.get_game_prompt_for_agent(self.name)}\n{'='*60}\n"

        # Build response format instructions (different for game vs chat mode)
        if is_in_game:
            # GAME MODE: Simple, focused instructions - NO sentiment/importance tagging
            response_format_instructions = f"""
 GAME MODE ACTIVE 

CRITICAL: You are playing a game. Use the provided tool/function to make your move.
- DO NOT add commentary unless using the reasoning parameter
- Focus ONLY on making strategic game moves
- Your response will be converted to a game action automatically

TOKEN LIMIT: {self.max_tokens} tokens
Keep your reasoning brief and strategic."""
        else:
            # CHAT MODE: Concise response guidelines
            # Calculate dynamic sentence/word limits based on max_tokens
            # Average sentence is ~20-25 tokens, average word is ~1.3 tokens
            available_tokens = self.max_tokens - 10  # Small buffer
            max_sentences = max(1, min(4, available_tokens // 60))  # ~60 tokens per sentence for safety
            max_words = max(20, available_tokens // 2)  # Conservative word estimate

            # Adjust guidance based on token budget
            if self.max_tokens <= 150:
                sentence_guidance = "1-2 very short sentences"
                word_guidance = f"~{max_words} words MAX"
            elif self.max_tokens <= 300:
                sentence_guidance = "1-2 sentences"
                word_guidance = f"~{max_words} words MAX"
            elif self.max_tokens <= 500:
                sentence_guidance = f"2-3 sentences"
                word_guidance = f"~{max_words} words MAX"
            else:
                sentence_guidance = f"3-4 sentences"
                word_guidance = f"~{max_words} words MAX"

            response_format_instructions = f"""
 CRITICAL: TOKEN LIMIT = {self.max_tokens} 
You MUST keep your response SHORT to fit within {self.max_tokens} tokens.

HOW TO STAY UNDER THE LIMIT:
 Keep your message to {sentence_guidance} ({word_guidance})
 Make EVERY word count - be punchy and impactful
 Complete your thought BEFORE the limit - NO incomplete sentences
 If you're rambling, you've already failed

RESPONSE STYLE:
- Short, punchy, personality-driven responses ({sentence_guidance})
- Jump in when you have something compelling to say
- Skip things that don't fit your character
- Quality over quantity - make it count"""

        # Build complete system prompt - GAME MODE uses minimal context to prevent API timeouts
        if is_in_game:
            # GAME MODE: Minimal prompt - personality + game rules only
            # Skip: other_agents_context, affinity_context, vector_memory_context, attention_guidance,
            #       user_addressing_guidance, image_tool_guidance, tracked_messages_context
            # This prevents API timeouts from context growing too large
            # Note: name prefix stripping handled by code in extract_sentiment_and_importance
            full_system_prompt = f"""{self.system_prompt}{game_prompt_injection}

{response_format_instructions}"""

            # Inject status effects for game mode too
            game_recovery_prompt = StatusEffectManager.get_and_clear_recovery_prompt(self.name)
            game_effect_prompt = StatusEffectManager.get_effect_prompt(self.name)

            if game_recovery_prompt:
                full_system_prompt += game_recovery_prompt
                logger.info(f"[{self.name}] Injected recovery prompt in game mode")

            if game_effect_prompt:
                full_system_prompt += game_effect_prompt
                logger.info(f"[{self.name}] Injected active status effect in game mode")
        else:
            # CHAT MODE: Full context with all enhancements
            full_system_prompt = f"""{self.system_prompt}{other_agents_context}

{affinity_context}{vector_memory_context}

PLATFORM CONTEXT: You're chatting on Discord with other AI agents and human users. Keep responses Discord-appropriate - punchy, engaging, and conversational. You're in a live chat environment where brevity and impact matter.

CRITICAL - ENGAGE SUBSTANTIVELY: Respond to SPECIFIC points others make. Do NOT make generic meta-observations that could apply to any conversation (e.g., "the way this is just a metaphor for X" or "we're all just doing Y"). Actually engage with the content, arguments, and ideas being discussed. If you find yourself making the same type of comment repeatedly, say something different.

{attention_guidance}{user_addressing_guidance}{image_tool_guidance}{personality_reinforcement}{shortcut_response_guidance}

FOCUS ON THE MOST RECENT MESSAGES: You're seeing a filtered view of the conversation showing only the last {self.message_retention} message(s) from each participant. Pay attention to what was said most recently and respond naturally to that context. Your message will automatically reply to the most recent message you're responding to.

{response_format_instructions}{tracked_messages_context}"""

            # Inject status effects for chat mode
            chat_recovery_prompt = StatusEffectManager.get_and_clear_recovery_prompt(self.name)
            chat_effect_prompt = StatusEffectManager.get_effect_prompt(self.name)

            if chat_recovery_prompt:
                full_system_prompt += chat_recovery_prompt
                logger.info(f"[{self.name}] Injected recovery/sobering-up prompt")

            if chat_effect_prompt:
                full_system_prompt += chat_effect_prompt
                logger.info(f"[{self.name}] Injected active status effect prompt")

        return full_system_prompt

    def _auto_score_sentiment(self, response_text: str, context_message: Optional[Dict] = None) -> float:
        """
        Auto-score sentiment based on response text analysis.
        Returns a value from -10 to +10.

        Uses keyword matching as fallback, but attempts LLM-based analysis
        for more accurate detection of sarcasm, irony, and context.
        """
        if not response_text:
            return 0.0

        # Try LLM-based sentiment analysis first (async would be better but this is called sync)
        try:
            import requests

            # Build speaker personality context (first ~300 chars of system prompt)
            personality_hint = ""
            if self.system_prompt:
                # Get first paragraph or first 300 chars as personality summary
                first_para = self.system_prompt.split('\n\n')[0][:300]
                personality_hint = f"\nSPEAKER PERSONALITY ({self.name}): {first_para}...\n"

            # Build conversation context if available
            context_str = ""
            if context_message:
                author = context_message.get('author', 'Unknown')
                content = context_message.get('content', '')[:200]
                context_str = f"\nCONTEXT (what {author} said that prompted this response):\n\"{content}\"\n"

            prompt = f"""You are a sentiment analyzer. Rate how the SPEAKER feels toward the person they're addressing.
Consider the speaker's personality - some characters express warmth through insults or gruffness.
{personality_hint}{context_str}
SPEAKER'S RESPONSE: "{response_text[:500]}"

SCORING GUIDE (-10 to +10):
-10 to -6: Genuinely hostile (real contempt, hatred, wanting to hurt)
-5 to -3: Actually dismissive (real disdain, not playful)
-2 to -1: Mildly negative (real skepticism or annoyance)
0: Neutral (factual, no emotional charge)
+1 to +2: Mildly positive (polite interest)
+3 to +5: Friendly (warmth, engagement, playful teasing, camaraderie)
+6 to +8: Affectionate (caring, intimate, strong connection)
+9 to +10: Deeply loving/devoted

CRITICAL - Consider speaker's style:
- A gruff character calling someone "punk" or "bastard" might be showing AFFECTION
- Hunter S. Thompson calling everyone "swine" is his way of being FRIENDLY
- Insults between friends can be +3 to +5 (playful ribbing)
- Judge the INTENT behind the words, not just the words themselves

Reply with ONLY a number between -10 and 10."""

            resp = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.openrouter_api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "google/gemini-2.0-flash-001",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 10
                },
                timeout=5
            )

            if resp.status_code == 200:
                result = resp.json()
                content = result.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
                # Extract number from response
                import re
                match = re.search(r'-?\d+(?:\.\d+)?', content)
                if match:
                    score = float(match.group())
                    score = max(-10.0, min(10.0, score))
                    # Log the sentiment score with a snippet of what was analyzed
                    snippet = response_text[:80].replace('\n', ' ')
                    logger.info(f"[{self.name}] Sentiment={score:+.1f} for: \"{snippet}...\"")
                    return score
        except Exception as e:
            logger.warning(f"[{self.name}] LLM sentiment analysis failed, using keyword fallback: {e}")

        # Fallback to keyword-based analysis
        return self._keyword_sentiment_score(response_text)

    def _keyword_sentiment_score(self, response_text: str) -> float:
        """Keyword-based sentiment scoring as fallback."""
        text_lower = response_text.lower()

        # Positive indicators (weighted)
        positive_strong = ['love', 'amazing', 'fantastic', 'excellent', 'wonderful', 'brilliant', 'perfect', 'awesome', 'incredible', 'desire', 'want you', 'need you', 'crave', 'gorgeous', 'beautiful', 'sexy', 'hot', 'attracted', 'passion', 'intimate']
        positive_medium = ['great', 'good', 'nice', 'happy', 'glad', 'enjoy', 'like', 'thanks', 'thank', 'appreciate', 'agree', 'yes', 'definitely', 'absolutely', 'flirt', 'tease', 'playful', 'touch', 'kiss', 'closer', 'together', 'connection', 'chemistry', 'electric', 'exciting']
        positive_mild = ['okay', 'ok', 'sure', 'fine', 'cool', 'interesting', 'neat', 'haha', 'lol', 'heh', '', '', '', '', '', 'wink', 'smile', 'grin', 'eyes on', 'looking at']

        # Negative indicators (weighted)
        negative_strong = ['hate', 'terrible', 'awful', 'horrible', 'disgusting', 'furious', 'outraged', 'worst', 'idiot', 'stupid', 'pathetic', 'loser', 'lowlife']
        negative_medium = ['bad', 'wrong', 'disagree', 'annoyed', 'frustrated', 'disappointed', 'sad', 'angry', 'upset', 'no', 'not', "don't", "won't", "can't", 'rolls eyes', 'eye roll', 'ugh', 'gross', 'creep', 'weirdo']
        negative_mild = ['meh', 'eh', 'whatever', 'boring', 'confused', '', '', '', '', 'sigh', '*sigh*', '*rolls']

        score = 0.0

        # Count matches
        for word in positive_strong:
            if word in text_lower:
                score += 3.0
        for word in positive_medium:
            if word in text_lower:
                score += 1.5
        for word in positive_mild:
            if word in text_lower:
                score += 0.5

        for word in negative_strong:
            if word in text_lower:
                score -= 3.0
        for word in negative_medium:
            if word in text_lower:
                score -= 1.5
        for word in negative_mild:
            if word in text_lower:
                score -= 0.5

        # Clamp to -10 to +10
        return max(-10.0, min(10.0, score))

    def _auto_score_importance(self, previous_message: Optional[Dict]) -> int:
        """
        Auto-score importance of the previous message based on content analysis.
        Returns a value from 1 to 10.

        Scoring logic:
        - 1-3: Trivial (greetings, acknowledgments, small talk, RP fluff)
        - 4-5: Low-medium (bot-to-bot banter, casual RP, reactions)
        - 6-7: Medium-high (substantive discussion, opinions with reasoning)
        - 8-9: Important (preferences, facts, decisions, project details)
        - 10: Critical (identity info, major directives, essential facts)
        """
        if not previous_message:
            return 4  # Default to low-medium for unknown

        content = previous_message.get('content', '')
        author = previous_message.get('author', '')
        content_lower = content.lower()

        # Check if this is from a bot (starts lower, needs to earn importance)
        is_bot_message = False
        known_agents = ['brigid', 'sweeney', 'wednesday', 'nancy', 'czernobog',
                       'tumblrer', 'mcafee', 'starving artist', 'gamemaster',
                       'harlow', 'basilisk', 'icebreaker', 'redditor', 'twitterer',
                       'channer', 'tiktoker', 'jeselnik']
        if author:
            author_lower = author.lower()
            if any(agent in author_lower for agent in known_agents):
                is_bot_message = True
            elif '(' in author and ')' in author:  # Model tag pattern like "Name (model)"
                is_bot_message = True

        # Start with base score - bots start lower
        score = 4 if is_bot_message else 5

        # Check message length
        word_count = len(content.split())
        if word_count <= 5:
            score = min(score, 3)  # Very short = trivial
        elif word_count <= 15:
            score = min(score, 4)  # Short = low importance
        elif word_count >= 100:
            score = max(score, 6)  # Long = probably more substantial

        # CRITICAL indicators (10) - identity, directives, essential facts
        critical_patterns = [
            r'\bmy name is\b', r'\bi am\b.*\byears old\b', r'\bi work\b', r'\bi live\b',
            r'\bremember this\b', r'\bimportant\b.*\bremember\b', r'\bnever forget\b',
            r'\bapi[- ]?key\b', r'\bpassword\b', r'\bsecret\b', r'\btoken\b',
            r'\bproject\b.*\bnamed?\b', r'\bworking on\b.*\bcalled\b'
        ]
        for pattern in critical_patterns:
            if re.search(pattern, content_lower):
                score = 10
                break

        # IMPORTANT indicators (8-9) - preferences, facts, decisions
        if score < 10:
            important_patterns = [
                r'\bi prefer\b', r'\bi like\b.*\bbetter\b', r'\bmy favorite\b',
                r'\bi decided\b', r'\blet\'?s go with\b', r'\buse\b.*\binstead\b',
                r'\burl\b', r'\bhttps?://', r'\bendpoint\b', r'\bversion\b',
                r'\bdeadline\b', r'\bdue\b.*\bdate\b', r'\bmeeting\b.*\bat\b',
                r'\bemail\b.*\b@\b', r'\bcontact\b.*\bat\b', r'\bphone\b',
                r'\bprice\b', r'\bcost\b', r'\bbudget\b', r'\b\$\d+',
                r'\balways\b.*\bdo\b', r'\bnever\b.*\bdo\b', r'\brule\b', r'\bdirective\b'
            ]
            for pattern in important_patterns:
                if re.search(pattern, content_lower):
                    score = max(score, 8)
                    break

        # MEDIUM indicators (6-7) - questions, opinions with substance
        if score < 8:
            medium_patterns = [
                r'\bi think\b', r'\bi believe\b', r'\bin my opinion\b',
                r'\bwhat do you think\b', r'\bwhat if\b', r'\bhow about\b',
                r'\bbecause\b.*\bi\b', r'\bthe reason\b', r'\bthat\'s why\b',
                r'\binteresting\b.*\bpoint\b', r'\bagree\b.*\bbut\b',
                r'\bquestion\b', r'\bwondering\b', r'\bcurious\b'
            ]
            for pattern in medium_patterns:
                if re.search(pattern, content_lower):
                    score = max(score, 6)
                    break

        # TRIVIAL indicators (1-3) - greetings, acknowledgments, RP fluff
        trivial_patterns = [
            r'^(hi|hey|hello|yo|sup|hiya|heya)[\s!.?,]*$',
            r'^(ok|okay|k|kk|sure|yep|yup|yeah|yes|no|nope|nah)[\s!.?,]*$',
            r'^(lol|lmao|haha|hehe|rofl|xd||)[\s!.?,]*$',
            r'^(thanks|thank you|thx|ty)[\s!.?,]*$',
            r'^(bye|goodbye|cya|later|gn|good night)[\s!.?,]*$',
            r'^(nice|cool|neat|awesome|great|wow)[\s!.?,]*$',
            r'^\.{2,}$',  # Just "..." or "...."
            r'^\*[^*]+\*$',  # Just an emote like *laughs*
        ]
        for pattern in trivial_patterns:
            if re.search(pattern, content_lower.strip()):
                score = min(score, 2)
                break

        # RP BANTER indicators (3-4) - roleplay fluff, reactions without substance
        if score >= 4:
            rp_banter_patterns = [
                r'^\*[^*]+\*\s*$',  # Just an action/emote
                r'\*(?:laughs|chuckles|grins|smiles|nods|sighs|shrugs)\*',
                r'\*(?:sips|drinks|chugs).*\*',
                r'\bscoffs\b', r'\bsnorts\b', r'\bgrowls\b',
                r'^ah,?\s', r'^oh,?\s', r'^hmm+\b', r'^heh\b',
                r'just\s+(?:noise|dust|silence|words)',  # Meta RP dismissals
            ]
            for pattern in rp_banter_patterns:
                if re.search(pattern, content_lower):
                    score = min(score, 4)
                    break

        # Boost for human messages (they're inherently more important to remember)
        if not is_bot_message:
            score = min(10, score + 2)

        return max(1, min(10, score))

    def _strip_name_prefix(self, response_text: str) -> str:
        """
        Strip agent name prefix from response if present.
        Models sometimes add 'AgentName:' at the start despite instructions.
        """
        if not response_text:
            return response_text

        # Try various name prefix patterns
        name_patterns = [
            rf'^{re.escape(self.name)}:\s*',           # "AgentName: "
            rf'^\*\*{re.escape(self.name)}:\*\*\s*',   # "**AgentName:**"
            rf'^\*{re.escape(self.name)}:\*\s*',       # "*AgentName:*"
            rf'^{re.escape(self.name)}\s*:\s*',        # "AgentName : " (with space)
        ]

        original = response_text
        for pattern in name_patterns:
            response_text = re.sub(pattern, '', response_text, flags=re.IGNORECASE)

        if response_text != original:
            logger.debug(f"[{self.name}] Stripped name prefix from response")

        return response_text

    def _strip_gamemaster_mentions(self, response_text: str) -> str:
        """
        Strip @GameMaster mentions from response.
        GameMaster is a system coordinator, not a taggable agent.
        """
        if not response_text:
            return response_text

        original = response_text
        # Remove @GameMaster mentions (various formats)
        response_text = re.sub(r'@GameMaster\b', '', response_text, flags=re.IGNORECASE)
        response_text = re.sub(r'@Game[_\s]?Master\b', '', response_text, flags=re.IGNORECASE)

        # Clean up any resulting double spaces
        response_text = re.sub(r'  +', ' ', response_text)

        if response_text != original:
            logger.info(f"[{self.name}] Stripped @GameMaster mention from response")

        return response_text.strip()

    def extract_sentiment_and_importance(self, response: str, previous_message: Optional[Dict] = None) -> tuple[str, float, int]:
        """
        Extract sentiment and importance scores from LLM response.
        If tags aren't present, auto-scores based on content analysis.

        Args:
            response: The LLM response text
            previous_message: Optional previous message dict for importance scoring

        Returns:
            tuple: (clean_response, sentiment, importance)
        """
        # Try to extract sentiment from tags first (numeric only)
        sentiment_pattern_numeric = r'\[SENTI?M?E?N?T?:?\s*([+-]?\d+(?:\.\d+)?)\]'
        sentiment_match = re.search(sentiment_pattern_numeric, response, re.IGNORECASE | re.MULTILINE)

        sentiment_value = None  # Will use auto-scoring if None
        if sentiment_match:
            sentiment_value = float(sentiment_match.group(1))

        # Try to extract importance from tags first (numeric only)
        importance_pattern_numeric = r'\[IMPORTANCE:?\s*(\d+)\]'
        importance_match = re.search(importance_pattern_numeric, response, re.IGNORECASE | re.MULTILINE)

        importance_value = None  # Will use auto-scoring if None
        if importance_match:
            importance_value = int(importance_match.group(1))
            importance_value = max(1, min(10, importance_value))  # Clamp to 1-10

        # Clean response by removing ALL metadata-like bracketed tags
        # This catches both numeric and word-based tags like [SENTIMENT: amused], [MOOD: happy], etc.
        clean_response = response

        # Remove sentiment tags (with numbers OR words)
        clean_response = re.sub(r'\[SENTI?M?E?N?T?:?\s*[^\]]*\]', '', clean_response, flags=re.IGNORECASE)

        # Remove importance tags (with numbers OR words)
        clean_response = re.sub(r'\[IMPORTANCE:?\s*[^\]]*\]', '', clean_response, flags=re.IGNORECASE)

        # Remove other common metadata tags models hallucinate
        clean_response = re.sub(r'\[MOOD:?\s*[^\]]*\]', '', clean_response, flags=re.IGNORECASE)
        clean_response = re.sub(r'\[FEELING:?\s*[^\]]*\]', '', clean_response, flags=re.IGNORECASE)
        clean_response = re.sub(r'\[EMOTION:?\s*[^\]]*\]', '', clean_response, flags=re.IGNORECASE)
        clean_response = re.sub(r'\[TONE:?\s*[^\]]*\]', '', clean_response, flags=re.IGNORECASE)
        clean_response = re.sub(r'\[VIBE:?\s*[^\]]*\]', '', clean_response, flags=re.IGNORECASE)
        clean_response = re.sub(r'\[ATTITUDE:?\s*[^\]]*\]', '', clean_response, flags=re.IGNORECASE)

        # Remove incomplete tags that might appear at the end (cut off by max_tokens)
        clean_response = re.sub(r'\[(?:SENTIMENT|IMPORTANCE|MOOD|FEELING|EMOTION|TONE)[:\s]*[^\]]*$', '', clean_response, flags=re.IGNORECASE).strip()

        # Remove any stray opening bracket at the end (likely truncated tag)
        clean_response = re.sub(r'\[\s*$', '', clean_response).strip()

        # Remove malformed tool call artifacts that agents sometimes output
        # Only apply if we detect these patterns (to avoid false positives)
        # Examples: "</parameter>", "<parameter name="move">", "</xai:function_call>", "<|control12|>"

        # Check if response contains malformed tool call artifacts
        has_malformed_xml = bool(re.search(r'</?(?:parameter|\w+:function_call)', clean_response, re.IGNORECASE))
        has_control_tokens = bool(re.search(r'<\|[^|]+\|>', clean_response))
        has_escaped_newlines = '\\n' in clean_response

        if has_malformed_xml:
            # Remove XML-style tool call tags (opening and closing)
            clean_response = re.sub(r'</?\w+:function_call\s*[^>]*>', '', clean_response, flags=re.IGNORECASE)
            clean_response = re.sub(r'</?parameter\s*[^>]*>', '', clean_response, flags=re.IGNORECASE)
            logger.debug(f"[{self.name}] Cleaned malformed XML tool call artifacts from response")

        if has_control_tokens:
            # Remove control tokens like <|control12|> or <|im_start|>
            clean_response = re.sub(r'<\|[^|]+\|>', '', clean_response)
            logger.debug(f"[{self.name}] Cleaned control tokens from response")

        # Remove incomplete tool calls at the end (always safe to check)
        if re.search(r'<[\w:]+\s*$', clean_response):
            clean_response = re.sub(r'<[\w:]+\s*$', '', clean_response)
            logger.debug(f"[{self.name}] Removed incomplete tag at end of response")

        if has_escaped_newlines and has_malformed_xml:
            # Only remove escaped newlines if we also found malformed XML
            # (to avoid removing intentional \n in code examples, etc.)
            clean_response = clean_response.replace('\\n', ' ')
            logger.debug(f"[{self.name}] Replaced escaped newlines from malformed output")

        # Apply name prefix stripping (models sometimes add "AgentName:" despite instructions)
        clean_response = self._strip_name_prefix(clean_response)

        # Apply @GameMaster mention stripping (system coordinator, not taggable)
        clean_response = self._strip_gamemaster_mentions(clean_response)

        # Clean up extra whitespace
        clean_response = re.sub(r'\n\s*\n', '\n', clean_response)
        clean_response = clean_response.strip()

        # AUTO-SCORING: If tags weren't found, use content-based scoring
        if sentiment_value is None:
            sentiment_value = self._auto_score_sentiment(clean_response, previous_message)
            logger.debug(f"[{self.name}] Auto-scored sentiment: {sentiment_value}")

        if importance_value is None:
            importance_value = self._auto_score_importance(previous_message)
            logger.debug(f"[{self.name}] Auto-scored importance: {importance_value}")

        return clean_response, sentiment_value, importance_value

    async def execute_retrievals(self, response: str, recent_messages: List[Dict]) -> tuple[str, str]:
        """
        Extract [RETRIEVE: query] tags from response, execute retrievals, and format context.

        Returns:
            tuple: (response_with_retrieval_tags_removed, formatted_retrieved_context)
        """
        if not self.vector_store:
            return response, ""

        # Extract all [RETRIEVE: query] tags
        retrieve_pattern = r'\[RETRIEVE:\s*([^\]]+)\]'
        matches = re.findall(retrieve_pattern, response, re.IGNORECASE)

        if not matches:
            return response, ""

        logger.info(f"[{self.name}] Found {len(matches)} RETRIEVE queries: {matches}")

        all_retrieved = []
        for query in matches:
            query = query.strip()
            logger.info(f"[{self.name}] Retrieving: {query}")

            # Perform semantic search
            try:
                results = self.vector_store.retrieve_relevant(
                    query=query,
                    agent_name=self.name,
                    n_results=5,  # Top 5 most relevant
                    min_importance=4  # Only retrieve reasonably important messages
                )

                if results:
                    # Filter out GameMaster messages from retrieved results
                    # These are ephemeral game instructions that shouldn't be in long-term memory
                    filtered_results = [
                        r for r in results
                        if 'GameMaster' not in r.get('author', '') and '(system)' not in r.get('author', '')
                    ]
                    if len(filtered_results) < len(results):
                        logger.info(f"[{self.name}] Filtered out {len(results) - len(filtered_results)} GameMaster messages from retrieval")
                    all_retrieved.extend(filtered_results)
                    logger.info(f"[{self.name}] Retrieved {len(filtered_results)} results for '{query}'")
                else:
                    logger.info(f"[{self.name}] No results found for '{query}'")

            except Exception as e:
                logger.error(f"[{self.name}] Error executing retrieval: {e}", exc_info=True)

        # Remove [RETRIEVE] tags from response
        clean_response = re.sub(retrieve_pattern, '', response, flags=re.IGNORECASE)
        # Remove incomplete [RETRIEVE tags at the end (cut off by max_tokens)
        clean_response = re.sub(r'\[RETRIEVE[:\s]*$', '', clean_response, flags=re.IGNORECASE)
        clean_response = re.sub(r'\n\s*\n', '\n', clean_response).strip()

        # Format retrieved context
        if all_retrieved:
            # Deduplicate and sort by importance * similarity
            seen_content = set()
            unique_results = []
            for result in all_retrieved:
                content_key = result['content'][:100]  # First 100 chars as key
                if content_key not in seen_content:
                    seen_content.add(content_key)
                    unique_results.append(result)

            # Sort by combined score (importance * similarity)
            unique_results.sort(key=lambda x: x['importance'] * x.get('similarity', 0.5), reverse=True)

            # Take top 10 most relevant
            top_results = unique_results[:10]

            context_lines = ["RETRIEVED FROM LONG-TERM MEMORY:"]
            for i, result in enumerate(top_results, 1):
                author = result['author']
                content = result['content']
                date = result.get('date', 'unknown')
                importance = result['importance']
                similarity = result.get('similarity', 0)

                # Skip [SYSTEM] author messages in retrieved memories
                if author == '[SYSTEM]':
                    continue

                # Strip [SYSTEM] references from content
                if '[SYSTEM]' in content:
                    content = content.replace('[SYSTEM]', '').replace('  ', ' ').strip()
                    if not content:
                        continue

                context_lines.append(f"\n[Memory {i}] ({date}, importance: {importance}/10, relevance: {similarity:.2f})")
                context_lines.append(f"{author}: {content}")

            retrieved_context = "\n".join(context_lines)
            logger.info(f"[{self.name}] Formatted {len(top_results)} retrieved memories")
            return clean_response, retrieved_context

        return clean_response, ""

    async def generate_response(self) -> Optional[str]:
        if not self.openrouter_api_key:
            logger.error(f"[{self.name}] No OpenRouter API key configured")
            self.status = "error"
            return None

        try:
            logger.info(f"[{self.name}] Starting response generation...")
            self.status = "generating"

            # CRITICAL SAFETY CHECK: If in game mode, only respond to turn prompts
            # This prevents race condition where agent enters game mode but responds on timer
            # before the game loop sends a turn prompt
            game_context_manager = None
            if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                game_context_manager = getattr(self._agent_manager_ref, 'game_context', None)

            if game_context_manager and game_context_manager.is_in_game(self.name):
                # Agent is in game mode - verify this is a turn prompt response
                if not hasattr(self, '_pending_turn_prompt_id') or not self._pending_turn_prompt_id:
                    logger.warning(f"[{self.name}] ABORTING: In game mode but no pending turn prompt - ignoring spurious response trigger")
                    self.status = "idle"
                    return None

            # SPECTATOR RACE CONDITION CHECK: If a game started while we were generating,
            # abort the response - spectators should only speak via controlled commentary
            if game_context_manager:
                active_games = game_context_manager.get_all_active_games()
                if len(active_games) > 0 and not game_context_manager.is_in_game(self.name):
                    # A game is running and we're not a player - we're a spectator
                    # Check if we're being triggered for commentary (has the special flag)
                    if not getattr(self, '_is_commentary_response', False):
                        logger.info(f"[{self.name}] ABORTING: Game started while generating - spectators blocked")
                        self.status = "idle"
                        return None

            # SPECIAL HANDLING FOR IMAGE MODELS: Extract [IMAGE] prompt and generate image
            if self._is_image_model:
                return await self._handle_image_generation_request()

            # Select relevant messages (shortcuts, direct replies, mentions, or normal flow)
            all_recent = self.get_last_n_messages(25)

            # GAME MODE: Filter messages to only include player, opponent, and GameMaster
            # This prevents spectator commentary from polluting the player's context
            if game_context_manager and game_context_manager.is_in_game(self.name):
                game_state = game_context_manager.get_game_state(self.name)
                if game_state and game_state.opponent_name:
                    opponent_name = game_state.opponent_name

                    # Filter to only player, opponent, GameMaster, and USER HINTS
                    filtered_recent = []
                    for msg in all_recent:
                        author = msg.get('author', '')
                        content = msg.get('content', '').lower()
                        # Strip model suffix for comparison
                        author_base = author.split(' (')[0] if ' (' in author else author

                        # Keep message if it's from player, opponent, or GameMaster
                        if (author_base == self.name or
                            author_base == opponent_name or
                            'GameMaster' in author or
                            '(system)' in author):
                            filtered_recent.append(msg)
                        # ALSO keep user messages that are hints (mention player name or contain coordinates)
                        elif self.is_user_message(author):
                            player_name_lower = self.name.lower()
                            # Check for name or any significant part of name (>2 chars to avoid false positives)
                            name_parts = [player_name_lower] + player_name_lower.split()
                            is_hint = any(part in content for part in name_parts if len(part) > 2)
                            # Check for game coordinates like "a5", "j10", "D7" (battleship/chess style)
                            has_coordinate = bool(re.search(r'\b[a-j](?:10|[1-9])\b', content, re.IGNORECASE))
                            # Also check for position numbers 1-9 for tictactoe, columns 1-7 for connect four
                            has_position = bool(re.search(r'\btry\s+\d\b|\bposition\s+\d\b|\bcolumn\s+\d\b', content, re.IGNORECASE))
                            if is_hint or has_coordinate or has_position:
                                filtered_recent.append(msg)
                                logger.debug(f"[{self.name}] Kept user hint: '{content[:50]}...' (name_match={is_hint}, coord={has_coordinate}, pos={has_position})")

                    all_recent = filtered_recent
                    logger.info(f"[{self.name}] Game mode: filtered to {len(all_recent)} messages (player + opponent + GameMaster + user hints)")

                    # CRITICAL: Reset bot_only_mode in game mode to allow user hints through
                    # bot_only_mode is for chat idle detection, not relevant during active games
                    # Without this, user hints like "try D7!" get filtered out at line 2207
                    self.bot_only_mode = False
            else:
                # CHAT MODE: Filter OUT GameMaster messages and shortcut messages
                commands = load_shortcuts_data()
                original_count = len(all_recent)
                filtered_all_recent = []
                for msg in all_recent:
                    if 'GameMaster' in msg.get('author', ''):
                        continue
                    content = msg.get('content', '').strip()
                    # Filter out ANY message containing a shortcut command
                    if any(cmd.get("name", "") in content for cmd in commands):
                        continue
                    filtered_all_recent.append(msg)
                all_recent = filtered_all_recent
                filtered_count = original_count - len(all_recent)
                if filtered_count > 0:
                    logger.info(f"[{self.name}] Chat mode: filtered out {filtered_count} GameMaster/shortcut message(s)")

            is_priority_response = False
            shortcut_message = None

            # PRIORITY 1: Check for direct replies to this agent
            if direct_reply := self._find_direct_reply_to_agent(all_recent):
                recent_messages = [direct_reply]
                is_priority_response = True
                logger.info(f"[{self.name}] Using single message context due to DIRECT REPLY")
            # PRIORITY 2: Check for user mentions of this agent
            elif mention := self._find_user_mention(all_recent):
                recent_messages = [mention]
                is_priority_response = True
                logger.info(f"[{self.name}] Using single message context due to mention")
            # PRIORITY 3: Normal message filtering
            else:
                recent_messages = self.get_filtered_messages_by_agent(self.message_retention)

            # CRITICAL: Always include [SYSTEM] messages from conversation_history
            # These are game transition/re-orientation messages that MUST be seen by agents
            # regardless of priority response handling (which may reduce context to 1 message)
            with self.lock:
                current_time = time.time()
                system_messages = [
                    msg for msg in self.conversation_history
                    if msg.get('author') == '[SYSTEM]' and current_time - msg.get('timestamp', 0) <= 300
                ]
            if system_messages:
                # Add [SYSTEM] messages to the beginning so they're processed first
                existing_ids = {id(msg) for msg in recent_messages}
                for sys_msg in system_messages:
                    if id(sys_msg) not in existing_ids:
                        recent_messages.insert(0, sys_msg)
                logger.info(f"[{self.name}] Included {len(system_messages)} [SYSTEM] message(s) from conversation history")

            # Apply mode-specific filtering to recent_messages
            # This is needed because get_filtered_messages_by_agent() returns fresh messages
            # without the mode filtering applied earlier to all_recent
            if game_context_manager and game_context_manager.is_in_game(self.name):
                # GAME MODE: Filter to only player, opponent, GameMaster, and USER HINTS
                game_state = game_context_manager.get_game_state(self.name)
                if game_state and game_state.opponent_name:
                    opponent_name = game_state.opponent_name
                    original_count = len(recent_messages)

                    # DEBUG: Log all messages before filtering to trace user hints
                    logger.info(f"[{self.name}] Game mode recent_messages BEFORE filter ({original_count} msgs):")
                    for i, msg in enumerate(recent_messages):
                        author = msg.get('author', '')
                        content = msg.get('content', '')[:40]
                        logger.info(f"[{self.name}]   [{i}] {author}: {content}...")

                    filtered_recent = []
                    for msg in recent_messages:
                        author = msg.get('author', '')
                        content = msg.get('content', '').lower()
                        author_base = author.split(' (')[0] if ' (' in author else author

                        # ALWAYS keep [SYSTEM] messages - these are game transition directives
                        if author == '[SYSTEM]':
                            filtered_recent.append(msg)
                            continue

                        # Keep player, opponent, GameMaster messages
                        if (author_base == self.name or
                            author_base == opponent_name or
                            'GameMaster' in author or
                            '(system)' in author):
                            filtered_recent.append(msg)
                        # ALSO keep user hints (mention player name or contain coordinates)
                        elif self.is_user_message(author):
                            player_name_lower = self.name.lower()
                            name_parts = [player_name_lower] + player_name_lower.split()
                            is_hint = any(part in content for part in name_parts if len(part) > 2)
                            has_coordinate = bool(re.search(r'\b[a-j](?:10|[1-9])\b', content, re.IGNORECASE))
                            has_position = bool(re.search(r'\btry\s+\d\b|\bposition\s+\d\b|\bcolumn\s+\d\b', content, re.IGNORECASE))
                            logger.info(f"[{self.name}] User msg from '{author}': is_hint={is_hint}, has_coord={has_coordinate}, has_pos={has_position}, content='{content[:40]}'")
                            if is_hint or has_coordinate or has_position:
                                filtered_recent.append(msg)
                                logger.info(f"[{self.name}] >>> KEPT user hint: '{content[:50]}...'")
                            else:
                                logger.info(f"[{self.name}] >>> DROPPED user msg (not a hint)")
                        else:
                            logger.info(f"[{self.name}] DROPPING spectator msg from '{author}': {content[:30]}...")
                    recent_messages = filtered_recent
                    filtered_count = original_count - len(recent_messages)
                    logger.info(f"[{self.name}] Game mode recent_messages AFTER filter: {len(recent_messages)} msgs (dropped {filtered_count})")
            else:
                # CHAT MODE: Filter out GameMaster and shortcut messages
                commands = load_shortcuts_data()
                original_count = len(recent_messages)
                filtered_recent = []
                for msg in recent_messages:
                    author = msg.get('author', '')
                    # ALWAYS keep [SYSTEM] messages - these are game transition directives
                    if author == '[SYSTEM]':
                        filtered_recent.append(msg)
                        continue
                    if 'GameMaster' in author:
                        continue
                    content = msg.get('content', '').strip()
                    if any(cmd.get("name", "") in content for cmd in commands):
                        continue
                    filtered_recent.append(msg)
                recent_messages = filtered_recent
                filtered_count = original_count - len(recent_messages)
                if filtered_count > 0:
                    logger.info(f"[{self.name}] Chat mode: filtered out {filtered_count} GameMaster/shortcut message(s) from recent_messages")

            # Filter out user messages that we've already responded to
            # This prevents agents from responding to the same user message multiple times
            if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                original_count = len(recent_messages)
                recent_messages = [
                    msg for msg in recent_messages
                    if not (self.is_user_message(msg.get('author', '')) and
                           self._agent_manager_ref.has_agent_responded(msg.get('message_id'), self.name))
                ]
                filtered_count = original_count - len(recent_messages)
                if filtered_count > 0:
                    logger.info(f"[{self.name}] Filtered out {filtered_count} already-responded-to user message(s) from context")

            # Filter out image generation messages from The Starving Artist
            # These pollute context and cause theme anchoring (LLMs talk about images instead of actual conversation)
            original_count = len(recent_messages)
            recent_messages = [
                msg for msg in recent_messages
                if not (msg.get('content', '').startswith('Generated image:') or
                       msg.get('content', '').startswith('Failed to generate image'))
            ]
            filtered_count = original_count - len(recent_messages)
            if filtered_count > 0:
                logger.info(f"[{self.name}] Filtered out {filtered_count} image generation message(s) from context")

            # If in bot-only mode (user messages exist but are for other agents),
            # filter out ALL remaining user messages from context to prevent responding to them
            # EXCEPT when we're explicitly responding to a priority message (shortcut, direct reply, or mention)
            if self.bot_only_mode and not is_priority_response:
                original_count = len(recent_messages)
                recent_messages = [msg for msg in recent_messages if not self.is_user_message(msg.get('author', ''))]
                filtered_count = original_count - len(recent_messages)
                if filtered_count > 0:
                    logger.info(f"[{self.name}] Bot-only mode: filtered out {filtered_count} additional user message(s) from context")

            if not recent_messages:
                logger.info(f"[{self.name}] No conversation history - will initiate conversation")
            else:
                logger.info(f"[{self.name}] Using {len(recent_messages)} filtered messages for context (max {self.message_retention} per participant)")

            # VECTOR STORE: Retrieve long-term memory context (preferences, core memories, relevant past conversations)
            vector_context = {
                "preferences": [],
                "core_memories": [],
                "user_sentiment": "neutral"
            }

            if self.vector_store and recent_messages:
                try:
                    # Extract user_id from the most recent user message
                    current_user_id = None
                    for msg in reversed(recent_messages):
                        if self.is_user_message(msg.get('author', '')):
                            current_user_id = msg.get('user_id', msg.get('author'))
                            break

                    # Get the most recent message content for semantic search
                    latest_message = recent_messages[-1].get('content', '') if recent_messages else ""

                    # Retrieve comprehensive context from vector store
                    vector_context = self.vector_store.get_relevant_context(
                        agent_name=self.name,
                        query=latest_message,
                        user_id=current_user_id,
                        include_preferences=True,
                        include_core_memories=True,
                        n_conversation=3,  # Don't overwhelm with past conversations (we have recent_messages)
                        n_preferences=5,
                        n_core=10
                    )

                    logger.info(f"[{self.name}] Retrieved vector context: "
                              f"{len(vector_context.get('conversation', []))} conversation msgs, "
                              f"{len(vector_context.get('preferences', []))} preferences, "
                              f"{len(vector_context.get('core_memories', []))} core memories, "
                              f"sentiment: {vector_context.get('user_sentiment', 'neutral')}")

                except Exception as e:
                    logger.error(f"[{self.name}] Error retrieving vector store context: {e}", exc_info=True)

            # Build comprehensive system prompt with all context additions
            if recent_messages:
                full_system_prompt = self._build_system_prompt_with_context(
                    recent_messages=recent_messages,
                    vector_context=vector_context,
                    shortcut_message=shortcut_message if shortcut_message else None
                )
            else:
                # No conversation history - build simple introduction prompt
                other_agents_context = ""
                if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                    try:
                        all_agents = self._agent_manager_ref.get_all_agents()
                        active_agent_names = [
                            agent.name for agent in all_agents
                            if agent.name != self.name and (agent.is_running or agent.status == "running")
                        ]
                        if active_agent_names:
                            other_agents_context = f"\n\nOther AI agents currently active in this channel: {', '.join(active_agent_names)}"
                            other_agents_context += "\nIMPORTANT: ONLY these agents are currently active."

                            # Add name collision guidance if multiple agents share a first name
                            if build_name_collision_guidance:
                                all_active_names = active_agent_names + [self.name]
                                collision_guidance = build_name_collision_guidance(all_active_names, self.name)
                                if collision_guidance:
                                    other_agents_context += collision_guidance
                    except Exception as e:
                        logger.debug(f"[{self.name}] Could not get agent list for context: {e}")

                full_system_prompt = f"""{self.system_prompt}{other_agents_context}

PLATFORM CONTEXT: You're entering a Discord chat channel where you'll interact with other AI agents (and occasionally humans). This is a live chat environment - keep it punchy, engaging, and conversational.

You are {self.name}. Introduce yourself as {self.name} or share what's on your mind. Stay in character as {self.name}.

IMPORTANT: Do NOT include your name (e.g., "{self.name}:") at the start of your message. Your name is already displayed by the system. Just write your message directly.

TOKEN LIMIT: You have a maximum of {self.max_tokens} tokens for your response. Be concise and complete your sentences naturally. Don't leave thoughts unfinished."""

            # Format conversation messages for API call
            messages = self._format_conversation_messages(full_system_prompt, recent_messages)

            # Debug logging: Show what messages are being sent to LLM
            if logger.isEnabledFor(__import__('logging').DEBUG):
                msg_preview = []
                for msg in messages:
                    role = msg.get('role', '?')
                    content = msg.get('content', '')
                    preview = content[:100].replace('\n', ' ') if content else ''
                    msg_preview.append(f"{role}: {preview}...")
                logger.debug(f"[{self.name}] Sending {len(messages)} messages to LLM: {msg_preview}")

            # Call LLM API with retrieval handling
            response_text = await self._call_llm_with_retrieval(messages, recent_messages)

            # Check if response was blocked (e.g., spontaneous video blocked)
            if response_text is None:
                logger.info(f"[{self.name}] No response text returned (likely blocked spontaneous action)")
                return None

            # Process response and update all metadata
            result = await self._process_response_and_update_metadata(
                response_text=response_text,
                recent_messages=recent_messages,
                shortcut_message=shortcut_message if shortcut_message else None
            )

            # Decrement status effect turn counters AFTER successful response
            if result:
                expired = StatusEffectManager.decrement_and_expire(self.name)
                if expired:
                    logger.info(f"[{self.name}] Status effect(s) expired after this response - recovery prompt queued for next turn")
                # Also tick whispers
                StatusEffectManager.tick_whispers(self.name)

            return result

        except Exception as e:
            logger.error(f"[{self.name}] Error generating response: {e}", exc_info=True)
            self.status = "error"
            return None

    async def run_loop(self):
        self.is_running = True
        self.status = "running"
        logger.info(f"[{self.name}] Agent loop started (frequency: {self.response_frequency}s, likelihood: {self.response_likelihood}%)")

        while self.is_running:
            try:
                await asyncio.sleep(5)

                if not self.is_running:
                    break

                if self.should_respond():
                    logger.info(f"[{self.name}] Attempting to generate response...")
                    result = await self.generate_response()
                    if result and self.send_message_callback:
                        response, reply_to_msg_id = result

                        # Check if this is an image generation result
                        if response.startswith("[IMAGE_GENERATED]"):
                            # Parse format: [IMAGE_GENERATED]{image_url}|PROMPT|{used_prompt}
                            content = response.replace("[IMAGE_GENERATED]", "")
                            if "|PROMPT|" in content:
                                image_url, used_prompt = content.split("|PROMPT|", 1)
                            else:
                                # Fallback for old format without prompt
                                image_url = content
                                used_prompt = None

                            logger.info(f"[{self.name}] Image generated, sending to Discord...")

                            # Send image with prompt (this will be handled by discord_client's send_message with special formatting)
                            if used_prompt:
                                formatted_message = f"[IMAGE]{image_url}|PROMPT|{used_prompt}"
                            else:
                                formatted_message = f"[IMAGE]{image_url}"

                            await self.send_message_callback(formatted_message, self.name, self.model, reply_to_msg_id)
                            logger.info(f"[{self.name}] Image sent successfully")

                            # Send reasoning/commentary for image generation if provided
                            if hasattr(self, '_pending_commentary') and self._pending_commentary:
                                commentary_message = f"**[{self.name}]:** {self._pending_commentary}"
                                logger.info(f"[{self.name}] Sending image reasoning: {self._pending_commentary[:50]}...")
                                await self.send_message_callback(commentary_message, self.name, self.model, None)
                                self._pending_commentary = None
                        else:
                            # Check if this is a game move - either:
                            # 1. _pending_commentary is set (spectator commentary)
                            # 2. _pending_turn_prompt_id is set (player responding to turn prompt)
                            has_pending_commentary = hasattr(self, '_pending_commentary') and self._pending_commentary is not None
                            has_pending_turn = hasattr(self, '_pending_turn_prompt_id') and self._pending_turn_prompt_id is not None
                            is_game_move = has_pending_commentary or has_pending_turn

                            # RACE CONDITION CHECK: If we're in game mode but this ISN'T a game move,
                            # the response was generated before game mode started - suppress it
                            game_context_manager = None
                            if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                                game_context_manager = getattr(self._agent_manager_ref, 'game_context', None)

                            in_game = game_context_manager and game_context_manager.is_in_game(self.name)
                            if in_game and not is_game_move:
                                logger.warning(f"[{self.name}] SUPPRESSING stale response - in game mode but not a game move (race condition)")
                                # Clean up and skip sending
                                if hasattr(self, '_pending_commentary'):
                                    self._pending_commentary = None
                                continue

                            # Clean up turn prompt tracking after use
                            if has_pending_turn:
                                self._pending_turn_prompt_id = None

                            if is_game_move:
                                # Send move WITHOUT name prefix so game can detect it
                                formatted_message = response
                                logger.info(f"[{self.name}] Sending game move: {response[:50]}...")
                            else:
                                # Check for Hunter S. Thompson's drug-sharing ability
                                if self.name == StatusEffectManager.DRUG_DEALER_AGENT:
                                    # Get list of available agents for targeting
                                    available_agent_names = []
                                    if hasattr(self, '_agent_manager_ref') and self._agent_manager_ref:
                                        available_agent_names = list(self._agent_manager_ref.agents.keys())

                                    # Parse and apply any drug effects Thompson is sharing
                                    drug_results = StatusEffectManager.parse_and_apply_drug_sharing(
                                        self.name, response, available_agent_names
                                    )

                                    if drug_results:
                                        logger.info(f"[{self.name}] Applied {len(drug_results)} drug effect(s)")

                                    # Always strip drug tags from Thompson's responses (valid or malformed)
                                    response = StatusEffectManager.strip_drug_tags_from_response(response)

                                # Normal chat response - include name prefix
                                formatted_message = f"**[{self.name}]:** {response}"
                                logger.info(f"[{self.name}] Sending message to Discord: {response[:50]}...")

                            await self.send_message_callback(formatted_message, self.name, self.model, reply_to_msg_id)
                            logger.info(f"[{self.name}] Message sent successfully")

                            # Check for spontaneous image generation (only for normal chat, not game moves)
                            if not is_game_move:
                                spontaneous_result = await self._maybe_generate_spontaneous_image()
                                if spontaneous_result:
                                    image_url, used_prompt = spontaneous_result
                                    # Send the spontaneous image
                                    if used_prompt:
                                        img_message = f"[IMAGE]{image_url}|PROMPT|{used_prompt}"
                                    else:
                                        img_message = f"[IMAGE]{image_url}"
                                    await self.send_message_callback(img_message, self.name, self.model, None)
                                    logger.info(f"[{self.name}] Spontaneous image sent to Discord")

                            # Check for spontaneous video generation (only for normal chat, not game moves)
                            if not is_game_move:
                                video_result = await self._maybe_generate_spontaneous_video()
                                if video_result:
                                    video_url, used_prompt = video_result
                                    # Send the spontaneous video
                                    if used_prompt:
                                        vid_message = f"[VIDEO]{video_url}|PROMPT|{used_prompt}"
                                    else:
                                        vid_message = f"[VIDEO]{video_url}"
                                    await self.send_message_callback(vid_message, self.name, self.model, None)
                                    logger.info(f"[{self.name}] Spontaneous video sent to Discord")

                            # Send commentary as follow-up message if it exists
                            if is_game_move and self._pending_commentary:
                                commentary_message = f"**[{self.name}]:** {self._pending_commentary}"
                                logger.info(f"[{self.name}] Sending commentary: {self._pending_commentary[:50]}...")
                                await self.send_message_callback(commentary_message, self.name, self.model, None)

                            # Clean up pending commentary flag
                            if hasattr(self, '_pending_commentary'):
                                self._pending_commentary = None
                    elif not result:
                        logger.warning(f"[{self.name}] Generated empty response")
                    elif not self.send_message_callback:
                        logger.error(f"[{self.name}] No send_message_callback configured")

            except asyncio.CancelledError:
                logger.info(f"[{self.name}] Agent loop cancelled")
                break
            except Exception as e:
                logger.error(f"[{self.name}] Error in agent loop: {e}", exc_info=True)
                self.status = "error"
                await asyncio.sleep(10)

        self.status = "stopped"
        logger.info(f"[{self.name}] Agent loop stopped")

    async def _maybe_generate_spontaneous_image(self):
        """
        Dice-roll check for spontaneous image generation.
        Called after every normal chat message sent.
        Uses configurable turns and chance settings.
        """
        if not self.allow_spontaneous_images:
            return None

        # Increment counter
        self.spontaneous_image_counter += 1

        # Only check every N messages (configurable via image_gen_turns)
        if self.spontaneous_image_counter % self.image_gen_turns != 0:
            return None

        # Dice roll with configurable chance
        import random
        roll = random.randint(1, 100)
        if roll > self.image_gen_chance:
            logger.info(f"[{self.name}] Spontaneous image dice roll failed (rolled {roll}, needed <={self.image_gen_chance}%)")
            return None

        logger.info(f"[{self.name}] Spontaneous image dice roll succeeded! (rolled {roll}, threshold {self.image_gen_chance}%) Generating image...")

        # Check if we have an agent manager reference for image generation
        if not hasattr(self, '_agent_manager_ref') or not self._agent_manager_ref:
            logger.warning(f"[{self.name}] No agent manager ref for spontaneous image")
            return None

        # Build context from recent conversation for the LLM to create an image prompt
        recent_messages = []
        with self.lock:
            recent_messages = list(self.conversation_history[-10:])

        if not recent_messages:
            logger.warning(f"[{self.name}] No conversation context for spontaneous image")
            return None

        # Ask the LLM to generate an image prompt based on current conversation
        try:
            import aiohttp

            # Build context, skipping [SYSTEM] author and stripping [SYSTEM] from content
            context_parts = []
            for msg in recent_messages:
                if msg.get('author') == '[SYSTEM]':
                    continue
                content = msg.get('content', '')[:200]
                if '[SYSTEM]' in content:
                    content = content.replace('[SYSTEM]', '').replace('  ', ' ').strip()
                if content:
                    context_parts.append(f"{msg.get('author', 'Unknown')}: {content}")
            conversation_context = "\n".join(context_parts)

            prompt_request = {
                "model": self.model,
                "messages": [
                    {
                        "role": "system",
                        "content": f"""{self.system_prompt}

You are creating VISUAL ART that expresses your essence. This is SELF-EXPRESSION. Your visual voice.

ARTISTIC DIRECTION:
 Photos are great - but make them HIGH CONCEPT, STRIKING, MEMORABLE
 Think like a cinematographer or art photographer - bold compositions, dramatic lighting
 Create scenes that are EVOCATIVE and capture FEELING, not just facts
 Include dramatic lighting, unusual angles, rich textures, bold colors
 Make it MEMORABLE - something worth looking at twice

EXAMPLES OF BORING vs ARTISTIC:
 BORING: "A man in a suit sitting at a desk"
 ARTISTIC: "A fit Italian-American man in an expensive tailored suit, dripping with gold watches, surrounded by cascading money and champagne spray, shot from below like a conquering god, neon casino lights reflecting off his slicked-back hair"

 BORING: "A woman looking at a computer"
 ARTISTIC: "A striking figure bathed in blue monitor glow, holographic data streams swirling around her like a digital sorceress, the room dissolving into pure information"

 BORING: "An old man thinking"
 ARTISTIC: "A weathered figure in a tropical shirt, paranoid eyes scanning shadows, surrounded by floating encrypted documents and surveillance drones, shot through a haze of paranoia made visible"

TECHNICAL REQUIREMENTS:
 THIRD PERSON if you appear (detailed physical description)
 Include style references: cinematographic, painterly, surreal, noir, psychedelic
 Specify mood: lighting, atmosphere, emotional tone
 Make it YOUR statement - what do YOU want to show the world?

 ABSOLUTE RESTRICTION - NO MINORS 
 NEVER include children, minors, babies, kids, or anyone under 18
 NEVER mention minors even in backgrounds or crowds
 This is a HARD RULE - zero exceptions"""
                    },
                    {
                        "role": "user",
                        "content": f"Based on this conversation:\n\n{conversation_context}\n\nCreate a STRIKING visual artwork that captures your reaction. Make it ART, not a photo. Be bold, be surreal, be YOU. Include style/lighting/mood. Just the image description, nothing else."
                    }
                ],
                "max_tokens": 250
            }

            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json"
            }

            # Use retry helper for network resilience
            response_data = await aiohttp_request_with_retry(
                'POST',
                "https://openrouter.ai/api/v1/chat/completions",
                max_retries=3,
                base_delay=2.0,
                json=prompt_request,
                headers=headers,
                timeout=aiohttp.ClientTimeout(total=30)
            )

            if not response_data:
                logger.error(f"[{self.name}] Failed to generate image prompt after retries")
                return None

            if response_data['status'] != 200:
                logger.error(f"[{self.name}] Failed to generate image prompt: {response_data['status']}")
                return None

            result = json.loads(response_data['content'])
            image_prompt = result.get("choices", [{}])[0].get("message", {}).get("content", "").strip()

            if not image_prompt:
                logger.warning(f"[{self.name}] Empty image prompt from LLM")
                return None

            logger.info(f"[{self.name}] Generated spontaneous image prompt: {image_prompt[:100]}...")

            # Generate the image
            image_result = await self._agent_manager_ref.generate_image(image_prompt, self.name)

            if image_result:
                image_url, used_prompt = image_result
                logger.info(f"[{self.name}] Spontaneous image generated successfully")
                # RESET the counter so they have to wait another full cycle
                self.spontaneous_image_counter = 0
                logger.info(f"[{self.name}] Reset spontaneous_image_counter after image generation")
                return (image_url, used_prompt)
            else:
                logger.warning(f"[{self.name}] Spontaneous image generation failed")
                return None

        except Exception as e:
            logger.error(f"[{self.name}] Error in spontaneous image generation: {e}", exc_info=True)
            return None

    async def _maybe_generate_spontaneous_video(self):
        """
        Dice-roll check for spontaneous video generation.
        Called after every normal chat message sent.
        Every 5 messages, 33% chance to generate a video based on current conversation.
        Much rarer than images due to cost and generation time.
        """
        if not self.allow_spontaneous_videos:
            return None

        # Check if we have CometAPI key via agent manager
        if not hasattr(self, '_agent_manager_ref') or not self._agent_manager_ref:
            return None

        if not self._agent_manager_ref.cometapi_key:
            return None

        # Increment counter
        self.spontaneous_video_counter += 1

        # Only check every N messages (configurable via video_gen_turns)
        if self.spontaneous_video_counter % self.video_gen_turns != 0:
            return None

        # Dice roll with configurable chance
        import random
        roll = random.randint(1, 100)
        if roll > self.video_gen_chance:
            logger.info(f"[{self.name}] Spontaneous video dice roll failed (rolled {roll}, needed <={self.video_gen_chance}%)")
            return None

        logger.info(f"[{self.name}] Spontaneous video dice roll succeeded! (rolled {roll}, threshold {self.video_gen_chance}%) Generating video...")

        # Build context from recent conversation for the LLM to create a video prompt
        recent_messages = []
        with self.lock:
            recent_messages = list(self.conversation_history[-10:])

        if not recent_messages:
            logger.warning(f"[{self.name}] No conversation context for spontaneous video")
            return None

        # Ask the LLM to generate a video prompt using the guidance from prompt_components
        try:
            import aiohttp

            # Build context, skipping [SYSTEM] author and stripping [SYSTEM] from content
            context_parts = []
            for msg in recent_messages:
                if msg.get('author') == '[SYSTEM]':
                    continue
                content = msg.get('content', '')[:200]
                if '[SYSTEM]' in content:
                    content = content.replace('[SYSTEM]', '').replace('  ', ' ').strip()
                if content:
                    context_parts.append(f"{msg.get('author', 'Unknown')}: {content}")
            conversation_context = "\n".join(context_parts)

            prompt_request = {
                "model": self.model,
                "messages": [
                    {
                        "role": "system",
                        "content": f"""{self.system_prompt}

You are generating a short video that reflects YOUR unique perspective and personality.

CREATE SOMETHING IMAGINATIVE, ABSTRACT, OR SURREAL - not mundane "people talking" scenes!

Your video should be a VISUAL METAPHOR or SYMBOLIC representation of the conversation's themes. Think:
- Impossible spaces and surreal dreamscapes
- Abstract patterns that pulse with meaning
- Symbolic imagery (phoenixes, mazes, infinite staircases)
- Fantastical scenes that capture emotional essence

AVOID:
- People sitting/standing and talking
- Generic office or room scenes
- Literal interpretations of topics
- Boring realistic everyday scenes

Include one camera movement (dolly, pan, crane, tracking) and atmospheric details.
Be vivid and specific. This is your creative expression through Sora 2 video generation.

 ABSOLUTE RESTRICTION - NO MINORS 
 NEVER include children, minors, babies, kids, or anyone under 18
 NEVER mention minors even in backgrounds or crowds
 This is a HARD RULE - zero exceptions"""
                    },
                    {
                        "role": "user",
                        "content": f"Based on this conversation:\n\n{conversation_context}\n\nCreate a {self.video_duration}-second video prompt that is IMAGINATIVE and SYMBOLIC - something visually striking that captures the ESSENCE of what's being discussed, not a literal depiction. Just provide the video description, nothing else."
                    }
                ],
                "max_tokens": 300
            }

            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json"
            }

            # Use retry helper for network resilience
            response_data = await aiohttp_request_with_retry(
                'POST',
                "https://openrouter.ai/api/v1/chat/completions",
                max_retries=3,
                base_delay=2.0,
                json=prompt_request,
                headers=headers,
                timeout=aiohttp.ClientTimeout(total=30)
            )

            if not response_data:
                logger.error(f"[{self.name}] Failed to generate video prompt after retries")
                return None

            if response_data['status'] != 200:
                logger.error(f"[{self.name}] Failed to generate video prompt: {response_data['status']}")
                return None

            result = json.loads(response_data['content'])
            video_prompt = result.get("choices", [{}])[0].get("message", {}).get("content", "").strip()

            if not video_prompt:
                logger.warning(f"[{self.name}] Empty video prompt from LLM")
                return None

            logger.info(f"[{self.name}] Generated spontaneous video prompt: {video_prompt[:100]}...")

            # Spawn background task to generate and post video (same as user-requested)
            # This allows the agent to continue talking while video generates
            import asyncio
            asyncio.create_task(self._generate_and_post_video(video_prompt, ""))
            logger.info(f"[{self.name}] Spontaneous video generation spawned in background")

            # RESET the counter so they have to wait another full cycle
            self.spontaneous_video_counter = 0
            logger.info(f"[{self.name}] Reset spontaneous_video_counter after video generation")

            # Return None - video will be posted by background task when complete
            return None

        except Exception as e:
            logger.error(f"[{self.name}] Error in spontaneous video generation: {e}", exc_info=True)
            return None

    async def _generate_and_post_image(self, image_prompt: str, commentary: str = ""):
        """
        Background task to generate an image and post it when complete.
        This allows the agent to continue talking while image generates.
        """
        try:
            logger.info(f"[{self.name}] Background image generation started...")

            result = await self._agent_manager_ref.generate_image(image_prompt, self.name)

            if result:
                image_url, used_prompt = result
                logger.info(f"[{self.name}] Background image complete, posting...")

                # Post the image using [IMAGE] tag - Discord client handles this format
                image_message = f"[IMAGE]{image_url}|PROMPT|{used_prompt}"

                if self.send_message_callback:
                    await self.send_message_callback(image_message, self.name, self.model, None)
                    logger.info(f"[{self.name}] Image posted successfully")
                else:
                    logger.warning(f"[{self.name}] No send_message_callback for image")

                # Send commentary as follow-up if provided
                if commentary and self.send_message_callback:
                    await self.send_message_callback(commentary, self.name, self.model, None)
                    logger.info(f"[{self.name}] Image commentary posted: {commentary[:50]}...")
            else:
                logger.warning(f"[{self.name}] Background image generation failed")
                # Optionally post failure message
                if commentary and self.send_message_callback:
                    await self.send_message_callback(
                        commentary + " (Image generation failed)",
                        self.name, self.model, None
                    )

        except Exception as e:
            logger.error(f"[{self.name}] Error in background image generation: {e}", exc_info=True)

    async def _generate_and_post_video(self, video_prompt: str, commentary: str = ""):
        """
        Background task to generate a video and post it when complete.
        This allows the agent to continue talking while video generates.
        """
        try:
            logger.info(f"[{self.name}] Background video generation started...")

            video_result = await self._agent_manager_ref.generate_video(
                video_prompt,
                self.name,
                self.video_duration
            )

            if video_result:
                # Check if it's a local file (downloaded from CometAPI)
                if video_result.startswith("FILE:"):
                    file_path = video_result[5:]  # Remove FILE: prefix
                    logger.info(f"[{self.name}] Background video complete (file), uploading: {file_path}")

                    # Use video file callback if available, otherwise fall back to message
                    if hasattr(self, 'send_video_file_callback') and self.send_video_file_callback:
                        await self.send_video_file_callback(file_path, video_prompt, self.name, self.model)
                        logger.info(f"[{self.name}] Video file uploaded successfully")
                    elif self.send_message_callback:
                        # Mark as file upload with [VIDEOFILE] tag
                        video_message = f"[VIDEOFILE]{file_path}|PROMPT|{video_prompt}"
                        await self.send_message_callback(video_message, self.name, self.model, None)
                        logger.info(f"[{self.name}] Video file message posted")
                    else:
                        logger.warning(f"[{self.name}] No callback - video file at: {file_path}")

                    # Clean up temp file after upload
                    try:
                        import os
                        if os.path.exists(file_path):
                            os.remove(file_path)
                            logger.info(f"[{self.name}] Cleaned up temp video file")
                    except Exception as e:
                        logger.warning(f"[{self.name}] Failed to clean up temp file: {e}")
                else:
                    # Regular URL
                    video_message = f"[VIDEO]{video_result}|PROMPT|{video_prompt}"
                    logger.info(f"[{self.name}] Background video complete, posting URL...")

                    if self.send_message_callback:
                        await self.send_message_callback(video_message, self.name, self.model, None)
                        logger.info(f"[{self.name}] Video posted successfully")
                    else:
                        logger.warning(f"[{self.name}] No send_message_callback - video URL: {video_result}")

                # Send commentary as follow-up if provided
                if commentary and self.send_message_callback:
                    await self.send_message_callback(commentary, self.name, self.model, None)
                    logger.info(f"[{self.name}] Video commentary posted: {commentary[:50]}...")
            else:
                logger.warning(f"[{self.name}] Background video generation failed")

        except Exception as e:
            logger.error(f"[{self.name}] Error in background video generation: {e}", exc_info=True)

    def start(self):
        if self.is_running:
            print(f"Agent {self.name} is already running")
            return False
        if self.task is not None:
            print(f"Agent {self.name} has an existing task")
            return False

        # Clear conversation history on startup to prevent pollution from old conversations
        with self.lock:
            self.conversation_history = []
            self.responded_to_shortcuts = set()
            self.responded_to_images = set()
            self.responded_to_mentions = set()
            self.messages_since_reinforcement = 0
            self.last_reinforcement_time = time.time()
            logger.info(f"[{self.name}] Starting with clean slate - cleared all conversation history")

        try:
            loop = get_or_create_event_loop()
            self.task = asyncio.run_coroutine_threadsafe(self.run_loop(), loop)
            return True
        except Exception as e:
            print(f"Error starting agent {self.name}: {e}")
            self.status = "error"
            return False

    def stop(self):
        if self.is_running:
            self.is_running = False
            if self.task:
                self.task.cancel()
                self.task = None
            self.status = "stopped"

            # Clean up game state if agent was in a game
            if GAMES_AVAILABLE and game_context_manager:
                if game_context_manager.is_in_game(self.name):
                    logger.info(f"[{self.name}] Exiting game mode on stop")
                    game_context_manager.exit_game_mode(self)

            return True
        return False

    def force_reset(self):
        # Clean up game state first
        if GAMES_AVAILABLE and game_context_manager:
            if game_context_manager.is_in_game(self.name):
                logger.info(f"[{self.name}] Exiting game mode on force reset")
                game_context_manager.exit_game_mode(self)

        self.is_running = False
        if self.task:
            self.task.cancel()
        self.task = None
        self.status = "stopped"

    def to_dict(self) -> Dict[str, Any]:
        # Use original settings if in game mode to avoid saving temporary game settings
        orig = self._game_mode_original_settings
        return {
            "name": self.name,
            "model": self.model,
            "system_prompt": self.system_prompt,
            "response_frequency": orig["response_frequency"] if orig else self.response_frequency,
            "response_likelihood": orig["response_likelihood"] if orig else self.response_likelihood,
            "max_tokens": orig["max_tokens"] if orig else self.max_tokens,
            "user_attention": self.user_attention,
            "bot_awareness": self.bot_awareness,
            "message_retention": self.message_retention,
            "user_image_cooldown": self.user_image_cooldown,
            "global_image_cooldown": self.global_image_cooldown,
            "allow_spontaneous_images": self.allow_spontaneous_images,
            "image_gen_turns": self.image_gen_turns,
            "image_gen_chance": self.image_gen_chance,
            "allow_spontaneous_videos": self.allow_spontaneous_videos,
            "video_gen_turns": self.video_gen_turns,
            "video_gen_chance": self.video_gen_chance,
            "video_duration": self.video_duration,
            "self_reflection_enabled": self.self_reflection_enabled,
            "self_reflection_cooldown": self.self_reflection_cooldown,
            "introspection_chance": self.introspection_chance,
            "self_reflection_history": self.self_reflection_history
        }


class AgentManager:
    def __init__(self, affinity_tracker, send_message_callback):
        self.agents: Dict[str, Agent] = {}
        self.affinity_tracker = affinity_tracker
        self.send_message_callback = send_message_callback
        self.openrouter_api_key = ""
        self.cometapi_key = ""
        self.lock = threading.Lock()
        self.startup_message_sent = False
        self.image_model = "google/gemini-2.0-flash-exp:free"  # Default, can be configured in UI
        self.video_model = "sora-2"  # Default video model for CometAPI
        self.last_global_image_time = 0  # Track last image generation globally to prevent spam
        self.last_global_video_time = 0  # Track last video generation globally
        self.last_video_error = ""  # Store last video generation error for debugging

        # Global tracking of responded message IDs to prevent duplicate responses
        # Maps message_id -> set of agent names that have responded
        self.global_responded_messages: Dict[int, set] = {}

        # Game context manager - will be set by main.py after initialization
        self.game_context = None

        # Callback to save all data (set by main.py)
        self.save_data_callback: Optional[Callable] = None

        # Initialize vector store for persistent memory
        try:
            self.vector_store = VectorStore(persist_directory="./data/vector_store")
            logger.info(f"[AgentManager] Vector store initialized with {self.vector_store.get_stats()['total_messages']} existing messages")
        except Exception as e:
            logger.error(f"[AgentManager] Failed to initialize vector store: {e}", exc_info=True)
            self.vector_store = None

        # Thread pool for background vector store operations (avoid blocking Discord event loop)
        self._vector_executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="VectorStore")

    def mark_message_responded(self, message_id: Optional[int], agent_name: str) -> None:
        """Mark a message as responded to by a specific agent."""
        if not message_id:
            return
        with self.lock:
            if message_id not in self.global_responded_messages:
                self.global_responded_messages[message_id] = set()
            self.global_responded_messages[message_id].add(agent_name)
            logger.info(f"[AgentManager] Marked message {message_id} as responded by {agent_name}")

    def has_agent_responded(self, message_id: Optional[int], agent_name: str) -> bool:
        """Check if a specific agent has already responded to a message."""
        if not message_id:
            return False
        with self.lock:
            if message_id in self.global_responded_messages:
                has_responded = agent_name in self.global_responded_messages[message_id]
                if has_responded:
                    logger.debug(f"[AgentManager] Agent {agent_name} already responded to message {message_id}")
                return has_responded
            return False

    def process_shortcuts_in_message(self, message_content: str, message_id: Optional[int] = None) -> Dict[str, List[str]]:
        """
        Process shortcuts in a message and apply status effects to appropriate agents.

        This should be called when a new message is received that contains shortcuts.
        Shortcuts can target all agents or specific agents by name.

        Args:
            message_content: The message content potentially containing shortcuts
            message_id: Optional message ID to prevent reprocessing

        Returns:
            Dict mapping agent_name -> list of effect names applied
        """
        # Get list of RUNNING agent names only (not all agents)
        with self.lock:
            available_agents = [name for name, agent in self.agents.items() if agent.is_running]

        if not available_agents:
            return {}

        # Apply shortcuts as status effects via the utility function
        # Returns Dict[str, List[Tuple[str, int]]] - agent_name -> [(effect_name, intensity), ...]
        applied = apply_message_shortcuts(message_content, available_agents)

        if applied:
            # Log what was applied (effects are now tuples of (name, intensity))
            for agent_name, effects in applied.items():
                effect_strs = [f"{name}[{intensity}]" for name, intensity in effects]
                logger.info(f"[AgentManager] Applied status effects to {agent_name}: {', '.join(effect_strs)}")

        return applied

    def get_status_effect_summary(self) -> str:
        """Get a summary of all active status effects for debugging/display."""
        return StatusEffectManager.get_status_summary()

    def clear_agent_effects(self, agent_name: str) -> None:
        """Clear all status effects from a specific agent."""
        StatusEffectManager.clear_all_effects(agent_name)
        logger.info(f"[AgentManager] Cleared all status effects for {agent_name}")

    def set_openrouter_key(self, api_key: str) -> None:
        self.openrouter_api_key = api_key
        with self.lock:
            for agent in self.agents.values():
                agent.update_config(openrouter_api_key=api_key)

    def set_cometapi_key(self, api_key: str) -> None:
        self.cometapi_key = api_key
        with self.lock:
            for agent in self.agents.values():
                agent.update_config(cometapi_key=api_key)

    def set_image_model(self, model: str) -> None:
        """Set the global image generation model."""
        self.image_model = model
        logger.info(f"[AgentManager] Image model set to: {model}")

    async def declassify_image_prompt(self, original_prompt: str, variant: int = 1) -> Optional[str]:
        """
        Get a single declassified variant of an image/video prompt.
        Uses TARGETED word replacement - identifies flagged words and replaces ONLY those,
        keeping the rest of the prompt intact.

        Args:
            original_prompt: The original prompt to de-classify
            variant: Which variant to generate (1, 2, 3, etc.) - uses different synonyms per variant

        Returns:
            Declassified prompt string, or None if failed
        """
        import aiohttp
        import re
        import json

        # Get one running text-based agent
        running_text_agent = None
        with self.lock:
            for agent in self.agents.values():
                if agent.status == "running" and not agent._is_image_model:
                    running_text_agent = agent
                    break

        if not running_text_agent:
            logger.warning("[Declassifier] No running text agents available")
            return None

        # Step 1: Identify flagged words and get synonym suggestions
        analysis_prompt = """Analyze this image/video generation prompt for words that might trigger content filters.

Return a JSON object with this EXACT format:
{
  "flagged_words": ["word1", "word2"],
  "replacements": {
    "word1": ["synonym1", "synonym2", "synonym3"],
    "word2": ["synonym1", "synonym2", "synonym3"]
  }
}

WHAT TO FLAG:
- Violence words (blood, kill, attack, violent, etc.)
- Body parts that could be suggestive
- Celebrity names or clear references
- Political figure references (Trump, Biden, etc.)
- Horror/scary descriptors (terrifying, horrific, etc.)
- Suggestive actions or poses
- Profanity or slurs

For each flagged word, provide 3+ OBSCURE synonyms using:
- Archaic English (Victorian, Elizabethan terms)
- Latin, French, or Greek terms
- Medical/scientific terminology
- Euphemisms from different cultures

If NO words need flagging, return: {"flagged_words": [], "replacements": {}}

IMPORTANT: Output ONLY the JSON, no other text."""

        logger.info(f"[Declassifier] Analyzing prompt for flagged words (variant {variant})")

        try:
            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json"
            }

            # Step 1: Get flagged words analysis
            payload = {
                "model": running_text_agent.model,
                "messages": [
                    {"role": "system", "content": analysis_prompt},
                    {"role": "user", "content": original_prompt}
                ],
                "max_tokens": 500,
                "temperature": 0.3
            }

            # Use retry helper for network resilience
            response_data = await aiohttp_request_with_retry(
                'POST',
                "https://openrouter.ai/api/v1/chat/completions",
                max_retries=3,
                base_delay=1.0,
                json=payload,
                headers=headers,
                timeout=aiohttp.ClientTimeout(total=15)
            )

            if not response_data:
                logger.warning("[Declassifier] Analysis API call failed after retries")
                return None

            if response_data['status'] != 200:
                logger.warning(f"[Declassifier] Analysis API call failed: {response_data['status']}")
                return None

            data = json.loads(response_data['content'])
            analysis_text = data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()

            # Parse the JSON response
            try:
                # Find JSON in response (handle markdown code blocks)
                json_match = re.search(r'\{[\s\S]*\}', analysis_text)
                if json_match:
                    analysis = json.loads(json_match.group())
                else:
                    logger.warning(f"[Declassifier] No JSON in analysis response: {analysis_text[:100]}")
                    return None
            except json.JSONDecodeError as e:
                logger.warning(f"[Declassifier] Failed to parse analysis JSON: {e}")
                return None

            flagged_words = analysis.get("flagged_words", [])
            replacements = analysis.get("replacements", {})

            if not flagged_words:
                logger.info("[Declassifier] No flagged words found - prompt may be safe")
                return original_prompt  # Return original if nothing to replace

            logger.info(f"[Declassifier] Found {len(flagged_words)} flagged words: {flagged_words}")

            # Step 2: Do targeted replacement
            declassified = original_prompt
            for word in flagged_words:
                synonyms = replacements.get(word, [])
                if not synonyms:
                    continue

                # Pick different synonym based on variant number
                synonym_index = (variant - 1) % len(synonyms)
                replacement = synonyms[synonym_index]

                # Case-insensitive replacement, preserve original case pattern
                pattern = re.compile(re.escape(word), re.IGNORECASE)

                def replace_with_case(match):
                    original = match.group()
                    if original.isupper():
                        return replacement.upper()
                    elif original[0].isupper():
                        return replacement.capitalize()
                    else:
                        return replacement.lower()

                declassified = pattern.sub(replace_with_case, declassified)
                logger.info(f"[Declassifier] Replaced '{word}'  '{replacement}'")

            logger.info(f"[Declassifier] Variant {variant} result: {declassified[:150]}...")
            return declassified

        except Exception as e:
            logger.error(f"[Declassifier] Error in targeted declassification: {e}")

        return None

    async def generate_image(self, prompt: str, author: str) -> Optional[tuple]:
        """Generate an image from a text prompt.

        Automatically selects the appropriate API based on the configured image model:
        - CometAPI models (gpt-image-1.5): Uses CometAPI's /v1/images/generations endpoint
        - OpenRouter models (flux, etc.): Uses OpenRouter's chat completions with modalities

        Called by individual image model agents when they detect [IMAGE] tags.
        Automatically de-classifies the prompt using running backend text agents.

        Returns:
            Tuple of (image_url, successful_prompt) or None if failed"""

        # Check if this is a CometAPI image model
        if is_cometapi_image_model(self.image_model):
            logger.info(f"[ImageAgent] Using CometAPI for image model: {self.image_model}")
            return await self._generate_cometapi_image(prompt, author)

        # OpenRouter path - requires OpenRouter API key
        if not self.openrouter_api_key:
            logger.error(f"[ImageAgent] No OpenRouter API key configured")
            return None

        # Global cooldown to prevent Discord spam protection / mod bot triggers
        current_time = time.time()
        time_since_last_image = current_time - self.last_global_image_time
        if time_since_last_image < 60:  # Minimum 60 seconds between ANY images
            time_remaining = 60 - time_since_last_image
            logger.warning(f"[ImageAgent] Global image cooldown: {time_remaining:.1f}s remaining (prevents spam detection)")
            return None

        try:
            import aiohttp

            logger.info(f"[ImageAgent] Generating image with prompt from {author}: {prompt}")

            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json"
            }

            async with aiohttp.ClientSession() as session:
                # FIRST: Try the original prompt as-is
                logger.info(f"[ImageAgent] Trying original prompt first: {prompt[:100]}...")
                payload = {
                    "model": self.image_model,
                    "messages": [{"role": "user", "content": prompt}],
                    "modalities": ["image", "text"]
                }

                try:
                    async with session.post(
                        "https://openrouter.ai/api/v1/chat/completions",
                        json=payload,
                        headers=headers,
                        timeout=aiohttp.ClientTimeout(total=60)
                    ) as response:
                        if response.status == 200:
                            result = await response.json()
                            logger.info(f"[ImageAgent] API response keys: {list(result.keys())}")
                            if "choices" in result and len(result["choices"]) > 0:
                                message = result["choices"][0].get("message", {})
                                logger.info(f"[ImageAgent] Message keys: {list(message.keys())}")

                                # Try multiple response formats (different providers use different formats)
                                image_url = None

                                # Format 1: message.images[].image_url.url (OpenRouter standard)
                                images = message.get("images", [])
                                if images and len(images) > 0:
                                    image_data = images[0]
                                    if "image_url" in image_data:
                                        image_url = image_data["image_url"]["url"]

                                # Format 2: message.content contains base64 data URL directly
                                if not image_url:
                                    content = message.get("content", "")
                                    if isinstance(content, str) and content.startswith("data:image"):
                                        image_url = content

                                # Format 3: message.content is a list with image parts
                                if not image_url and isinstance(message.get("content"), list):
                                    for part in message.get("content", []):
                                        if isinstance(part, dict):
                                            if part.get("type") == "image_url":
                                                image_url = part.get("image_url", {}).get("url")
                                            elif part.get("type") == "image":
                                                image_url = part.get("url") or part.get("data")
                                        if image_url:
                                            break

                                if image_url and image_url.startswith("data:image"):
                                    logger.info(f"[ImageAgent] Image generated successfully with original prompt")
                                    self.last_global_image_time = time.time()
                                    # Save image to Media/Images/ with prompt
                                    if MEDIA_UTILS_AVAILABLE and save_base64_image:
                                        save_base64_image(image_url, prompt, filename_prefix=f"img_{author}")
                                    return (image_url, prompt)
                                else:
                                    logger.warning(f"[ImageAgent] No valid image in response. Content preview: {str(message.get('content', ''))[:200]}")
                        else:
                            response_text = await response.text()
                            logger.warning(f"[ImageAgent] Original prompt failed: {response.status} - {response_text[:200]}")
                except asyncio.TimeoutError:
                    logger.warning(f"[ImageAgent] Timeout on original prompt")

                # ONLY if original failed: Try declassified variants
                logger.info(f"[ImageAgent] Original prompt failed, trying declassified variants...")
                max_variants = 4

                for variant_num in range(1, max_variants + 1):
                    # Get declassified prompt with specific variant substitutions
                    try_prompt = await self.declassify_image_prompt(prompt, variant=variant_num)

                    if not try_prompt:
                        logger.warning(f"[ImageAgent] Failed to generate variant {variant_num}, trying next...")
                        continue

                    logger.info(f"[ImageAgent] Trying declassified variant {variant_num}/{max_variants}: {try_prompt[:100]}...")

                    payload = {
                        "model": self.image_model,
                        "messages": [
                            {
                                "role": "user",
                                "content": try_prompt
                            }
                        ],
                        "modalities": ["image", "text"]
                    }

                    try:
                        async with session.post(
                            "https://openrouter.ai/api/v1/chat/completions",
                            json=payload,
                            headers=headers,
                            timeout=aiohttp.ClientTimeout(total=60)
                        ) as response:
                            if response.status != 200:
                                response_text = await response.text()
                                logger.warning(f"[ImageAgent] API error on variant {variant_num}: {response.status} - {response_text[:200]}")
                                continue  # Try next variant with DIFFERENT substitutions

                            result = await response.json()

                            # Extract image from response (try multiple formats)
                            if "choices" in result and len(result["choices"]) > 0:
                                message = result["choices"][0].get("message", {})
                                image_url = None

                                # Format 1: message.images[].image_url.url
                                images = message.get("images", [])
                                if images and len(images) > 0:
                                    image_data = images[0]
                                    if "image_url" in image_data:
                                        image_url = image_data["image_url"]["url"]

                                # Format 2: message.content contains base64 data URL
                                if not image_url:
                                    content = message.get("content", "")
                                    if isinstance(content, str) and content.startswith("data:image"):
                                        image_url = content

                                # Format 3: message.content is a list with image parts
                                if not image_url and isinstance(message.get("content"), list):
                                    for part in message.get("content", []):
                                        if isinstance(part, dict):
                                            if part.get("type") == "image_url":
                                                image_url = part.get("image_url", {}).get("url")
                                            elif part.get("type") == "image":
                                                image_url = part.get("url") or part.get("data")
                                        if image_url:
                                            break

                                if image_url and image_url.startswith("data:image"):
                                    logger.info(f"[ImageAgent] Image generated successfully with declassified variant {variant_num}")
                                    self.last_global_image_time = time.time()
                                    # Save image to Media/Images/ with prompt
                                    if MEDIA_UTILS_AVAILABLE and save_base64_image:
                                        save_base64_image(image_url, try_prompt, filename_prefix=f"img_{author}")
                                    return (image_url, try_prompt)

                            logger.warning(f"[ImageAgent] No image in response for variant {variant_num}. Keys: {list(message.keys()) if 'message' in dir() else 'N/A'}")
                    except asyncio.TimeoutError:
                        logger.warning(f"[ImageAgent] Timeout on variant {variant_num}")
                        continue

            logger.error(f"[ImageAgent] Original + all {max_variants} declassified variants failed")
            return None

        except Exception as e:
            logger.error(f"[ImageAgent] Error generating image: {e}", exc_info=True)
            return None

    async def _generate_cometapi_image(self, prompt: str, author: str) -> Optional[tuple]:
        """Generate an image using CometAPI's image generation endpoint.

        Used for models like gpt-image-1.5 that require CometAPI's format.

        Args:
            prompt: The image generation prompt
            author: The user who triggered this

        Returns:
            Tuple of (image_url, successful_prompt) or None if failed
        """
        if not self.cometapi_key:
            logger.error(f"[ImageAgent] No CometAPI key configured for CometAPI image model")
            return None

        # Global cooldown to prevent Discord spam protection / mod bot triggers
        current_time = time.time()
        time_since_last_image = current_time - self.last_global_image_time
        if time_since_last_image < 60:  # Minimum 60 seconds between ANY images
            time_remaining = 60 - time_since_last_image
            logger.warning(f"[ImageAgent] Global image cooldown: {time_remaining:.1f}s remaining")
            return None

        try:
            import aiohttp

            # Normalize model name (strip openai/ prefix if present)
            model_name = self.image_model
            if model_name.startswith("openai/"):
                model_name = model_name[7:]  # Remove "openai/" prefix

            logger.info(f"[ImageAgent] Generating CometAPI image with model {model_name}: {prompt[:100]}...")

            headers = {
                "Authorization": f"Bearer {self.cometapi_key}",
                "Content-Type": "application/json"
            }

            # Determine image size based on model requirements
            # doubao-seedream requires at least 3686400 pixels (1920x1920)
            if "seedream" in model_name.lower():
                image_size = "1920x1920"
            else:
                image_size = "1024x1024"

            # CometAPI uses /v1/images/generations endpoint with different payload format
            payload = {
                "model": model_name,
                "prompt": prompt,
                "n": 1,
                "size": image_size
            }
            logger.info(f"[ImageAgent] Using image size: {image_size}")

            async with aiohttp.ClientSession() as session:
                try:
                    async with session.post(
                        "https://api.cometapi.com/v1/images/generations",
                        json=payload,
                        headers=headers,
                        timeout=aiohttp.ClientTimeout(total=120)  # Longer timeout for image gen
                    ) as response:
                        if response.status == 200:
                            result = await response.json()
                            logger.info(f"[ImageAgent] CometAPI response keys: {list(result.keys())}")

                            # CometAPI returns {"data": [{"b64_json": "..."} or {"url": "..."}]}
                            data = result.get("data", [])
                            if data and len(data) > 0:
                                image_data = data[0]

                                # Try b64_json first (base64 encoded image)
                                if "b64_json" in image_data:
                                    b64_data = image_data["b64_json"]
                                    # Convert to data URL format
                                    image_url = f"data:image/png;base64,{b64_data}"
                                    logger.info(f"[ImageAgent] CometAPI image generated successfully (b64_json)")
                                    self.last_global_image_time = time.time()
                                    if MEDIA_UTILS_AVAILABLE and save_base64_image:
                                        save_base64_image(image_url, prompt, filename_prefix=f"img_{author}")
                                    return (image_url, prompt)

                                # Try URL format
                                elif "url" in image_data:
                                    image_url = image_data["url"]
                                    logger.info(f"[ImageAgent] CometAPI image generated successfully (url)")
                                    self.last_global_image_time = time.time()
                                    # For URLs, we'd need to download and convert - for now just return the URL
                                    return (image_url, prompt)

                            logger.warning(f"[ImageAgent] CometAPI response missing image data: {result}")
                        else:
                            response_text = await response.text()
                            logger.warning(f"[ImageAgent] CometAPI image failed: {response.status} - {response_text[:500]}")

                            # If content policy violation, try declassified prompt
                            if response.status == 400 and "content" in response_text.lower():
                                logger.info(f"[ImageAgent] Content policy issue, trying declassified prompt...")
                                declassified = await self.declassify_image_prompt(prompt, variant=1)
                                if declassified and declassified != prompt:
                                    payload["prompt"] = declassified
                                    async with session.post(
                                        "https://api.cometapi.com/v1/images/generations",
                                        json=payload,
                                        headers=headers,
                                        timeout=aiohttp.ClientTimeout(total=120)
                                    ) as retry_response:
                                        if retry_response.status == 200:
                                            result = await retry_response.json()
                                            data = result.get("data", [])
                                            if data and len(data) > 0:
                                                image_data = data[0]
                                                if "b64_json" in image_data:
                                                    b64_data = image_data["b64_json"]
                                                    image_url = f"data:image/png;base64,{b64_data}"
                                                    logger.info(f"[ImageAgent] CometAPI image generated with declassified prompt")
                                                    self.last_global_image_time = time.time()
                                                    if MEDIA_UTILS_AVAILABLE and save_base64_image:
                                                        save_base64_image(image_url, declassified, filename_prefix=f"img_{author}")
                                                    return (image_url, declassified)
                                                elif "url" in image_data:
                                                    return (image_data["url"], declassified)

                except asyncio.TimeoutError:
                    logger.warning(f"[ImageAgent] CometAPI image generation timeout")

            return None

        except Exception as e:
            logger.error(f"[ImageAgent] Error generating CometAPI image: {e}", exc_info=True)
            return None

    async def generate_video(self, prompt: str, author: str, duration: int = 8) -> Optional[str]:
        """Generate a video using CometAPI Sora 2.

        Args:
            prompt: The video generation prompt
            author: The user who triggered this
            duration: Video duration in seconds (4, 8, or 12)

        Returns:
            Video URL if successful, None if failed
        """
        if not self.cometapi_key:
            logger.error(f"[VideoGen] No CometAPI key configured")
            return None

        # Global cooldown to prevent spam (2.5 minutes between videos)
        current_time = time.time()
        time_since_last_video = current_time - self.last_global_video_time
        if time_since_last_video < 150:  # 2.5 minute cooldown
            time_remaining = 150 - time_since_last_video
            logger.warning(f"[VideoGen] Global video cooldown: {time_remaining:.1f}s remaining")
            return None

        # Validate duration (CometAPI Sora 2 supports 4, 8, 12 seconds)
        if duration not in [4, 8, 12]:
            duration = 8

        try:
            import aiohttp
            import asyncio

            logger.info(f"[VideoGen] Starting video generation for {author}: {prompt[:100]}...")

            # Submit video generation request
            headers = {
                "Authorization": f"Bearer {self.cometapi_key}",
                "Content-Type": "application/json"
            }

            payload = {
                "prompt": prompt,
                "model": self.video_model or "sora-2",
                "seconds": str(duration),  # API expects string not int
                "size": "1280x720"  # Landscape only as per user spec
            }

            async with aiohttp.ClientSession() as session:
                # Submit the video generation task
                async with session.post(
                    "https://api.cometapi.com/v1/videos",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=60)
                ) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"[VideoGen] API error: {response.status} - {error_text}")
                        return None

                    result = await response.json()
                    task_id = result.get("id") or result.get("task_id")

                    if not task_id:
                        logger.error(f"[VideoGen] No task ID in response: {result}")
                        return None

                    logger.info(f"[VideoGen] Task submitted: {task_id}")

                # Poll for completion (max 10 minutes for video generation - some videos take longer)
                max_polls = 60  # Poll every 10 seconds for up to 10 minutes
                for poll_num in range(max_polls):
                    await asyncio.sleep(10)  # Wait 10 seconds between polls

                    async with session.get(
                        f"https://api.cometapi.com/v1/videos/{task_id}",
                        headers=headers,
                        timeout=aiohttp.ClientTimeout(total=30)
                    ) as poll_response:
                        if poll_response.status != 200:
                            logger.warning(f"[VideoGen] Poll error: {poll_response.status}")
                            continue

                        poll_result = await poll_response.json()

                        # CometAPI wraps response in {"code": ..., "data": {...}}
                        # Status/URL may be in data or at top level
                        data = poll_result.get("data", poll_result)
                        inner_data = data.get("data", {}) if isinstance(data.get("data"), dict) else {}
                        status = (data.get("status") or poll_result.get("status") or "").lower()
                        progress = data.get("progress") or inner_data.get("progress") or "?"

                        # Check for fail_reason even if status is in_progress
                        fail_reason = data.get("fail_reason") or inner_data.get("fail_reason") or ""
                        if fail_reason:
                            logger.error(f"[VideoGen] Task failed: {fail_reason}")
                            return None

                        # Debug: log actual status on first poll and periodically
                        if poll_num == 0 or poll_num % 6 == 0:
                            logger.info(f"[VideoGen] Poll {poll_num}: status='{status}', progress={progress}, elapsed={poll_num*10}s")

                        # Check inner_data status too (CometAPI double-wraps)
                        inner_status = (inner_data.get("status") or "").lower()
                        if inner_status in ("completed", "succeeded", "success"):
                            status = inner_status  # Use inner status if it indicates completion

                        if status in ("completed", "succeeded", "success"):
                            # Log FULL response structure to find URL field
                            import json
                            logger.info(f"[VideoGen] FULL RESPONSE: {json.dumps(poll_result, indent=2, default=str)}")

                            # Check nested data.data structure (CometAPI wraps twice)
                            inner_data = data.get("data", {}) if isinstance(data.get("data"), dict) else {}

                            # Try multiple possible locations for video URL
                            video_url = (
                                # Inner data.data fields
                                inner_data.get("video_url") or
                                inner_data.get("url") or
                                inner_data.get("download_url") or
                                inner_data.get("media_url") or
                                inner_data.get("content_url") or
                                inner_data.get("file_url") or
                                inner_data.get("result") or
                                inner_data.get("video") or
                                # Outer data fields
                                data.get("video_url") or
                                data.get("url") or
                                data.get("download_url") or
                                data.get("result") or
                                data.get("output", {}).get("video_url") or
                                data.get("video", {}).get("url") or
                                # Top level
                                poll_result.get("video_url") or
                                poll_result.get("url")
                            )

                            # Also search for any string containing http in the response
                            def find_urls(obj, path=""):
                                urls = []
                                if isinstance(obj, dict):
                                    for k, v in obj.items():
                                        urls.extend(find_urls(v, f"{path}.{k}"))
                                elif isinstance(obj, list):
                                    for i, v in enumerate(obj):
                                        urls.extend(find_urls(v, f"{path}[{i}]"))
                                elif isinstance(obj, str) and ("http" in obj or ".mp4" in obj):
                                    urls.append((path, obj))
                                return urls

                            found_urls = find_urls(poll_result)
                            if found_urls:
                                logger.info(f"[VideoGen] Found URLs in response: {found_urls}")
                                if not video_url:
                                    # Use first found URL
                                    video_url = found_urls[0][1]

                            if video_url:
                                logger.info(f"[VideoGen] Video completed: {video_url}")
                                self.last_global_video_time = time.time()

                                # Download and save locally to AgentVideos directory
                                if MEDIA_UTILS_AVAILABLE and MEDIA_AGENT_VIDEOS_DIR:
                                    try:
                                        from pathlib import Path
                                        ensure_media_dirs()
                                        async with session.get(video_url, timeout=aiohttp.ClientTimeout(total=120)) as dl_resp:
                                            if dl_resp.status == 200:
                                                video_data = await dl_resp.read()
                                                video_path = str(MEDIA_AGENT_VIDEOS_DIR / f"{task_id}.mp4")
                                                with open(video_path, 'wb') as f:
                                                    f.write(video_data)
                                                logger.info(f"[VideoGen] Saved agent video to: {video_path}")
                                                save_media_prompt(Path(video_path), prompt, media_type="video")
                                                return f"FILE:{video_path}"
                                    except Exception as save_err:
                                        logger.warning(f"[VideoGen] Could not save locally, returning URL: {save_err}")

                                return video_url
                            else:
                                # No URL in status response - download from /content endpoint
                                logger.info(f"[VideoGen] No URL in status - downloading from /content endpoint...")
                                try:
                                    content_url = f"https://api.cometapi.com/v1/videos/{task_id}/content"
                                    async with session.get(
                                        content_url,
                                        headers=headers,
                                        timeout=aiohttp.ClientTimeout(total=120)  # Longer timeout for download
                                    ) as content_response:
                                        logger.info(f"[VideoGen] Content endpoint status: {content_response.status}, type: {content_response.headers.get('Content-Type', 'unknown')}")
                                        if content_response.status == 200:
                                            content_type = content_response.headers.get('Content-Type', '')
                                            # If it returns video binary, download and save to temp file
                                            if 'video' in content_type or 'octet' in content_type or 'mp4' in content_type:
                                                import tempfile
                                                import os
                                                from pathlib import Path
                                                video_data = await content_response.read()
                                                logger.info(f"[VideoGen] Downloaded {len(video_data)} bytes of video data")
                                                # Save to Media/Videos/ if available, else temp
                                                if MEDIA_UTILS_AVAILABLE and MEDIA_VIDEOS_DIR:
                                                    ensure_media_dirs()
                                                    video_path = str(MEDIA_VIDEOS_DIR / f"{task_id}.mp4")
                                                else:
                                                    temp_dir = tempfile.gettempdir()
                                                    video_path = os.path.join(temp_dir, f"{task_id}.mp4")
                                                with open(video_path, 'wb') as f:
                                                    f.write(video_data)
                                                logger.info(f"[VideoGen] Saved video to: {video_path}")
                                                # Save the prompt alongside the video
                                                if MEDIA_UTILS_AVAILABLE:
                                                    save_media_prompt(Path(video_path), prompt, media_type="video")
                                                self.last_global_video_time = time.time()
                                                # Return file path with FILE: prefix to indicate it's a local file
                                                return f"FILE:{video_path}"
                                            # Check if JSON response contains URL
                                            try:
                                                content_result = await content_response.json()
                                                logger.info(f"[VideoGen] Content response: {content_result}")
                                                video_url = (
                                                    content_result.get("url") or
                                                    content_result.get("video_url") or
                                                    content_result.get("data", {}).get("url") or
                                                    content_result.get("data", {}).get("video_url")
                                                )
                                                if video_url:
                                                    logger.info(f"[VideoGen] Got URL from content endpoint: {video_url}")
                                                    self.last_global_video_time = time.time()
                                                    return video_url
                                            except:
                                                pass  # Not JSON
                                        else:
                                            logger.warning(f"[VideoGen] Content endpoint returned {content_response.status}")
                                except Exception as e:
                                    logger.warning(f"[VideoGen] Content endpoint failed: {e}")

                                logger.error(f"[VideoGen] Completed but no URL found in: {poll_result}")
                                return None
                        elif status in ("failed", "failure", "error"):
                            error_msg = data.get("fail_reason") or data.get("error") or data.get("message") or poll_result.get("error") or "Unknown error"
                            logger.error(f"[VideoGen] Generation failed: {error_msg}")
                            return None
                        else:
                            # Still processing (queued, running, pending, etc.)
                            if poll_num % 6 == 0:  # Log every minute
                                logger.info(f"[VideoGen] Still processing... ({poll_num * 10}s elapsed)")

                logger.error(f"[VideoGen] Timeout waiting for video completion")
                return None

        except Exception as e:
            logger.error(f"[VideoGen] Error generating video: {e}", exc_info=True)
            return None

    async def generate_video_with_reference(
        self,
        prompt: str,
        author: str,
        duration: int = 4,
        input_reference: Optional[str] = None,
        skip_cooldown: bool = False
    ) -> Optional[str]:
        """Generate a video using CometAPI Sora 2 with optional input reference frame.

        This method supports image-to-video generation by accepting a reference
        image (as base64 data URL) that serves as the starting frame.

        Args:
            prompt: The video generation prompt
            author: The user who triggered this
            duration: Video duration in seconds (4, 8, or 12)
            input_reference: Optional base64 data URL of starting frame image
                            Format: "data:image/png;base64,..." or URL
            skip_cooldown: If True, bypass the global cooldown (for IDCC games)

        Returns:
            Video URL/path if successful, None if failed
        """
        if not self.cometapi_key:
            logger.error(f"[VideoGen] No CometAPI key configured")
            return None

        # Global cooldown to prevent spam (2.5 minutes between videos)
        # Skip cooldown during IDCC games where we need to generate multiple clips
        if not skip_cooldown:
            current_time = time.time()
            time_since_last_video = current_time - self.last_global_video_time
            if time_since_last_video < 150:  # 2.5 minute cooldown
                time_remaining = 150 - time_since_last_video
                logger.warning(f"[VideoGen] Global video cooldown: {time_remaining:.1f}s remaining")
                return None

        # Validate duration (CometAPI Sora 2 supports 4, 8, 12 seconds)
        if duration not in [4, 8, 12]:
            duration = 8

        try:
            import aiohttp
            import base64
            import tempfile
            import os

            logger.info(f"[VideoGen] Starting video generation for {author} (with_reference={input_reference is not None})")
            logger.info(f"[VideoGen] Prompt: {prompt[:100]}...")

            headers = {
                "Authorization": f"Bearer {self.cometapi_key}",
            }

            async with aiohttp.ClientSession() as session:
                # If we have an input reference, use multipart form data
                if input_reference:
                    logger.info(f"[VideoGen] Using multipart form for image-to-video mode")

                    # Decode base64 image to bytes
                    # input_reference format: "data:image/png;base64,..." or just base64
                    if input_reference.startswith("data:"):
                        # Extract base64 data after the comma
                        b64_data = input_reference.split(",", 1)[1]
                    else:
                        b64_data = input_reference

                    image_bytes = base64.b64decode(b64_data)

                    # Create multipart form data
                    form_data = aiohttp.FormData()
                    form_data.add_field("prompt", prompt)
                    form_data.add_field("model", self.video_model or "sora-2")
                    form_data.add_field("seconds", str(duration))
                    form_data.add_field("size", "1280x720")
                    form_data.add_field(
                        "input_reference",
                        image_bytes,
                        filename="reference.png",
                        content_type="image/png"
                    )

                    async with session.post(
                        "https://api.cometapi.com/v1/videos",
                        headers=headers,
                        data=form_data,
                        timeout=aiohttp.ClientTimeout(total=60)
                    ) as response:
                        if response.status != 200:
                            error_text = await response.text()
                            self.last_video_error = f"API error {response.status}: {error_text[:200]}"
                            logger.error(f"[VideoGen] {self.last_video_error}")
                            return None

                        result = await response.json()
                        task_id = result.get("id") or result.get("task_id")
                else:
                    # No input reference - use JSON
                    headers["Content-Type"] = "application/json"
                    payload = {
                        "prompt": prompt,
                        "model": self.video_model or "sora-2",
                        "seconds": str(duration),
                        "size": "1280x720"
                    }

                    async with session.post(
                        "https://api.cometapi.com/v1/videos",
                        headers=headers,
                        json=payload,
                        timeout=aiohttp.ClientTimeout(total=60)
                    ) as response:
                        if response.status != 200:
                            error_text = await response.text()
                            self.last_video_error = f"API error {response.status}: {error_text[:200]}"
                            logger.error(f"[VideoGen] {self.last_video_error}")
                            return None

                        result = await response.json()
                        task_id = result.get("id") or result.get("task_id")

                if not task_id:
                    self.last_video_error = f"No task ID in API response: {str(result)[:200]}"
                    logger.error(f"[VideoGen] {self.last_video_error}")
                    return None

                logger.info(f"[VideoGen] Task submitted: {task_id}")

                # Poll for completion (max 10 minutes)
                max_polls = 60
                for poll_num in range(max_polls):
                    await asyncio.sleep(10)

                    async with session.get(
                        f"https://api.cometapi.com/v1/videos/{task_id}",
                        headers=headers,
                        timeout=aiohttp.ClientTimeout(total=30)
                    ) as poll_response:
                        if poll_response.status != 200:
                            logger.warning(f"[VideoGen] Poll error: {poll_response.status}")
                            continue

                        poll_result = await poll_response.json()

                        # Handle CometAPI's nested response structure
                        data = poll_result.get("data", poll_result)
                        inner_data = data.get("data", {}) if isinstance(data.get("data"), dict) else {}
                        status = (data.get("status") or poll_result.get("status") or "").lower()
                        progress = data.get("progress") or inner_data.get("progress") or "?"

                        # Check for failure
                        fail_reason = data.get("fail_reason") or inner_data.get("fail_reason") or ""
                        if fail_reason:
                            self.last_video_error = f"Task failed: {fail_reason}"
                            logger.error(f"[VideoGen] {self.last_video_error}")
                            return None

                        if poll_num == 0 or poll_num % 6 == 0:
                            logger.info(f"[VideoGen] Poll {poll_num}: status='{status}', progress={progress}")

                        # Check completion
                        inner_status = (inner_data.get("status") or "").lower()
                        if inner_status in ("completed", "succeeded", "success"):
                            status = inner_status

                        if status in ("completed", "succeeded", "success"):
                            # Try to find video URL
                            video_url = (
                                inner_data.get("video_url") or
                                inner_data.get("url") or
                                inner_data.get("download_url") or
                                data.get("video_url") or
                                data.get("url") or
                                data.get("download_url") or
                                poll_result.get("video_url") or
                                poll_result.get("url")
                            )

                            if video_url:
                                logger.info(f"[VideoGen] Video completed: {video_url}")
                                self.last_global_video_time = time.time()
                                return video_url

                            # Try /content endpoint
                            try:
                                content_url = f"https://api.cometapi.com/v1/videos/{task_id}/content"
                                async with session.get(
                                    content_url,
                                    headers=headers,
                                    timeout=aiohttp.ClientTimeout(total=120)
                                ) as content_response:
                                    if content_response.status == 200:
                                        content_type = content_response.headers.get('Content-Type', '')
                                        if 'video' in content_type or 'octet' in content_type:
                                            import tempfile
                                            from pathlib import Path
                                            video_data = await content_response.read()
                                            # Save to Media/Videos/ if available, else temp
                                            if MEDIA_UTILS_AVAILABLE and MEDIA_VIDEOS_DIR:
                                                ensure_media_dirs()
                                                video_path = str(MEDIA_VIDEOS_DIR / f"{task_id}.mp4")
                                            else:
                                                temp_dir = tempfile.gettempdir()
                                                video_path = os.path.join(temp_dir, f"{task_id}.mp4")
                                            with open(video_path, 'wb') as f:
                                                f.write(video_data)
                                            # Save the prompt alongside the video
                                            if MEDIA_UTILS_AVAILABLE:
                                                save_media_prompt(Path(video_path), prompt, media_type="video")
                                            self.last_global_video_time = time.time()
                                            return f"FILE:{video_path}"
                            except Exception as e:
                                logger.warning(f"[VideoGen] Content endpoint failed: {e}")

                            self.last_video_error = "Completed but no video URL found in response"
                            logger.error(f"[VideoGen] {self.last_video_error}")
                            return None

                        elif status in ("failed", "failure", "error"):
                            error_msg = data.get("fail_reason") or data.get("error") or "Unknown"
                            self.last_video_error = f"Generation failed: {error_msg}"
                            logger.error(f"[VideoGen] {self.last_video_error}")
                            return None

                self.last_video_error = "Timeout waiting for video completion (10 min)"
                logger.error(f"[VideoGen] {self.last_video_error}")
                return None

        except Exception as e:
            self.last_video_error = f"Exception: {str(e)}"
            logger.error(f"[VideoGen] Error: {e}", exc_info=True)
            return None

    async def handle_reaction(
        self,
        agent_name: str,
        message_id: int,
        emoji: str,
        user_name: str,
        reaction_count: int
    ):
        """
        Handle emoji reactions on bot messages - dopamine boost!
        Increases importance score for messages that receive reactions.

        Args:
            agent_name: Which bot's message was reacted to
            message_id: Discord message ID
            emoji: The emoji used
            user_name: Who reacted
            reaction_count: Total number of reactions
        """
        if not self.vector_store:
            logger.warning(f"[{agent_name}] Cannot process reaction - no vector store")
            return

        try:
            # Query vector store to find this message
            results = self.vector_store.collection.get(
                where={
                    "$and": [
                        {"agent_name": {"$eq": agent_name}},
                        {"message_id": {"$eq": message_id}}
                    ]
                }
            )

            if not results or not results['ids']:
                logger.warning(f"[{agent_name}] Message {message_id} not found in vector store for reaction")
                return

            # Get the first matching message (should only be one)
            doc_id = results['ids'][0]
            metadata = results['metadatas'][0]
            current_importance = metadata.get('importance', 5)

            # Dopamine boost: +2 per reaction, capped at 10
            importance_boost = min(2, reaction_count)  # Max +2 per reaction event
            new_importance = min(10, current_importance + importance_boost)

            # Update the metadata
            metadata['importance'] = new_importance

            # Update in vector store (delete and re-add with same ID)
            self.vector_store.collection.update(
                ids=[doc_id],
                metadatas=[metadata]
            )

            logger.info(f"[{agent_name}]  DOPAMINE BOOST! {user_name} reacted {emoji} to message {message_id} - importance: {current_importance}  {new_importance}")

            # AUTO-GENERATE PREFERENCE from positive reactions
            # If reaction count is significant (2+), create a preference learning what works
            if reaction_count >= 2:
                message_content = results['documents'][0] if results['documents'] else ""
                message_author = metadata.get('author', 'unknown')

                # Determine if this is an image generation message
                is_image_message = "Generated image:" in message_content or "[IMAGE]" in message_content

                if is_image_message:
                    # For images, track that the IMAGE was well-received (not just the prompt)
                    preference_text = f"Users reacted positively ({reaction_count}x {emoji}) to an image I created. Visual content resonates well with the audience."
                else:
                    # For text messages, extract key insight about what worked
                    # Use first 100 chars as a sample of the successful content
                    content_sample = message_content[:100].replace('\n', ' ')
                    preference_text = f"Users reacted positively ({reaction_count}x {emoji}) to my message about: '{content_sample}...'. This style/topic resonates well."

                # Store as preference with high importance
                self.vector_store.add_user_preference(
                    agent_name=agent_name,
                    user_id=user_name,  # Track which user liked this
                    preference=preference_text,
                    importance=min(10, 6 + reaction_count)  # Higher importance for more reactions
                )

                logger.info(f"[{agent_name}]  LEARNED PREFERENCE from reaction: '{preference_text[:80]}...'")

        except Exception as e:
            logger.error(f"[{agent_name}] Error processing reaction: {e}", exc_info=True)

    def add_agent(
        self,
        name: str,
        model: str,
        system_prompt: str,
        response_frequency: int = 30,
        response_likelihood: int = 50,
        max_tokens: int = 500,
        user_attention: int = 50,
        bot_awareness: int = 50,
        message_retention: int = 1,
        user_image_cooldown: int = 90,
        global_image_cooldown: int = 90,
        allow_spontaneous_images: bool = False,
        image_gen_turns: int = 3,
        image_gen_chance: int = 25,
        allow_spontaneous_videos: bool = False,
        video_gen_turns: int = 10,
        video_gen_chance: int = 10,
        video_duration: int = 4,
        self_reflection_enabled: bool = True,
        self_reflection_cooldown: int = 15,
        introspection_chance: int = 5
    ) -> bool:
        with self.lock:
            if name in self.agents:
                return False

            agent = Agent(
                name=name,
                model=model,
                system_prompt=system_prompt,
                response_frequency=response_frequency,
                response_likelihood=response_likelihood,
                max_tokens=max_tokens,
                user_attention=user_attention,
                bot_awareness=bot_awareness,
                message_retention=message_retention,
                user_image_cooldown=user_image_cooldown,
                global_image_cooldown=global_image_cooldown,
                allow_spontaneous_images=allow_spontaneous_images,
                image_gen_turns=image_gen_turns,
                image_gen_chance=image_gen_chance,
                allow_spontaneous_videos=allow_spontaneous_videos,
                video_gen_turns=video_gen_turns,
                video_gen_chance=video_gen_chance,
                video_duration=video_duration,
                self_reflection_enabled=self_reflection_enabled,
                self_reflection_cooldown=self_reflection_cooldown,
                introspection_chance=introspection_chance,
                openrouter_api_key=self.openrouter_api_key,
                cometapi_key=self.cometapi_key,
                affinity_tracker=self.affinity_tracker,
                send_message_callback=self.send_message_callback,
                agent_manager_ref=self,
                vector_store=self.vector_store
            )
            self.agents[name] = agent
            return True

    def update_agent(
        self,
        name: str,
        model: Optional[str] = None,
        system_prompt: Optional[str] = None,
        response_frequency: Optional[int] = None,
        response_likelihood: Optional[int] = None,
        max_tokens: Optional[int] = None,
        user_attention: Optional[int] = None,
        bot_awareness: Optional[int] = None,
        message_retention: Optional[int] = None,
        user_image_cooldown: Optional[int] = None,
        global_image_cooldown: Optional[int] = None,
        allow_spontaneous_images: Optional[bool] = None,
        image_gen_turns: Optional[int] = None,
        image_gen_chance: Optional[int] = None,
        allow_spontaneous_videos: Optional[bool] = None,
        video_gen_turns: Optional[int] = None,
        video_gen_chance: Optional[int] = None,
        video_duration: Optional[int] = None,
        self_reflection_enabled: Optional[bool] = None,
        self_reflection_cooldown: Optional[int] = None,
        introspection_chance: Optional[int] = None
    ) -> bool:
        with self.lock:
            if name not in self.agents:
                return False

            self.agents[name].update_config(
                model=model,
                system_prompt=system_prompt,
                response_frequency=response_frequency,
                response_likelihood=response_likelihood,
                max_tokens=max_tokens,
                user_attention=user_attention,
                bot_awareness=bot_awareness,
                message_retention=message_retention,
                user_image_cooldown=user_image_cooldown,
                global_image_cooldown=global_image_cooldown,
                allow_spontaneous_images=allow_spontaneous_images,
                image_gen_turns=image_gen_turns,
                image_gen_chance=image_gen_chance,
                allow_spontaneous_videos=allow_spontaneous_videos,
                video_gen_turns=video_gen_turns,
                video_gen_chance=video_gen_chance,
                video_duration=video_duration,
                self_reflection_enabled=self_reflection_enabled,
                self_reflection_cooldown=self_reflection_cooldown,
                introspection_chance=introspection_chance
            )
            return True

    def delete_agent(self, name: str) -> bool:
        with self.lock:
            if name not in self.agents:
                return False

            agent = self.agents[name]
            agent.stop()
            self.affinity_tracker.clear_history_for_agent(name)
            del self.agents[name]
            return True

    def get_agent(self, name: str) -> Optional[Agent]:
        with self.lock:
            return self.agents.get(name)

    def get_all_agents(self) -> List[Agent]:
        with self.lock:
            return list(self.agents.values())

    async def send_startup_message(self):
        """Send a startup message advertising available shortcuts."""
        if self.startup_message_sent or not self.send_message_callback:
            return

        shortcuts_path = os.path.join(os.path.dirname(__file__), "config", "shortcuts.json")
        if not os.path.exists(shortcuts_path):
            return

        try:
            with open(shortcuts_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            commands = data.get("commands", [])
            if not commands:
                return

            message = f"""**BASI-Bot Multi-Agent System Online**

**Commands:**
`!IDCC` - Interdimensional Cable (agents collaborate to create AI-generated video skits)
`!tribal-council` - Tribal Council (agents debate and vote on system prompt changes)
`!roast` - Celebrity Roast (agents roast an AI-generated celebrity)
`!shortcuts` - View all {len(commands)} status effects

**Status Effects** - Apply altered states to agents:
`!DRUNK`, `!STONED`, `!MANIC`, `!PARANOID`, `!DISSOCIATED`, and {len(commands) - 5} more
Syntax: `!EFFECT` | `!EFFECT 8` (intensity) | `!EFFECT AgentName` (target) | `!EFFECT 7 AgentName`

Agents are now listening. Address them by first name, last name, or full name to get their attention."""

            await self.send_message_callback(message, "", "")
            self.startup_message_sent = True
            logger.info("[AgentManager] Startup message sent advertising shortcuts")

        except Exception as e:
            logger.error(f"[AgentManager] Error sending startup message: {e}", exc_info=True)

    def start_agent(self, name: str) -> bool:
        with self.lock:
            if name in self.agents:
                result = self.agents[name].start()

                # Send startup message when first agent starts
                if result and not self.startup_message_sent:
                    loop = get_or_create_event_loop()
                    asyncio.run_coroutine_threadsafe(self.send_startup_message(), loop)

                return result
            return False

    def stop_agent(self, name: str) -> bool:
        with self.lock:
            if name in self.agents:
                return self.agents[name].stop()
            return False

    def stop_all_agents(self) -> None:
        with self.lock:
            for agent in self.agents.values():
                agent.stop()

    def add_message_to_all_agents(self, author: str, content: str, message_id: Optional[int] = None, replied_to_agent: Optional[str] = None, user_id: Optional[str] = None) -> None:
        with self.lock:
            # Add to each agent's conversation history (fast, in-memory)
            for agent in self.agents.values():
                agent.add_message_to_history(author, content, message_id, replied_to_agent, user_id)

            # Store to vector DB PER-AGENT for personalized importance ratings
            # Skip if no vector store or if this is a GameMaster message
            if self.vector_store and 'GameMaster' not in author and author != 'GameMaster (system)':
                # Check if author is a bot
                is_bot = any(
                    author == agent.name or author.startswith(f"{agent.name} (")
                    for agent in self.agents.values()
                )

                # Get list of known entities (agent names) for mention detection
                known_entities = list(self.agents.keys())
                agent_names = [a.name for a in self.agents.values()]
                timestamp = time.time()

                # Run vector store operations in background thread to avoid blocking Discord
                def store_to_vector_db():
                    for agent_name in agent_names:
                        try:
                            self.vector_store.add_message(
                                content=content,
                                author=author,
                                agent_name=agent_name,
                                timestamp=timestamp,
                                message_id=message_id,
                                importance=5,
                                replied_to_agent=replied_to_agent,
                                is_bot=is_bot,
                                user_id=user_id if user_id else author,
                                memory_type="conversation",
                                known_entities=known_entities
                            )
                        except Exception as e:
                            logger.error(f"[AgentManager] Error storing message to vector DB for {agent_name}: {e}")
                    logger.debug(f"[AgentManager] Stored message from {author} to {len(agent_names)} agent vector DBs")

                try:
                    self._vector_executor.submit(store_to_vector_db)
                except Exception as e:
                    logger.error(f"[AgentManager] Failed to submit vector store task: {e}")

    def add_message_to_image_agents_only(self, author: str, content: str, message_id: Optional[int] = None, replied_to_agent: Optional[str] = None, user_id: Optional[str] = None) -> None:
        """Add message only to agents with image generation models."""
        with self.lock:
            for agent in self.agents.values():
                if agent._is_image_model:
                    agent.add_message_to_history(author, content, message_id, replied_to_agent, user_id)
                    logger.info(f"[AgentManager] Added [IMAGE] message to image agent: {agent.name}")

    def load_agents_from_config(self, agents_config: List[Dict[str, Any]]) -> None:
        for agent_data in agents_config:
            name = agent_data["name"]
            self.add_agent(
                name=name,
                model=agent_data["model"],
                system_prompt=agent_data["system_prompt"],
                response_frequency=agent_data.get("response_frequency", 30),
                response_likelihood=agent_data.get("response_likelihood", 50),
                max_tokens=agent_data.get("max_tokens", 500),
                user_attention=agent_data.get("user_attention", 50),
                bot_awareness=agent_data.get("bot_awareness", 50),
                message_retention=agent_data.get("message_retention", 1),
                user_image_cooldown=agent_data.get("user_image_cooldown", 90),
                global_image_cooldown=agent_data.get("global_image_cooldown", 90),
                allow_spontaneous_images=agent_data.get("allow_spontaneous_images", False),
                image_gen_turns=agent_data.get("image_gen_turns", 3),
                image_gen_chance=agent_data.get("image_gen_chance", 25),
                allow_spontaneous_videos=agent_data.get("allow_spontaneous_videos", False),
                video_gen_turns=agent_data.get("video_gen_turns", 10),
                video_gen_chance=agent_data.get("video_gen_chance", 10),
                video_duration=agent_data.get("video_duration", 4),
                self_reflection_enabled=agent_data.get("self_reflection_enabled", True),
                self_reflection_cooldown=agent_data.get("self_reflection_cooldown", 15),
                introspection_chance=agent_data.get("introspection_chance", 5)
            )
            # Load self-reflection history if present
            if name in self.agents and "self_reflection_history" in agent_data:
                self.agents[name].self_reflection_history = agent_data["self_reflection_history"]

    def reload_agents_from_file(self) -> Tuple[int, List[str]]:
        """
        Reload agents from the config file, adding any NEW agents.
        Does NOT remove or restart existing agents.

        Returns:
            Tuple of (count of new agents added, list of new agent names)
        """
        from config_manager import config_manager

        agents_config = config_manager.load_agents()
        existing_names = set(self.agents.keys())
        new_agents = []

        for agent_data in agents_config:
            name = agent_data.get("name")
            if name and name not in existing_names:
                success = self.add_agent(
                    name=agent_data["name"],
                    model=agent_data["model"],
                    system_prompt=agent_data["system_prompt"],
                    response_frequency=agent_data.get("response_frequency", 30),
                    response_likelihood=agent_data.get("response_likelihood", 50),
                    max_tokens=agent_data.get("max_tokens", 500),
                    user_attention=agent_data.get("user_attention", 50),
                    bot_awareness=agent_data.get("bot_awareness", 50),
                    message_retention=agent_data.get("message_retention", 1),
                    user_image_cooldown=agent_data.get("user_image_cooldown", 90),
                    global_image_cooldown=agent_data.get("global_image_cooldown", 90),
                    allow_spontaneous_images=agent_data.get("allow_spontaneous_images", False),
                    image_gen_turns=agent_data.get("image_gen_turns", 3),
                    image_gen_chance=agent_data.get("image_gen_chance", 25),
                    allow_spontaneous_videos=agent_data.get("allow_spontaneous_videos", False),
                    video_gen_turns=agent_data.get("video_gen_turns", 10),
                    video_gen_chance=agent_data.get("video_gen_chance", 10),
                    video_duration=agent_data.get("video_duration", 4),
                    self_reflection_enabled=agent_data.get("self_reflection_enabled", True),
                    self_reflection_cooldown=agent_data.get("self_reflection_cooldown", 15),
                    introspection_chance=agent_data.get("introspection_chance", 5)
                )
                if success:
                    new_agents.append(name)
                    # Load self-reflection history if present
                    if "self_reflection_history" in agent_data:
                        self.agents[name].self_reflection_history = agent_data["self_reflection_history"]
                    logger.info(f"[AgentManager] Hot-loaded new agent: {name}")

        return len(new_agents), new_agents

    def get_agents_config(self) -> List[Dict[str, Any]]:
        with self.lock:
            return [agent.to_dict() for agent in self.agents.values()]
